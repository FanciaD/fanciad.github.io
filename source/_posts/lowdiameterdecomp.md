---
title: Low Diameter Decomposition
date: '2025-11-30 11:03:14'
updated: '2025-11-30 11:03:14'
tags: Fancia
permalink: EbariandtheForest/
description: Low Diameter Decomposition
mathjax: true
---


不一定写完了，但是下次再说。

Paper ref: 2304.05279

还有一些要看的东西：2508.20302， 2510.19780

### Low Diameter Decompositions

有人说，做路径题的时候 DAG 是好的，一般图是坏的；毕竟，DAG 给的性质太多了。

有人说，做路径题的时候图的直径小是好的；毕竟，你经常可以拿出一些限制 hop 数量的做法。

然后有人发现了 LDD，它只需要删掉一点点边，就可以使得剩下的图里面，每个 SCC 的直径（$\max(dis(u,v),dis(v,u))$）很小。这究竟是怎么想到的？

#### (weak) Low Diameter Decomposition

考虑让整个图的直径不超过 $D$。那么，如果有一对点之间距离大于了 $D$，我们就要把它拆掉。但怎么拆？我们希望不要一不小心拆掉一车边，那么借鉴 Fineman Shortcut 的想法：从 $u$ 开始随机一个距离 $d<D$，把这个距离向前的边切掉，这样就不连通了。这样想的话，一条长度为 $l$ 的边被删掉的概率是 $l/D$ 的。再想想可以发现，显然不可能比 $l/D$ 更好：给你一个长度 $2D$ 的环，至少得删一条边。

回到之前的想法，这里只能删正向边，因为我们用到了三角形不等式。而反向边可能跨越很长的 $d$ 但距离很短。因此留下来一个 DAG 看起来也是合理的。（毕竟 Directed Expander Decomposition 也这样做了。）

但这样搞完只保证了这一对是好的，可能还有别的部分需要处理——这里是拆开后两边的部分。因此我们需要递归，但这样会递归多少次？这就很难说了，因为 $u$ 出发走 $D$ 的距离可能能到 $n-1$ 个点，而我们是在这上面递归。

那能不能不把限制写成每个点出发在距离 $D$ 内能到 $n$ 个点呢？还真能：

> 在有向图中，如果每个点的入度与出度均不小于 $n/2$，则图强连通，且直径不超过 $2$。
>
> 证明：从一个点开始 bfs，第一步（出度）可以走到 $n/2+1$ 个点，从而下一步每个剩下的点（入度）必定能从这里的某个点走过来。

因此，我们可以转而要求，每个点向两个方向走 $D/2$ 距离，至少能走到 $n/2$ 个点。我们称满足这个条件的点是 Heary 的，否则是 In-light 或者 Out-light 的。

那现在考虑一个 Out-light 的点。类似之前的想法，我们从这个点开始，随机一个 $D/2$ 内的距离，然后把这个距离向外的边切掉，然后递归两侧。这样，左边剩余部分点数不超过 $n/2$，所以递归只有 $\log n$ 层。另外一边类似。

然后又有个问题：剩下部分你想继续删，但现在有一条边，你每次都刚好碰到它，所以有 $l/D$ 的概率把它删了，但没有概率把它包含进去。这样做很多次就寄了。

因此就得优秀地随机：如果你碰到了一条边的一端，那必须有 $1-(l/D)$ 级别的概率完全把这条边包含进去。这样的东西被称为几何分布：每次有 $1/D$ 的概率停下来，不停就 $+1$ 然后继续。这样就没有那个问题了，不过你现在有很大的概率爆掉 $D/2$ 的上界，然后几何级数得写成均值 $D/\log n$ 才能 whp 不爆。这样会让你的概率编程 $l\log n/D$，但看起来还好。（然后你递归还有一个 $\log$，所以加起来两个）

那这样就搞定了——每次一直找 light 的点，然后从对应方向用几何级数随一个均值 $D/\log n$ 的东西作为距离，从那里开始把向外的边切了，里面那块继续递归。然后外面继续做，直到只剩 Heavy 的东西，这样就直径很小了——不过因为你删边了，所以这个直径得是在原图上的直径；这就是为什么现在的算法被称为 Weak LDD。

还有个问题：你想看每个点是不是（限定距离）能走到至少 $n/2$ 个点，这怎么算？考虑经典随机采样技术：我们随机 $O(\log n)$ 个点，从它们开始反向最短路，就可以判断每个点能走到的点里面是否包含了我们采样的点，然后就可以以常数误差估计我们能走到的点的占比，比如保证 $\geq n/2$ 或者 $\leq 2n/3$。然后注意到递归的时候我们只需要点数除以一个常数，而不一定需要 $n/2$，所以那边放宽一点就可以了。

总结一下，我们现在删了一些边，保证一条长度为 $l$ 的边被删掉的概率是 $l/D\cdot \log^2 n$ 级别（后面这一项也被称为 Overhead），使得剩下的图可以被分成若干个点集，满足每个点集内部在**原图**上直径不超过 $D$，且点集中间的边是一个 DAG。

复杂度应当是 $\log^2$ 的：递归一个 log，最短路一个 log。~~虽然在你想做的题还是 $mn^\Omega(1)$ 的时候，这东西没有意义~~

现在这样是 whp 正确的。考虑到有人不喜欢这样，这个算法实际上还可以判定自己是否真的找到了合法的 LDD（也即 Monte Carlo vs Las Vegas，或者 BPP vs ZPP）。做法是，如果算法是对的，那么随机一个点就可以 $D$ 距离内双向到达所有点。那找一个点判定就可以保证所有点可以 $2D$ 距离内到达。所以再除以 $2$ 就好了。

#### Strong Low Diameter Decomposition

那我们能不能把原图拿掉，从而保证删完之后的每个强连通分量自己就是好的？这样就得重新处理 Heavy Vertex 的情况。

如果有一个 Heavy Vertex，那它已经能在 $D/2$ 的距离碰到很多点了。如果有重合的部分，那把它们（包含中间的路径）拿出来，就是一个直径很小的块。如果我们在上面把 $n/2$ 换成 $n/1.5$，那这里就有 $\Omega(n)$ 个点。

但这样你就不能把它切出来了，因为这样搞的度数是没有保证的。因此只能考虑切的时候不切到这一块内部。考虑把这一块缩起来然后继续做。问题显然是，缩完的直径在展开时会增加 $D$。但因为每次这样都是减少 $\Omega(n)$ 个点，因此最多缩点 $O(\log n)$ 次。那么，这样只会再多一个 $\log$。

#### Example: Integer-Weight SSSP

如果有负权边怎么办？考虑直接当成 $0$：其一，这样也不会删掉它；其二，新的图上的直径自然是原来的直径，因为我们只是放大了边权。

显然最短路在 DAG 上是简单的，因此我们看一个 SCC 里面的情况。此时，因为直径不超过 $D$，所以任何一段路径权值不能小于 $-D$——但这和 hop 数好像一点关系没有。

不过我们可以让它有关系——介绍 Cost Scaling，整数边权问题利器。考虑记一个 $B$ 表示最大负边权绝对值，然后我们每轮希望 $B$ 除以 $2$。那么在这一轮里面，可以看成我们给负权边全部加上一个 $B/2$，然后求一个最短路。这里也可以看成 $B=2$。

那现在在这个 SCC 里面跑最短路（All-source），如果有一个最短路用了 $h$-hop，那因为它的权值得 $<0$，所以加边权之前它的权值就是 $-h$。因此这件事不会在一个 $h$-LDD 上出现。因此此时我们只需要跑 $h$-hop 最短路即可。

那代价是什么呢？注意到还有那些删掉的边。为了把那些边加回来，我们需要对那些边再跑最短路。考虑分析 hop 数量，可以发现这和路径长度有关：记正权边和为 $s$，那么概率差不多是 $s/h$。那正权边总和是多少呢？我们再跑 all-source，这样这个值不超过负权边和（的相反数），而后者此时不超过 $n$。

那么你就会 $\tilde O(m\sqrt n)$ 了。但还可以更好：注意到每一步都是说“用了多少负权边”，那么可以递归：每一次从 $h$-hop 递归到 $h/2$-hop。这样就是 polylog 了。



#### Something

可以看到这个在做路径相关问题的时候很有用。那为什么我一点不会这东西呢？因为我开了个 Real-Weight 的题做了半年，然后这个对 Real-Weight 是不大行的。