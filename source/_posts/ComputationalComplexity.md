---
title: 'Computational Complexity: A Modern Approach 笔记'
date: '2025-01-22 00:19:06'
updated: '2025-01-22 00:19:06'
tags: Fancia
permalink: Phosphene/
description: 'Computational Complexity: A Modern Approach'
mathjax: true
---

二周目。

### I Computation Model

#### The Turing Machine

我们考虑一个通用的计算问题：我们有一个不定长的输入，输出也是不定长的。这样的一个问题被定义为一个函数 $f:\{0,1\}^*\to \{0,1\}^*$。在很多时候，我们会着重考虑输出只有一个 $01$ 的问题，即判定性问题。

我们考虑这样一个模型：有 $k+2$ 条在单向上的无限纸带，每个格子上有一个字符，我们认为字符属于某个字符集 $\Gamma$。每个纸带上有一个读写头。我们认为每条纸带上正好有一个字符表示开头位置。

我们认为第一条纸带为输入纸带，它是只读的，最后一条纸带是结果纸带，这条纸带上的最终结果为我们的输出。剩下的 $k$ 条被称为工作纸带。

这个图灵机还有一个状态 $q\in Q$，其中 $Q$ 是这个图灵机的状态空间。我们要求状态空间是有限的，同时这里我们钦定某一个状态是初始状态 $q_s$，一个状态是停机状态 $q_h$。如果我们到达了停机状态则其不再进行操作。

这个图灵机进行如下操作：每一时刻，我们通过当前状态和当前每个纸带头的值得到当前的操作：每个纸带上写入一个值，且每个纸带头进行移动：向左右一步或者不动。具体来说这可以看成一个 $Q\times \Gamma^k\to Q\times \Gamma^{k-1}\times \{L,S,R\}^k$ 的一个函数。

现在我们来定义复杂度。首先我们考虑一个问题的输入规模，这被直接定义为输入串的长度。我们称一个图灵机 $M$ 的时间复杂度在 $T(n)$ 时间内，当且仅当对于任意一个输入 $x$，$M$ 在 $T(|x|)$ 步内停机。我们称 $M$ 计算 $f$ 当且仅当（显然地）对于每个输入 $x$，$M$ 的输出为 $f(x)$。这里在没有显式说明的情况下，复杂度都指时间复杂度。

ex 1-4：平凡

为了避免神必的情况（？），我们只考虑这样的 $T$：$T(n)\geq n$ 且 $T$ 能被某个图灵机计算。第一点是为了要求读完输入，第二点是因为我们有的时候证明需要知道步数 $T(n)$，比如某个unary题。

当然，这个定义中的很多细节对计算性的影响没那么大，例如有如下情况：

1. 如果上述定义的图灵机算某个问题复杂度是 $T(n)$，那么即使我们把字符集限制在 $0,1$ 和开头字符，空白字符后，其复杂度不超过 $4\log|\Gamma|T(n)$。

简要证明：把原本的每个字符扩展为 $\log |\Gamma|$ 位的 01 编码，证明细节省略。

2. 如果我们用了 $k$ 条工作纸带，那么可以变为只用一条，复杂度不超过 $5kT(n)^2$。

简要证明：考虑把所有纸带交替拼在一起（因为它们是无限长的），每条纸带的开头可以用一类特殊字符描述。这样每次操作我们先扫一遍把 $\Gamma^k$ 的输入找出来，然后扫一遍模拟操作。

3. 如果我们用双向纸带，可以变回单条且复杂度最多 $*4$。

简要证明：考虑正反交替拼起来。一种简单方式是用 $\Gamma^2$ 的直接叠起来。

我们还有更多的结果：

ex 5-7：straightforward

ex8：我们还可以进一步限制图灵机的操作：我们称一个图灵机是 oblivious（不会翻译）的，当且仅当它的纸带头移动情况只和输入的大小有关。然后我们有如下结论：如果一个普通的图灵机可以 $T(n)$ 计算一个输出为 $01$ 的函数 $f$，那么我们可以有一个复杂度 $O(T(n)^2)$ 的 oblivious 的图灵机。

证明：拿出上面的第二条，把有限的情况控制编码到状态中就行了。

ex10：如果我们只有一条纸带，上面之前有输入，最后需要放输出。那么对于原来 $T(n)$ 能算的东西，现在不超过 $O(T(n)^2)$ 就能算。

证明：类似地交替拼在一起，最后实在不行拿一个状态把分散的输出合并即可。

ex11：如果我们有一个二维纸带的二维图灵机，那么如果这东西 $T(n)$ 能算，那么原来的图灵机 $O(T(n)^2)$ 也能算。

证明：我们先拿一个纸带模拟位置，然后考虑把二维纸带通过绕圈的方式变成一维。这样二维上移动一步只需要一维上移动 $O(T(n))$ 步，然后可以把这东西算出来。然后我们需要支持给一个 $n$ 向某个方向移动这么多步，那么我们模拟一个每次 $-1$ 的东西（类似加法器），每一步移一格。这样一直进位每一步复杂度是 $O(T(n))$。（ref：某个 gcj 题，我blog里面有）

(0.3*)ex12：考虑一个更符合现代计算机的模型：我们有一个RAM，然后有一条纸带用来访问这个RAM：我们往这条纸带上写一个数，然后就可以通过某个状态的操作访问这个数对应下标的位（读/写）。那么如果这东西 $T(n)$ 能算，那么原来的图灵机 $O(T(n)^2)$ 也能算。

证明：考虑如何模拟 RAM 访问，这里一个不小的挑战是访问下标可以是 $T(n)$ 级别的位数，因此不能直接上 ex11 的进位移动。考虑把这条纸带上的操作记录下来，然后每一轮扫一遍尝试找到访问的结果（每当写一个位置时我们把内容复制出来）。那么考虑维护当前这条纸带上的数，维护当前和我们需要的结果有多少位不匹配，修改时这容易维护。（注意我们认为当前数以纸带上位置结尾，因为我们会在这里写 R，这容易处理）（如果我们不看前导 $0$ 那么相等必定完全匹配，前导 $0$ 可以处理掉，虽然细节不少）对于这个不匹配数量的计数器如果继续这样做会是 $O(\log^* T(n))$，但我们有更聪明的方式：考虑再拿一条纸带只有第一个位置是 $1$，然后直接拿来当计数器用。这样就能处理访问了。

ex13：考虑另一种更符合现代计算机的模型：现在我们的程序可以跳转。具体来说每条命令有一个 label，然后我们可以通过 label 跳。证明可以线性维护。

证明：直接把 label 编码到状态里面。

那么在不考虑 fine-grained 复杂度时，图灵机和一大堆别的模型（比如常见的 word ram）可以不加区分地使用。在没有特殊说明的情况下，接下来的大部分情况下我们会使用这一点。那么我们可以回到更贴近现实的计算模型。

#### More about Turing Machines

ML 助教就是sb。

ML 助教就是sb。

ML 助教就是sb。

根据一些 sys 课的经验，我们可以把那里的程序也看成数据。在这里也有类似的事情：我们可以把每个图灵机编码为 $01$ 串，且这一编码可以还原出图灵机。一个简单的方式是我们先编码一些设定（字符集大小，纸带数量），再按顺序编码转移函数。

现在我们就可以准备同时用一个 $01$ 串来表示对应的图灵机 $M$。但还有一些小细节：可能有的串不能被我们的编码得到，此时可以认为所有不合法的串对应一个平凡图灵机：直接输出 $0$ 然后停机。还可以注意到每个图灵机都有无限个串表示它。感性理解很对，也可以用 ex15。

然后就有一些好玩的东西：

#### Universal Turing Machine

我们在 sys 课上学到一个通用的 cpu 可以运行任何程序。对于图灵机我们也有相同的结论（当然这个结论比通用计算机早多了）：存在一个通用的图灵机可以运行任何图灵机。具体来说，存在一个图灵机 $U$ 使得 $\forall M,a, U(M,a)=M(a)$。

##### A naive construction

task1：构造这样的 $u$，使得如果原先图灵机解决问题的复杂度是 $T(n)$，那么现在不超过 $O(T(n)^2*c)$。这里 $c$ 是只和目标图灵机纸带数，字符集大小相关的常数。

构造：考虑先把 $M$ 的一堆纸带合并到一条纸带上，这一步类似之前的方法。然后考虑先解码，然后把函数放到一条纸带上，再用一条纸带记录状态。每次先扫出需要的转移，再扫纸带更新。每一步需要扫一轮所以是平方。

##### A smart construction

(**)task2: 同 task1，但是限制变为 $O(cT(n)\log T(n))$。

高明的构造：我们考虑把字符集扩充为 $\Gamma^k$，这是容易模拟出来的（也可以做到不需要事先知道 $k$，后面的状态也可以稍微处理一下）。但问题是我们需要每条纸带的 head 能分别移动，这在合并后是不受支持的。一个 naive 的想法是我们不移动头，而是平移纸带（造电路就可以这样造），但naive地做需要 $O(n^2)$ 复杂度。

但可以发现一些很好的处理方式：我们可以放一些空位，这样每次移动就不需要移动所有东西。但我们需要思考怎么处理这些空位。然后有一个极其高明的构造：

考虑用双向纸带，根据之前的某问这只需要多常数倍时间。考虑在两侧依次分出 $2^0,2^1,2^2,\cdots$ 长度的组，然后我们要求两侧每一对 $2^i$ 组中每个组内空位数量占比是 $0,\frac12,1$ 中的一个(?)，且加起来正好是 $2^i$。为了达到初始条件，我们可以让第一次扩展到某一段时空位和非空交替填（这里原来的空位和我们这样加进来的空位是区分的），这容易处理。然后考虑如下操作：

如果我们要向左移动，考虑往左找到第一个左侧 $2^i$ 不是满的部分，然后考虑把之前每一个满的 $2^{i-1}$ 进位到下一个 $2^i$ 的一半，这是合法的。这样就把一个数放了进去。右侧相当于找到了第一个不是空的部分，那么考虑退位一个 $2^{i-1}$ 下来每一部分填一半，最后的 $1$ 移到中心。可以发现这样两侧操作对称，不违反我们的限制。（！!1）

可以发现移动一位后更小的段都是半满，那么容易看出第 $i$ 段只会 $c*2^i$ 次操作后影响到一次。那么复杂度就是 $\sum_i 2^i*\frac T{2^i}=O(T\log T)$。显然多个纸带的移动不影响情况。

(0.7*) ex9: 做到 oblivious 只需要 $O(T\log T)$ 的步数。

证明：考虑拿这个构造去模拟，但它显然不直接是 oblivious 的。

考虑我们实际上干了啥，考虑左边每一层的大小，相当于一个二进制数，但现在每一位可以取 $0,1,2$ 中的一个。我们希望这样的 $\sum c_i2^i$ 可以快速支持加一和减一（修改第 $i$ 位的代价是 $2^i$）。之前的做法是暴力平衡，但这不 oblivious。那么考虑每次固定修改到某一位，直观地想我们可以第 $i$ 次修改到下 $lowbit(i)$ 位，为了以防万一这里加个 $O(1)$。我们希望这次操作我们可以通过调整第 $i$ 位和更低的位使得再过 $2^i/4$ 次操作无论发生什么都不会改到之前的位。考虑这样操作：求出当前下面总和是多少，然后调整这一位取值让剩下的尽量接近 $2^i$。那么只要一开始这里的和不太极端（小于 $\frac12$ 或者大于 $\frac72$ 倍 $2^i$），往下都能做到距离 $2^i$ 不超过 $2^{i-1}$。下一位操作前我们需要再过 $2^{i-1}/4$ 次操作，可以发现这些操作后下一位也达不到过于极端的界限。那么我们这样分后下面一定不会去世。然后考虑实现每一步我们的这些逻辑。加法器很难直接 oblivious，但这里我们只操作最高位，所以进位可以直接放进状态，拿个图灵机当栈扫一下就完事了。还有一部分是移动这么多数，考虑先正着扫一遍进位，再倒着扫一遍退位。相邻位进 $O(1)$ 的量可以把控制读到状态里面，然后每一对 $2^i$ 大小的组扫一遍视情况看要不要复制。



还有更有趣的事：如果我们把图灵机喂给自己，会发生什么？

#### Uncomputable functions

我们希望图灵机有很强的计算能力，但事实并不总是那么令人满意。

##### UC

考虑这样一个函数：$UC(M)=1$ 当且仅当 $M$ 代表的图灵机在接受 $M$ 为输入时输出 $0$，如果不停机/输出 $1$/输出一大堆东西则值都是 $0$。

那么如果有一个图灵机 $M_1$ 能计算 $UC$，考虑 $M_1(M_1)=UC(M_1)$，但如果 $UC=1$ 那么 $M_1$ 必定输出 $0$，如果 $UC=0$ 那么 $M_1$ 不可能输出 $0$，矛盾。因此 UC 不可能被任何图灵机计算。

note：这一技巧将会在接下来占据一整个章节

##### Halt

最经典的停机问题：输入一个图灵机 $M$ 及其输入 $a$，判断是否停机。

考虑规约：如果我们证明 $UC\leq HALT$，那显然 HALT 无法计算。具体来说，考虑如下方式：对于要求计算 $UC(x)$ 的情况，我们先拿 HALT 跑出是否停机，如果不停机直接返回 $0$，否则拿之前学到的通用图灵机跑出结果。那么只要我们能算 HALT 我们就能算 UC。

##### Rice's Theorem

(0.9*) ex15: 我们之前考虑图灵机计算函数时只考虑了一定停机的情况，现在我们考虑一个扩展定义：我们在判定性问题下考虑，称一个部分函数是 $\{0,1\}^*\to \{0,1,*\}$ 的函数；我们称 $M$ 计算了这样一个 $f$，指 $M(x)$ 不停机当且仅当 $f(x)=*$，且其它情况 $M$ 计算了 $f$。显然每个图灵机会计算一个这样的函数，我们称两个图灵机等价，当且仅当它们计算了相同的函数（但显然不是所有函数都可计算！）。考虑这样一个函数 $f_S$：给定一个图灵机的集合 $S$（可以无限大），对于一个输入 $M$，我们返回 $1$ 当且仅当 $M$ 和 $S$ 中某一个图灵机等价。证明对于任意非平凡的 $S$（平凡指空集或者全集，全集在等价定义下考虑），$f_S$ 不可计算。换言之只要 $f_S$ 不是全 $0$ 或全 $1$，则其不可计算。

证明：考虑规约停机。可以发现一个有趣的构造：我们拿一个 $S$ 中的图灵机 $M_1$，然后考虑通过如下方式解决停机问题：我们先把 $HALT_{M,a}$ 中的图灵机和输入复制下来（输入复制到一条新的纸带），然后先模拟跑这个，如果这个图灵机跑到停机我们就立刻开始跑 $M_1$（状态转换容易实现）。那么如果原问题停机我们的输出就是 $M_1$，否则输出全部不停机。考虑把这个喂给 $f_S$，那么只要 $S$ 不包含全部不停机的函数 $f$ 我们就解决了停机问题。

然后考虑另一种情况，如果 $S$ 包含这个，但不包含某个图灵机 $M_2$，那么可以发现像刚才那样接还是对的。还有更直接的说明方式：可以发现 $S$ 取补集只是输出取反，那取个补集就行了。



Note: 这里的 Uncomputable 只是针对图灵机而言的。事实上如果换一种模型我们还是有希望的，这在接下来的某一章可能会讲到。

#### Deterministic Time

现在我们来正式地定义时间复杂度。

在这里和下面的很多章节，我们只考虑判定性问题。对于这样的问题，我们有一种描述方式：考虑将所有输出 $1$ 的输入看成一个集合 $L$，显然 $L$ 可以完整地描述问题。我们称 $L$ 是一个语言，它也对应一个判定性问题。显然用一个集合表示比用文字描述问题更根本。

我们现在考虑的图灵机是确定性的，因此我们可以定义如下确定性时间复杂度的复杂度类：

称一个问题属于 $DTIME(T(n))$，当且仅当存在一个计算它的图灵机复杂度不超过 $c*T(n)$。

然后我们就可以定义众所周知的东西：$P=\cup_{k\geq 0}DTIME(n^k)$，直观看就是确定性多项式算法。

ex16-17：一些显然在 P 里面的东西。

这里还有一些小问题：图灵机的纸带数并没有被限制，但根据之前的结论换纸带数需要 $f(k)*\log$ 的代价；还有字符集大小的问题。好消息是这对 $P$ 显然不影响，大部分时候我们也只关心指数大小或者是否 $\in P$。但这在一些时候也会影响结果。更多的讨论留到第三章进行。

#### More Than Decision?

$P$ 只考虑最坏情况复杂度，且必须要求精确解。所以接下来会有一些部分讲近似算法和平均复杂度，但这看起来又是chernoff小练习。

$P$ 只考虑判定问题，虽然大多数时候我们都可以直接转成判定问题，但专门考虑计数的复杂度类也会被讲到。

我们的图灵机是确定性的，但我们还有 random.hpp，还有量子计算机；所以接下来会有一部分讲随机算法和 $BQP$。

但很多情况下，这就够了。









### II Nondeterministic Polynomial Time

我们继续考虑判定性问题。

#### NP and the verifier

一个常见的定义：NP是可以在多项式时间内验证的问题集合。

更严谨地，一个语言属于 NP，当且仅当存在一个多项式 $p(n)$（限制证明长度）和一个验证器 $M$，使得 $f(x)=1$ iff. $\exists prf\in \{0,1\}^(p(|x|)), M(x,prf)=1$。

常见地证明是给一个 poly 大小的解。

prop1: $P\subset NP$

证明：$M$ 忽略证明直接算就行。

prop2: $NP\subset \cup_k DTIME(2^{n^k})$

证明：直接搜所有证明。

ex5：显然，输入某一个的证明或者同时输入两个的证明即可。

#### NP and the Non-deterministic Turing machines

这才是 NP 这个名字的来源.jpg

我们考虑一个非确定性图灵机，这里有一个非常好的定义：

一个非确定性图灵机有两个转移函数，每个时刻它随机选择一个函数转移。它有一个（表示拒绝的）停机状态和一个接受状态，两者都会导致停止。然后我们称这样的 NDTM 计算了一个 $01$ 函数 $f$，如果 $f(x)=1$ 当且仅当输入 $x$ 时 NDTM 可能能接受它。

我们可以类似地定义非确定性时间复杂度：如果它在 $c*T(n)$ 后必定停机，那么这个复杂度被认为属于 $NTIME(T(n))$。

可以发现这两个定义是等价的：

lemma: $NP=\cup_{k\geq 0}NTIME(n^k)$

证明：考虑双向规约。如果属于 NTIME，那么把每一步选择的函数下标写下来当成 proof，然后扔给一个确定性通用图灵机模拟。

如果属于 NP，我们有一个直接的规约方式：考虑先用非确定性的步骤把证明写下来，然后后面全部跑确定性步骤。

对于非确定图灵机，我们有通用图灵机的推广：非确定性通用图灵机。具体来说它可以读入一个非确定性图灵机，它有概率输出 $1$ 当且仅当原问题能输出 $1$。

ex1a: 如果我们用上一章 $T\log T$ 的构造，我们就可以类似得到 $O(T\log T)$ 乘一个图灵机相关常数的算法。但这里还能更优：

(0.7*) ex1b：证明我们可以找到一个非确定性通用图灵机，其可以 $O(cT)$ 模拟任意非确定性图灵机。

证明：考虑用 verifier，然后我们可以先随机出输入，这样我们只需要模拟一个确定性图灵机。但这样直接做还是一个 $\log$。注意到我们不只可以随 proof，考虑一些激进的方式：直接把状态和每一步选择的转移枚举出来，接下来只需要验证这些转移是否合法。直接看验证好像还是要维护多带，但可以发现实际上可以每条带分开判定合法（因为转移都被枚举了）。然后每条带依次模拟一下看是否满足转移条件即可。

#### Polynomial Karp Reduction

我们来考虑 $NP$ 中的规约。我们有一个更精确的定义：

Def. 我们称语言 $L_A$ 能规约到 $L_B$，当且仅当存在一个可以 poly 计算的函数 $f$，使得 $L_A(x)=L_B(f(x))$（这里表示是否属于语言），即 $f$ 可以把 $L_A$ 问题上的输入转为 $L_B$ 问题上的输入。如果满足这一条件则我们称 $L_A\leq_p L_B$。

**注意**：这一定义不等价于说我们可以调用一次解决 $L_B$ 问题的 oracle。

**注意**：这一定义不等价于说我们可以调用一次解决 $L_B$ 问题的 oracle。

**注意**：这一定义不等价于说我们可以调用一次解决 $L_B$ 问题的 oracle。在接下来的某个地方我们会看到区别。（跳转 coNP）

如果 $\forall A\in NP, A\leq_p B$ 则我们称 $B$ 是 NP-hard 的，如果它还属于 $NP$ 那我们称它是 NP-complete 的。

根据这个定义显然 $\leq_p$ 有传递性：给函数复合一下。同时显然有如下结论：

如果 $A$ 是 NPC 的，那么 $A\in P$ 当且仅当 $P=NP$。

证明：一个方向显然，另一个方向直接规约。

ex3：证明 HALT 是 NP-Hard。然后它显然不在 NP 里面，不然它可以被 DTM 计算。（NP in EXP）

证明：考虑外侧循环枚举输入然后跑确定性验证，如果验证出 false 就继续，否则跑死循环。然后把这个交给 halt。

ex4：刚刚就证明了

(*) ex13：我们称一个语言是 unary 的，当且仅当它只包含全 $1$ 串。证明：如果某个 unary 语言 $L$ 是 NP-Complete 的，那么 P=NP。

证明：考虑条件是啥意思。根据 Karp 规约，这相当于对于每一个 NP 问题 $A$ 和一组大小为 $n$ 的输入，我们可以通过一个 poly 算法将其转换为 $L$ 上的一个输入，即一个大小不超过 $p(n)$ 的数；原问题答案是 Yes 当且仅当这个数的答案是 Yes。我们无法知道这个数的答案是啥，但利用这个数我们已经可以解决问题了：

注意到 SAT 填了一个变量还是个 SAT，考虑依次填数，每填一个就问一次当前对应的数是啥。然后我们记录 $f_{n,k}$ 表示是否已经搜过一个大小为 $n$ 且对应数为 $k$ 的状态，显然搜过一次下次就不需要再搜这种状态了。（这里放一个 $n$ 是为了避免阻挡）那我们的复杂度就变成 poly 了。

#### NP-Completeness

众所周知，如果我们定义了一个东西但它实际上不存在，那这就没有意义。好消息是我们确实存在这样的问题。

##### TMSAT

定义 TMSAT 为如下形式的问题：给定图灵机 $M$ 和输入的一部分 $x$，再给定输入 $1^n,1^t$（这相当于一种 padding，从而将输入规模强行提升到 $n+t$ 级别。这样的 padding 在之后也会用到），判定是否存在一组长度为 $t$ 的输入 $y$ 使得 $M(x,y)$ 在 $n$ 步内停机。

ex2：证明这是 npc 的。

证明：显然这东西可以表示任意一个 verifier，那么它是 NP-Hard 的，然后拿通用图灵机显然可以验证它的解。

##### CNF-SAT

定义：我们有一堆01变量 $x_i$，一个 literal 是 $x_i$ 或者 $!x_i$，一个 clause 是一堆 literal 的或，一个表达式是一堆 clause 的与，求是否有解。

这显然是 NP 的，因为可以验证。通过图灵机我们也可以证明它是 complete 的。

证明：根据上一章的推导，我们可以只使用一条输入+一条工作纸带，并且可以认为我们的图灵机是 oblivious 的。然后我们直接设每个格子上每个时刻的状态，读写头的位置确定后这东西怎么向后转移是容易的：在读写头上把图灵机的函数写成一堆 clause，别的地方不变所以甚至可以直接缩点。输出也容易处理。

甚至这里也可以不用 oblivious，我们让纸带动即可（虽然多个平方）。但原来这个做法的好处是我们最终得到的大小只有 $O(t\log t)$（拿出ex1.13） 乘上一些与图灵机复杂度相关的常数，这可能会有用。

这个规约还有一些很好的性质：我们可以将一侧问题的解自然地变为另一侧问题的解(Levin)，同时这还是一个一一对应(parsimonious)。事实上很多规约都满足这一条件。有时这是有用的，比如 #P。

ex11a：容易。

##### 3-SAT

定义：和之前几乎一样，但是每个 clause 大小为 $3$。容易证明小于 $3$ 的 clause 不改变情况，因为我们可以手玩造点常数出来。

证明：如果有很长的 clause，我们可以模拟依次 $\or$ 过去的过程，显然任何一个二元逻辑门都可以枚举真值表写成 3SAT。

ex10：证明任何一个 NP 问题都可以规约到 $O(T\log T)$ 大小的 3SAT。

证明：拿出线性的 TMSAT，然后直接像上面那样构造。显然 CNF-SAT 可以直接线性变成 3SAT。

ex11b：找到一个 CNF-SAT 到 3SAT 的规约使得方案数不变。

证明：考虑顺序取并，要求必须取到并就可以确保唯一了。或者就是那个直接的构造。

然后我们就可以开始大力规约了：

##### Independent Set

众所周知。可以看上一周目。

##### Integer Programming

显然可以描述 3SAT。

##### Directed Hamiltonian Path

经典构造。可以看上一周目。

##### Clique and Vertex Cover

ex14: 显然都是独立集，一个是取反边集，一个是取反点集。

##### Max Cut

(0.2*)ex15: 考虑从独立集过来。建一个点 $s$，$s$ 一侧表示不选。每个点向 $s$ 连边。然后对于每条边 $(x,y)$ 来一个 $s-a,a-x,a-y,x-y$，手玩可以发现除了都选分数是 $2$，其它分数都是 $3$。那么现在相当于选每个点有 $1$ 的收益，但导出子图每有一条边就有 $1$ 的代价，从而存在一个最优解选出的是独立集。当然如果想让每个最优解都是可以造两个 $a$ 搞一搞。

##### ExactlyOne 3SAT

(0.3*)ex16a: 注意这里不是方案数 $1$（看起来有 coNP 难度，但我证据不足），而是说每个 clause 正好有一个位置被满足。

考虑从 3SAT 过来，这里容易造一个取反（容易手玩出 $0$ 和 $1$），然后考虑造类似加法器的东西，可以发现如下构造：$(a,x_1,x_2),(b,x_3,x_4),(x_2,x_3,t)$ 可以把加法高位取出来（如果高位是 $1$ 那么必定 $1$，否则都可以），那么两两加再三个 $t$ 放一起即可。

##### Subset Sum

ex16b：一万种规约方式。

就像上一周目说过的那样，尝试解 NPC 问题并不是完全无用：我们还有平均复杂度，近似……这些在之后会提到。

##### (directed/undirected) Hamiltonian (path/cycle)

ex17: 可以看上一周目。

##### Quadratic Equations

ex18: 有一堆 $01$ 变量，给一堆 $\sum x_ix_j\equiv a\pmod 2$ 的限制，问是否有解。

证明：考虑拉 3SAT，直接搞看起来有点麻烦，可以发现搞 ExactlyOne 会简单一些：先两两求和去掉 $2,3$ 个的情况，然后考虑手搓一个 $1$（容易做到）单向连边去掉 $0,2$ 就行了。



#### Do we need the solution?

我们对 NP 的定义只是需要回答是否存在解，但实际情况中有时我们还需要构造解。显然构造解的问题直接包含判断是否有解。但我们有如下结果：

如果 P=NP，那么对每个 NP 中的语言 $L$，在给定 verifier 后存在一个多项式复杂度的图灵机可以对于每个答案为 Yes 的输出给出它的一组 proof。

很 OI style 的证明：考虑逐位确定，每填一位后的问题都是一个 TMSAT，然后就搞完了。

#### Introduction to Some Other Classes


##### coNP

定义一个语言属于 coNP，当且仅当它的补集属于 NP。

换一个角度看，我们相当于把 $\exists$ 一个 proof 改成了 $\forall$ proof，这样在等会可以得到PH。

严谨地说一个语言 $L$ 属于 coNP，如果存在多项式 $p$，$x\in L$ 当且仅当 $\forall a\in \{0,1\}^{p(|x|)},M(x,a)=1$。

ex20：证明这两等价。

证明：平凡。

如果 P=NP 那么容易得到 coNP=P，所以 $NP\neq coNP \rightarrow P\neq NP$。

一个 coNP 的例子：给一个 SAT，问是否所有输入都使其值为真。这里称这个问题为 coSAT。

lem. coSAT 是 coNP-complete 的。

证明：考虑任意一个 coNP 问题，输出取反后可以规约到 SAT，再取个反就是 coSAT。那么按照 Karp 规约的方式，我们把原来的那个函数直接拿过来用就行了。

ex7：证明如果 3SAT 和 coSAT 可以规约，那么 NP=coNP。

证明：根据这个定义规约可以传递，那么所有 coNP 都可以规约到 SAT。那么造一个图灵机先确定性处理规约，然后跑 SAT，它就 NP 了。

在定义 NP-Hard 时，我们选择了 Karp Reduction，或者说一个语言的映射。而不是直观意义上的那种规约（如果我们能 poly 做 f，我们就能 poly 做 g）（Cook Reduction），即我们可以调用 poly 次 oracle。尽管在 P vs NP 上它们之间似乎没有区别，但情况却并不总是如此：

ex12：在 Cook Reduction 下，3SAT 可以规约到 coSAT。

证明：调一次 oracle 然后取反输出。

我们看起来得到了 NP=coNP，那问题出在了哪里？考虑 ex7 证明的最后一句话，用这个规约的话，相当于任何一个 coNP 问题都可以在跑出一个 SAT 后翻转答案得到解，但这就不等价于一个 NP 问题。

为什么会不一样？一种解释是 Cook 的规约只考虑能不能 poly 做，我们已经证明了如果 P=NP 那么 NP=coNP，所以会有这一结果。但如果我们假设 $P\neq NP$，那我们实际上可以有更多的复杂度类别。

ex19：证明 $P\in NP\cap coNP$。

证明：拿 verifier 就行。

ex21：如果 $L_1,L_2\in NP\cap coNP$，那么 $L_1\oplus L_2$ 也属于，这里相当于集合异或。

证明：可以发现 $\lnot L_i$ 也是 $NP\cap coNP$ 的，那么我们可以把两个 proof 接起来证明 $x\in L_1,x\not\in L_2$ 和另外四种情况，然后就容易构造两个方向的 verifier。

ex22：平凡


##### EXP and NEXP

定义 $EXP=\cup_k DTIME(2^{n^k})$，NEXP 同理。

有如下结论：

如果 P=NP 则 EXP=NEXP，因此逆否命题也成立。

证明：如果 P=NP，那么对于任意一个 NEXP 问题，考虑往问题上加 $2^n$ 个 $1$，此时可以发现问题属于 NP，因为 NDTM 的复杂度不太受padding影响。那么 pad 之后问题属于 P，进而原问题就属于 EXP。

ex8：我们也可以用 verifier 的方式定义图灵机，证明就和之前那个类似，唯一的区别是现在 proof 是指数的，原输入是 poly 的，那可以随便限制一下 verifier 是 poly 或者 exp 于原输入的。

ex9：构造一个 NEXP-complete。

Sol：有了ex8后容易想到和之前类似的构造：考虑 TMSAT，把输入的 $n,k$ 换成二进制表示。那么每个 verifier 都可以变成这样的问题（指数步数变成了 poly 输入），同时这个问题显然 NEXP。

ex23：证明如果任何 unary NP language 属于 P，那么 EXP=NEXP。

证明：类似 padding，把 NEXP 问题的输入 unary 化，然后一个 NDTM decode后跑 NEXP 就是 NP 的；因此它属于 P，然后就做完了。可以发现 ex13 也能推出 EXP=NEXP，但这两的前提完全相反。



### III Diagonalization

高难度证明警告 ~~这章的Thm都巨大难，所以exercise也是~~

从这里开始，exercise 使用 final version 里面的。

我们在第一章已经遇到了一次这样的技巧，这里我们会进一步探索这个技巧的极限。

recap：每个图灵机可以看成一个 $01$ 串。如果我们只考虑判定问题，可以认为每个图灵机在每个 $01$ 串的输入上会输出一个 $01$ 值或者其它情况（没停机, etc）。$01$ 串是可数的，那么我们可以把图灵机和输入得到输出的过程看成一个矩阵，第 $i$ 行第 $j$ 列表示 $M_i$ 输入 $j$ 的结果。之前的 Diagonalization 则是说，如果我们把这个矩阵的对角线取反得到一个序列（即之前的 not $M_i(i)$），那么它显然和任何一行不同（因为相交位置的不同）。另一个不tcs的常见例子是证明实数不可数的翻转对角。

我们可以进一步使用这一技巧。接下来是一些很强的结果：我们可以证明一个 class 严格包含另一个，这在复杂度理论里通常是特别难完成的任务。

#### Deterministic Time Hierarchy

Thm. 如果两个复杂度函数（要求 time-constructible，见ch1）$f,g$ 满足 $f(n)\log f(n)=o(g(n))$，则 $DTIME(f(n)) \subsetneq DTIME(g(n))$ ~~现在我们就可以证明 $P\neq EXP$~~

Prf. 为了简便，考虑一个函数 $h(n)$ 使得 $f(n)\log f(n)=o(h(n)),h(n)=o(g(n))$。然后我们考虑这样一个图灵机：

对于输入 $x$，我们用一个通用图灵机（UTM）的方式模拟 $M_x$ 输入 $x$ 的过程，如果这一过程使用不超过 $h(n)$ 步停止，则我们输出它的相反数，否则我们强行掐断然后随便输出一个数。

直观上看，对于一个 $DTIME(f(n))$ 内的图灵机 $M_i$，它在 $i$ 上的过程可以被 UTM 在 $O(f\log f)$ 步内模拟，然后它就和我们的图灵机不一样了。但常数还是一个问题。好消息时我们不需要引入额外处理步骤，因为：

recap from ch1：每个图灵机都被无限个 $01$ 串表示。

坏消息是我们的 $c*f\log f$ 里面 $c$ 和图灵机有关，好消息是我们可以找到一些表示 $M$ 的图灵机使得它们的 $c$ 不超过某个定值：比如我们可以规定往表示后面里面随便填 $0$ 不改变图灵机。（虽然这样实际上就和改变枚举顺序依次枚举长度不超过 $1$ 的，长度不超过 $2$ 的，etc一样了）。那么随着串长增加，总有一个时刻 $cf(n)\log f(n)<h(n)$，然后就不一样了。

(0.1*) ex4a：我们称 class $A$ is superior to class $B$，如果 $A$ 中存在一个图灵机 $M_1$，其对于每个 $B$ 中的图灵机 $M_2$ 都满足对于任何足够大的 $n$，存在一个长度在 $[n,n^2]$ 中的输入使得 $M_1,M_2$ 输出不同。证明 $DTIME(n^{1.1})$ is superior to $DTIME(n)$。

Prf. 之前构造的一个小问题是，虽然每个 $i$ 都被无限个串表示，但它们之间的距离可能很大。好消息是往后面加 $0$ 不会出现这种情况，所以搞定了。

#### Deterministic Space Hierarchy

Thm. 同样有 $f,g$，如果 $f(n)=o(g(n))$，那么 $DSPACE(f(n))\subsetneq DSPACE(g(n))$。

Prf. 和刚才一样，唯一的区别是 UTM 可以只使用常数倍空间（显然）。

#### Nondeterministic Time Hierarchy

考虑把之前的结论搬到 $NTIME$ 上。好消息是ch2证明了 NDUTM 是线性的，但坏消息是现在我们完全不能把 output 翻转：翻转 $\exists f(x,p)$ 不能得到另一个 $\exists$。如果我们暴力模拟则需要指数级的时间。

这时有一个高(ha)明(rd)的技巧：我们不直接翻转，而是考虑把大小 $n,n+1$ 的问题连接起来，连出一个指数级大小的东西再翻转：

Thm. 如果 $f(n+1)=o(g(n))$，那么 $NTIME(f(n))\subsetneq NTIME(g(n))$。

Prf. 为了简便，考虑让我们的 $M$ 忽略全 $1$ 输入外的所有输入。（我们需要让它不被 $NTIME(f)$ 计算，那么我们加限制显然没问题）直观的想，如果我们想让 $M$ 和某个复杂度 $f$ 的 NDTM $M_i$ 在 $[c,+\infty]$ 上有一个不同，考虑让 $M(1^c)$ 去模拟 $M_i(1^{c+1})$（这就是为什么那里有个 $+1$！!1）。

如果我们一直这样模拟，那么如果 $M=M_i$ 则它们在 $1^c,1^{c+1},1^{c+2},\cdots$ 上的输出必须全部相等。这样我们就可以做指数复杂度的翻转：找到一个 $2^c$ 级别的位置，在这个位置搜 $M(1^c)$ 的所有非确定性输入，这样就可以翻转了。

具体来说，我们还是找一个夹在中间的 $h$，然后令 $c_1=1,c_i=2^{h(c_i)}$。对于每个 $i$，我们对 $M_i$ 在 $[c_i,c_{i+1})$ 上做上面的事情。然后就做完了。

这里本来有一张好看的图片，但是我不想搞图片了。

(**) ex4b：我们称 class $A$ is superior to class $B$，如果 $A$ 中存在一个图灵机 $M_1$，其对于每个 $B$ 中的图灵机 $M_2$ 都满足对于任何足够大的 $n$，存在一个长度在 $[n,n^2]$ 中的输入使得 $M_1,M_2$ 输出不同。证明 $NTIME(n^{1.1})$ is superior to $NTIME(n)$。

Prf. 之前的证明完全不行，因为我们用了指数级的长度去规约。考虑用多项式长度规约。首先我们可以相信同时规约多个图灵机不是大问题，因此先只考虑一个 NDTM 的情况。显然要翻转我们必须枚举所有 random string(好消息是这东西长度是线性的)。那么考虑找到一个 $n^{1.01}$，在这个长度确定性模拟 $M_i$ 输入前 $n$ 个字符然后剩下的作为非确定性输入的结果然后翻过来。然后考虑全部合并。直接的想法是二叉树。坏消息是如果自己这样搞 $n$ 层就指数了，但好消息是有一个确定大小的 $M_i$ 希望和我们相同，那么有如下结果：

如果当前串 $s$ 长度在 $[n,n^{1.01})$ 之间，则我们模拟 $M_i$ 在 $s+0,s+1$ 上的输出，然后取一个 $\land$（从 NDTM 看起来不太直观，但从 proof 上极其直观，见上一章的某个exercise）。如果到了 $n^{1.01}$ 就用之前方式反转（和之前一样，跑不完就掐断）。

如果 $M_i$ 在中间和我们都一样，那么我们在 $s$ 上求出的就是我们在 $s+0,s+1$ 上是否都是 $1$，进一步我们求出了所有 $s+t$ 是不是都是 $1$。（直接分析是指数的，但我们通过 $M_i$ 解决了问题。）那么这样我们就完成了反转，且只用了 $n^{0.01}$ 的长度区间。

然后考虑多个图灵机。每个串占 $0.01$ 看起来也不是问题，具体来说我们仍然考虑一轮一轮地做，第 $i$ 轮安排一次所有长度不超过 $i$ 的图灵机，安排的时候把 $i$ 放到输入的前缀（显然这不影响之前的过程），然后我们就会模拟了。具体的输入就是一个 $(M,input,random)$ 的形式。然后每一轮是一个 $[n,n^{1.01}]$，一个图灵机足够大了之后每轮都错。


#### Nondeterministic Space Hierarchy

我们将会知道 $NSPACE(f(n))\subset DSPACE(f(n)^2)$，然后抄一个上述证明我们就能得到类似的结果。当然这里好像有更标准的证明方式。

这个定理的证明可以参考下一章。

除了 Hierarchy Theorem，还有一些分离复杂度的技巧也被放在了这里：

#### Ladner’s Theorem

Thm. 如果 $P\neq NP$，那么存在一个 $NP$ 问题既不属于 $P$ 也不是 $NP-C$。我们称之为 NP Intermediate Problems。

(hard+) Prf. 考虑 Padding argument:把 SAT 的输入扩展到 $n^{H(n)}$，得到一个问题 $SAT_H$。一方面我们希望 $SAT_H\not\in P$(assuming $P\neq NP$)，这相当于我们不能 pad 过多。

另一方面我们希望它不是 NPC 的。注意到如果它是 NPC 的，那么任何 SAT 问题可以被规约到一个 $n^c$ 的 $SAT_H$ 问题。但我们把 padding 拿掉就变成了一个 $n^{\frac c{H(n)}}$ 的问题。如果 $H(n)\to +\infty$，那么对于足够大的 $n$，我们可以每次规约让大小开根（也可以是别的变换），那么大的 $n$ 都可以通过连续规约变到一个固定大小的问题然后暴力，从而 $SAT\in P$。然后就矛盾了。

那么我们希望找到一个 $H$ 趋向 $\infty$，但又不能太快。然后有神奇的构造：

我们定义 $H(n)$ 为最小的 $i\leq \log \log n$ 满足它($M_i$) 能在 $ix^i$ 的复杂度内计算所有长度不超过 $\log n$ 的 $SAT_H$ 问题。如果不存在则设为 $\log\log n$

这个构造看起来非常奇怪：它甚至是一个递归定义。但可以发现这个性质是我们所需要的：如果 $SAT_H\in P$，那么存在一个 $c$ 使得我们可以 $cx^c$，又因为图灵机有无限个表示，我们可以找到一个 $i$ 使得它能在 $ix^i$ 算所有问题，那么 $H$ 就不超过一个常数。但常数 pad 的话 SAT 就可以规约到这个问题，这就寄了。

那么 $SAT_H\not\in P$，因此每个 $M_i$ 都不能在 $ix^i$ 内正确计算所有函数。因此对于任意一个 $i$，一定存在一个 $n$ 使得 $\geq n$ 后 $1,\cdots,i$ 全错，那么 $H\to +\infty$，然后它就不可能是 NPC。

证明非常震撼，但我不太明白为啥会放到这。

ex6：上述证明的细节

#### Oracle machines

我们在之前提到了 Cook reduction，并说这可以看成一个 $P$ 的程序可以调用 $NP$。这里我们给这种东西一个严谨的定义。

对于一个语言 $O$，我们称一个包含 Oracle $O$ 的图灵机为在普通图灵机上加上如下修改的结果：这个图灵机有一条特殊纸带，它可以往纸带上写东西；图灵机还有一些特殊状态，当跑到 $q_{start}$ 时，我们会通过某些魔法（神谕）得到特殊纸带上的东西是否属于 $O$（例如这一步之后可以跳转到状态 $q_{yes},q_{no}$ 中的一个），这只使用一步操作。

然后我们可以定义 $P^O$ 表示所有能被某个多项式复杂度确定性图灵机（带有 oracle O），别的class也可以类似定义。作为例子，这里有一些小结论：

1. coSAT$\in P^{SAT}$。 | 证明：跑一遍反转。
2. 如果 $O\in P$ 那么 $P^O=P$。 | 证明：我们可以模拟。
3. 定义 $EXPCOM$ 为如下 oracle：输入 $M,x$ 和 $n$ 个 $1$，求 $M$ 输入 $x$ 时能否在 $2^n$ 步内停机并输出 $1$。那么 $P^{EXPCOM}=NP^{EXPCOM}=EXP$。

证明：显然这个 oracle 都能算指数级了，EXP随便跑。所以显然 $3\subset 1\subset 2$（$1\subset 2$ 是直接的，虽然 $A\subset B$ 不一定代表 $A^P\subset B^P$，因为我们定义 $^P$ 的时候需要用到下面图灵机的性质）。另一方面，我们容易 EXP 地模拟 $NP^{EXPCOM}$，那么它们全部相等。

(0.2*+) ex8: 考虑如下 random unary oracle：对于每个 $n$，我们以 $\frac 12$ 的概率往里面塞一个长度为 $n$ 的随机串。证明有高概率 $P^B\neq NP^B$.

Prf. 考虑问有没有长度为 $n$ 的随机串，那么 $NP^B$ 可以直接随，$P^B$ 不可能 poly 次搞对。（严谨证明不会测度咕了）

(0.5*) ex9：考虑完全的 random oracle：每个串有 $\frac 12$ 的概率存在。证明有高概率 $P^B\neq NP^B$.

Prf. 考虑如下问题：给定 $n$ 个 $1$，问你能不能找到高 $n-\log n$ 位使得低位无论怎么填都是 $1$。这又是一个 $NP$ 随便猜的问题，同时有解概率是接近 $\frac 12$ 的所以 $P$ 很难对。

#### relativize and the limits of diagonalization

回到 Diagonalization 本身，可以发现它只需要两点性质：

1. 图灵机能被 01 串表示。（我们并不强行需要每个 $M$ 有无数个表示，因为我们可以用一些高超的枚举顺序，例如依次枚举长度不超过 $1$ 的，长度不超过 $2$ 的，etc）
2. 我们可以拿图灵机模拟另一个图灵机。

可以发现 $^O$ 不影响这些性质。（构造 UTM with oracle 是容易的）

我们称这样的性质是 relativizing 的，即它们不随 $^O$ 改变。那么 diagonalization 本身是 relativizing 的，即上述所有 hierarchy theorem 对于任意 $^O$ 仍然成立。（例如我们可以有 $DTIME(n)^{EXP}\subsetneq DTIME(n^2)^{EXP}$，虽然这看起来极其抽象）

但另一方面，这一方法的结果一定满足这一性质，那么不满足这一性质的结果一定不能被 relativizing 的方法证明。正如下面这样：

Thm. 存在 orcale $A,B$ 使得 $P^A=NP^A,P^B\neq NP^B$。

Prf. 刚才已经证明了 $A$ 的部分，现在考虑 $B$。

考虑这样一个问题：给一个 oracle $B$，输入 $n$ 个 $1$，判断 $B$ 是否接受一个长度为 $n$ 的串。那 $NP^B$ 显然能做这个问题：随一个串直接交。

然后我们希望 $P^B$ 做不了这件事。直观上看这确实是对的：我们只能问 poly(n) 个东西，这对于在 $2^n$ 里面找一个位置显然是困难的。具体来说，我们可以得到如下构造：

我们仍然考虑依次安排掉每一个 $M_i$。在考虑到 $i$ 时，我们记之前已经询问过的最长串长度为 $n-1$，然后我们让 $M_i$ 跑 $1^n$，跑 $2^n/10$ 步如果还不停就掐断。这中间如果它问更小长度的串我们正常回答，问长度大于等于 $n$ 的就回答 $0$。如果 $M_i$ 正常返回了，那么如果它返回 $1$ 我们啥都不干，如果它返回 $0$ 我们从它没问到的里面加一个进去。这样就安排掉了 $M_i$。和之前类似地，因为每个图灵机能被无限个串表示，所以我们总能超越常数和 $n$ 上的指数，那它就真的被安排掉了。

ex3：证明存在 $B\in EXP$ 使得 $P^B=NP^B$。

Prf. 冷静看一下上面那个过程，虽然决定到 $i$ 的时间看起来是 up arrow 的，但判定到长度为 $n$ 的串的时间是 exp 的，所以就对了。

这说明 $P?=NP$ 不可能是一个 relativizing 的结果，那么只使用 relativizing 的证明（例如 diagonalization）不可能解决 P vs NP 的问题。因此我们需要更多的技巧。

This last result caused diagonalization to go out of favor for many years. ... Thus future complexity theorists should master this simple idea before going on to anything fancier!

我们还可以证明ch4的两个东西是 relativizing 的（咕咕咕）。

好消息是，我们也有不那么 relativizing 的结果，例如规约：

(0.5*) ex7：证明存在一个 oracle $A$ 使得 $NP^A$ 不能被 $P^A$ 地规约到 SAT。这里的意思是规约的图灵机是多项式的，它可以调用 $A$。（因为我们不能写 $SAT^A$，所以这个看起来是规约 $^A$ 的一个合理形式）

Prf. 考虑和上面一样的构造。如果我们可以规约那个东西，那么规约程序只需要 poly 次询问就能规约到一个不需要 $A$ 的确定结果，这看起来就不对。那么我们把上面证明抄下来，只是最后构造的时候我们暴力解出 SAT 然后反向安排。

#### Misc

ex5：证明存在 non time-constructible 的函数。

Prf. 随便搞搞，例如 $n+halt(n)$。

(1.1*) ex1：证明如下语言是 undecidable 的：$i\in S$ 当且仅当 $M_i$ 的时间复杂度不超过 $100n^2+200$。

Prf. 考虑从停机问题规约。对于一个 HALT 问题，考虑拿一个 UTM 模拟它，那么它可能停机也可能不停。然后可以发现如下构造：考虑一边模拟一边读输入，输入没了就停机，如果 UTM 停了就 loop。那么如果不停机则 $M$ 是一个 $O(n)$ 的复杂度，否则对于足够大的 $n$ 都不停机。那么如果上面那个东西能判定我们就能判停机了。

(1.5*) ex2：证明 $SPACE(n)\neq NP$。更坏的是，我们完全不知道这两个 class 的其它任何关系（比如是否包含）

Prf. 考虑 padding argument。如果相等，根据 Space Hierarchy 有一个 $SPACE(n^2)$ 的问题不在 NP 里面。但考虑给输入加 $n^2$ 个 $0$，那么加完后问题在 $SPACE(n)=NP$ 中，因此 padding 完在 NP 中。但 padding 又不影响 NP，所以之前的那个问题也在 NP 中，矛盾。

### IV Space Complexity

之前我们考虑的都是时间复杂度，但空间也是复杂度的一方面（无处存储.jpg）

#### Definition of Space Complexity

~~你在跑一个神经网络，然后你显存爆了~~

对于一个函数 $S$，我们称一个语言 $L$ 属于 $SPACE(s(n))$（或者 $DSPACE$），如果存在一个判断 $L$ 的图灵机和一个常数 $c$ 使得 $L$ 对于一组输入最多使用 $c*s(n)$ 个输入纸带外的纸带位置。

类似的我们定义 $NSPACE$：把图灵机换成非确定性的。

与 time-constructible 类似，我们需要要求 $S$ 是 space-constructible 的，即计算 $S(n)$ 需要不超过 $O(S(n))$ 的空间。原因也是类似的：我们做转换时经常需要知道接下来需要的 $S(n)$，所以我们经常需要算它。

但与之前不同的是，这里不考虑输入纸带的内存，因此我们完全可以让 $S(n)<n$，例如接下来的 $L,NL$ 部分。但我们仍然有一个“最低要求”： $S(n)\geq \log n$。大概来说，如果 $S(n)$ 更小，那我们根本不能记住当前的位置，也不能记住 $n$。这个时候我们干的事就和DFA差不多，但这不是我们考虑的内容。

#### Time and Space

考虑 $*TIME,*SPACE$ 之间的关系。我们显然有 $DTIME(f(n))\leq DSPACE(f(n))$，原因是每一步只能用 $O(1)$ 个位置。同时我们显然有 $DSPACE\in NSPACE$。

而另一方面，对于一个限定空间 $f(n)$ 的问题，纸带可能的状态数一定不超过 $2^{c*f(n)}$（考虑所有情况），那么考虑拉出所有状态然后做点大力 dfs，我们就可以在 $O(2^{c*f(n)})$ 的时间内判断。那么我们有 $NSPACE(f(n))\in DTIME(2^{O(f(n))})$。

人类已知最好结果是在这里除 $\log$，挑战图灵奖.jpg

#### Space Hierarchy

上一章证过了确定性的，非确定性的下次再说。

一些证过的结论：

ex1：存在常数倍空间的 UTM。

#### PSPACE

类似 P,NP，我们定义如下复杂度类型：

$$
PSPACE=\cup_{c\geq 1} SPACE(n^c)\\
NPSPACE=\cup_{c\geq 1} NSPACE(n^c)
$$

我们可以和 NP 一样定义这里的规约：称一个问题是 PSPACE-hard 的，当且仅当所有 PSPACE 问题可以 $\leq_p$ 到它。如果它也在 PSPACE 中则它是 PSPACE-complete 的。

##### Completeness

同样与 NP 类似，我们有自然(ex2)的 complete 问题：

定义问题 SPACE TMSAT 为，给定 $M,w$ 和 $n$ 个 $1$，判断 $M$ 是否在 $n$ 个空间内接受 $w$。显然任何一个 PSPACE 的图灵机拿过来就是 TMSAT，因为我们有常数倍空间（其实也没那么需要）的 UTM，那么拿 UTM 模拟即可说明它是 PSPACE 的。

仍然和 NP 类似地，我们有更正常的 complete 问题：

##### TQBF

我们定义一个 QBF 为如下问题：本来有一个 boolean formula，现在有人在前面加了一大堆 $\exists x_i$ 或者 $\forall x_i$（显然顺序重要）。

定义问题 TQBF 为，给定这么多 $\exists, \forall$ 和最后的formula，判断这个表达式是否是 true。

这显然是非常强的问题：从之前看过的东西来说，只加 $\exists$ 我们得到了 $NP$，只加 $\forall$ 我们得到了 $coNP$。

Thm. TQBF 是 PSPACE-complete 的。

证明：属于 PSPACE 只需要写个程序直接搜。然后考虑如何证明它能解决任何一个 SPACE TMSAT 问题。一个挑战是 $M$ 可能可以跑 $2^n$ 步，所以这里就不能再搜了。

这里有一个对很多空间问题都有效的高明分治：设 $f(S,T,k)$ 表示 $S$ 是否能在不超过 $2^k$ 步内走到 $T$。那么考虑 $k\geq 1$ 的时候枚举中间态然后递归到两个 $f(k-1)$ 的问题，否则大力判断。这样就成功把搜索深度从 $2^n$ 变成了 $n$。

回到这个问题，我们是个 QBF 而不是图灵机，但稍微搞搞也能搜出来：$\exists$ 中间状态，$\forall$ 两边的情况 $k-1$ 都成立。那么堆 $O(n)$ 层就完事了。

##### NPSPACE and Savitch’s Theorem

这一分治还有更知名的应用：证明 NPSPACE=PSPACE。（因此这里没有类似 P vs NP 的东西，但是 PSPACE 下面还有很多个章节的复杂度）

Savitch's Theorem: 考虑 $S(n)\geq \log n$ 的正常情况，我们有 $NSPACE(S(n))\in DSPACE(S(n)^2)$.

证明：直接拉上面的分治。



一些有趣的话题：对于很多 puzzle，如果它操作步数是 poly 的那么它经常是 NP-c 的，如果操作步数可以是指数级那么它经常是 PSPACE-c 的（通过分治）。而即使是对于二人博弈(ex10)，即使它是完全信息（否则容易 NEXP）且操作步数有 poly 的上限（否则 EXP），它也经常是 PSPACE-c 的（类比 QBF）。~~所以室友已经精通手玩 PSPACE 了，但我还在手玩 NP~~



#### log Space

我们还可以考虑更小的复杂度，定义：

$$
L=DSPACE(\log n)\\
NL=NSPACE(\log n)
$$

注意这里我们不考虑 $\log^c n$ 的东西。一种解释是因为 $O(\log n)$ 的空间显然自动是 $P$ 的，但 $poly\log n$ 就不一定了。

##### Logspace Reduction

根据常规流程我们开始考虑这些 class 的 completeness 问题。但可以发现我们之前用的 $\leq_p$ 在这里就完全不管用了：因为 $L,NL\in P$（上一行），拿 $\leq_p$ 规约不如直接算(ex3)。从而我们需要一些更弱的规约形式。

我们的目标是 logspace reduction，这对于 L vs NL 正相当于 poly reduction 对于 P vs NP。一个问题是 logspace 的程序不能输出那么多东西（注意输出纸带算内存）。解决方式是，我们要求程序能 logspace 算一位，即如下定义：

称一个函数（$\{0,1\}^*\to \{0,1\}^*$）能被隐式 logspace 计算，如果 $f$ 首先是 poly 长度，然后存在一个图灵机能任给一个 $x,i$ 算出 $f(x)$ 的第 $i$ 位，且只使用 logspace 空间。

用这种方式我们就可以类似定义 logspace 的规约：$L_1$ 能规约到 $L_2$ 当且仅当存在一个能用上述方式算的函数 $f$ 使得 $x\in L_1 iff. f(x)\in L_2$。记这种规约为 $\leq_l$。

用这个记号，我们类似地定义 NL-hard,NL-complete。

我们还可以用这种方式定义 P-complete。这在接下来可能用到。

我们还有另一种定义 logspace 计算函数方式：要求输出纸带不能往回走（可以停在当前位置），然后不考虑输出纸带的内存。

ex8：证明这两个定义等价。

Prf. 如果能算每一位那显然就能依次跑出答案。另一方面如果输出纸带不往前读就能继续算，那考虑拿个 counter 记录输出了多少位，然后扔掉第 $i$ 位之前的输出（之后不会用到），到第 $i$ 位再输出结束；这样就变成了上一个定义。

$\leq_l$ 和 $\leq_p$ 在定义上很相似，它们还有很多类似的性质：

1. $\leq_l$ 满足传递性。

Prf. 如果 $L_1\leq_l L_2$，$L_2\leq_l L_3$，那么相当于有两个可以算的 $f,g$，我们需要同样 logspace 地算 $g$ 复合 $f$。那么考虑模拟算 $g$，每次读一个输入位的时候我们跑一遍算 $f$ 的部分。

2. 如果 $L_1\leq_l L_2$，$L_2\in L$，那么 $L_1\in L$。

Prf. 和刚才类似，算 $L_2$ 然后每用一位输入就算一次。



ex6：证明即使换成 $\log_l$，SAT 和 3SAT 仍然是 NP-complete 的。

Prf. 首先 TMSAT 显然还是（造 UTM）。然后 UTM 还可以造成移动过程只和 $n$ 有关，且那个 pattern 可以快速计算，然后就很容易列出一堆 SAT/3SAT 的式子。（好像不 oblivious 也能搞，记录 $T(n)*S(n)$ 个变量，但是懒了）

ex9：证明即使换成 $\leq_l$，TQBF 仍然是 PSPACE-complete 的。

Prf. 隐式转换状态图是容易的，那个分治转 boolean formula 也是容易写的。

##### NL-complete

然后我们就可以定义：

一个语言是 NL-Hard 的当且仅当每个 NL 的语言都可以 $\leq_l$ 到它。

一个 NL-Hard 的 NL 语言是 NL-Complete 的。

与之前的各种情况类似，我们也有（比较）自然的 Complete 问题。例如我们可以继续搞 TMSAT。但这里有一个极其自然的问题，因此我们直接使用它：

输入一个**有向**图和两个点 $s,t$，判断是否存在 $s$ 到 $t$ 的路径。这个问题被称为 PATH。

Prf. 一方面这个问题在 NL 中：考虑直接每次随一个点走，走 $n$ 步（记录一个计数器）。考虑将 NL 规约过来的部分。注意到一个 logspace 的图灵机的状态可以被 $O(\log n)$ 个 bit 表示（输入纸带只记录位置。之前在证明 $PSPACE\in EXP$ 的时候也干过类似的事情）。考虑将每个状态看成一个点；一条边存在当且仅当可能可以转移过去（显然能 $O(1)$ 算）。这里可能有很多终点，因此可以每个接受状态再连到一个固定的边。这样我们就得到了一个 poly 大小的 NL 问题。编码可以常数空间算（冗余可以接受），加边只需要枚举，所以这可以是 logspace 的规约。

ex4：证明判定图是否强连通属于 NL。

Prf. 显然等价于 $\forall s,t$ 存在 $s\to t$ 的路径。

##### Certificate for NL

直接搞非确定性图灵机有时不那么方便，因此在 NP 的部分我们给了一个等价的定义：存在一个 verifier，使得对于答案是 $1$ 的情况存在至少一个被接受的 proof，否则所有 proof 都不被接受。

我们也想对于 NL 得到类似的 verifier 定义。直观上讲我们就需要让 verifier 只有 log 空间（不然直接就是 NP）。但我们还有一个 poly 大小的 certificate 需要读，那么另一个直接的想法是把这东西和 input 一样放在一条 read only type 上。但很遗憾的是：

ex7：证明如果 certificate type 只要求只读，那么得到的 class 还是 NP。

Prf. 首先因为这相当于 verifier 削了空间，所以它属于 NP。然后根据 ex6 我们只需要证明 3SAT 能被这样验证，而这是几乎显然的：枚举每个 clause，然后在 input 和 certificate（每个变量的取值）上来回看就行了。

这里的问题是往前重读 proof 相当于有了额外的内存。那么考虑要求不能向前读，即每一步这个纸带只能不动或者向右。这和 logspace reduction 的某个定义类似。那么我们最终得到如下定义：

对于一个语言 $L$，如果存在一个确定性 logspace verifier $M$，使得 $x\in L$ 当且仅当存在一个长度为 $p(|x|)$ 的 certificate $c$，使得 $M$ 以 $x$ 为输入，$c$ 为 read-once 输入时得到 $1$。

ex?：

Prf.

上面的例子也警示我们，造 certificate 的时候不能假装能重复读（比如复制几遍）。

#### Space Complement

类似 coNP，我们也可以直接定义 coNL：$L\in coNL$ 当且仅当 $\hat L\in NL$。那么自然的 coNL-complete 问题就是 coPATH：问 $s$ 到 $t$ 是否不存在有向路径。

但与 NP vs coNP 不同，这里我们又一次直接有了很震撼的结论：

##### Immerman-Szelepcsényi Theorem: NL=coNL

Thm. coPATH $\in$ NL，进而 NL=coNL

(**) Prf. 考虑 read-once certificate。这里主要的问题是 verifier 只有 logspace，我们需要让 verifier 不被各种精心构造骗过去。一个 naive 的想法是描述哪些点能被 $s$ 到达，即要求 certificate 给出 $s$ 能到达的集合 $S$。我们显然可以证明一个点能被 $s$ 到达。但我们记不住前面的 proof 是啥，certificate 随便伪造一下（前后不相同）就能骗过去。

我们不能记住一个集合，但一个有趣的发现是，我们可以记住集合的大小，然后我们要求 certificate 依次对于每个元素，说明它不在集合中或者**证明**它在集合中。这样只要我们知道了集合的大小，就可以强制要求 certificate 复读正确的集合。

但我们还不知道集合的大小，所以还是会被骗过去：我们可以要求 $s\in S,\forall v\not\in S, \forall u\to v\in E, u\not\in S$ 且 $\forall u\in S, \forall u\to v\in E, v\in S$。但如果大小不对，certificate 可以来回选择哪些数出现从而骗过去（即使有 $s\in S$）。

考虑从 $s$ 出发，逐渐推到 $S$。可以得到高明的构造：设 $S_i$ 表示 $s$ 出发 $i$ 步能到达的点集，那么我们自然有 $S_0=\{s\}$ 是确定的，$S_n$ 是我们想要的。我们只需要完成从已知 $S_i$（的大小）推到 $S_{i+1}$（的大小）的步骤。因为我们知道了 $S_i$ 的大小，我们可以重复让 certificate 复读 $S_i$（$i$ 步内可达可以显然证明）。那么我们可以通过如下方式判断一个点是否属于 $S_{i+1}$：枚举每一条连入的边，然后用 $S_{i}$ 的结果。这样我们就通过让 certificate 复读 $S_i$ 得到了 $S_{i+1}$，然后我们只需要记住大小继续。 $\square$



(0.4*) ex5: 证明 2SAT 属于 NL。

Prf. 直接证不太容易，但我们可以用 NL=coNL 的结论！根据众所周知的 2SAT 做法，无解当且仅当存在 $a,\bar a$ 在同一个强连通分量里面，那么判定无解是属于 NL 的，但是 NL=coNL。

这对更一般的状态图上显然也成立（而不仅仅是 logspace），唯一的问题是我们需要隐式建图，但这并不是难点(ex11)。因此我们得到了更一般的结论：

Thm. 对于 space-constructible 的 $S(n)\geq \log n$，我们有 $NSPACE(S(n))=coNSPACE(S(n))$。

#### Misc

(ex12) 我们定义 polyL=$\cup_{c>0}DSPACE(\log^c n)$。之前说过，这个概念不常用的原因是它不能对应到 $P$。

还有一个 class 被称为 SC：能够被某个图灵机以 poly 时间和 polylog 空间计算的语言。按照定义 $SC\in P\cap polyL$。但它们是否相等则是 open 的，因为一个语言可能分别有两种算法。例如，PATH 属于 P（平凡）和 $L^2$（Savitch's Thm），但后者的递归复杂度不属于 P。PATH 是否属于 SC 是开问题。



### V Exists, Forall, Alternations and PH

#### Quantifiers and Alternations

在第二章我们讲到，从 verifier 的角度，NP 可以看成如下类型的语言：

$$
x\in L \text{iff.} \exists u(\in \{0,1\}^{p(|x|)}) M(x,u)=1
$$

其中 $M$ 是一个确定性 polytime 图灵机，也可以看成一个 poly 的 circuit/booleam formula（TMSAT/SAT/circuitSAT容易相互规约）

而 coNP 可以看成（接下来省略 $(\in \{0,1\}^{p(|x|)})$，只需要注意这里每个东西都是一个 poly 大小的串）：

$$
x\in L \text{iff.} \forall u M(x,u)=0
$$

确定性图灵机都可以任意翻转，因此我们也可以把最后改成 $M(x,u)=1$。

我们分别感受了 $\exists,\forall$ 的力量，但有些问题只用不能只用一者描述：例如求最小值的部分，我们需要存在一个这样的解，同时所有更小的方案都不合法。那么这就需要我们合并两种 quantifier，从而有如下形状的定义：

$$
x\in L \text{iff.} \exists u\forall v M(x,u,v)=1
$$

我们称这个 class 为 $\sum_2^p$。

像这样交替，我们可以定义 $\sum_i^p$ 为

$$
x\in L \text{iff.} \exists u_1\forall u_2\exists u_3\cdots Q_i u_i M(x,u_1,u_2,\cdots,u_i)=1
$$

类似 coNP，我们可以定义 $\prod_i^p=co\sum_i^p$，或者说

$$
x\in L \text{iff.} \forall u_1\exists u_2\forall u_3\cdots Q_i u_i M(x,u_1,u_2,\cdots,u_i)=1
$$

ex9：我们考虑如下 EXACT INDSET 问题：给定 $G,k$，问 $G$ 的最大独立集大小是否正好是 $k$。那么它显然是 $\prod_2^p$ 也是 $\sum_2^p$ 的：我们需要分别验证是否有解，且是否没有更大的解，随便拉一种顺序写即可。

但我们还有更精细的刻画：定义 DP 表示如下 class：$L\in DP$ 当且仅当存在 $L_1\in NP,L_2\in coNP$ 使得 $L=L_1\cap L_2$。即 $L$ 是一个 NP 条件和一个 coNP 条件的并。（请自行感受这个和 $NP\cap coNP$ 的区别）那么按照定义显然 EXACT INDSET 属于 DP：两个限制分别是有解和没有更大的解。

我们甚至有更强的结论：EXACT INDSET 是 DP-complete 的。

Prf. 考虑规约一个 DP 问题。我们可以对对应的 $L_1,L_2$ 分别进行规约。因为目标是独立集，考虑把两个问题规约到两个独立集。那么原问题合法当且仅当第一个图的独立集大于等于 $k_1$ 且第二个图的独立集小于 $k_2$。注意到 SAT 到 3SAT 规约独立集的那个构造还满足独立集一定不超过 $k_1$，因此第一个图的限制是简单的：判断它的独立集是否正好是 $k_1$，这符合 EXACT INDSET。但第二个图上独立集可以是任意数，考虑通过如下方式限制：建一个二分图，左侧是原图，右侧是 $k_2-1$ 个点，两侧之间连所有边。那么现在图的最大独立集大小一定是 $\{k_2,k_2-1\}$ 中的一个，且是 $k_2$ 当且仅当原图最大独立集是 $k_2$。然后考虑合并起来，考虑将第一张图复制两份，然后判最大独立集是否是 $2k_1+k_2-1$。注意到复制两份后最大独立集大小是偶数，那么这样一定能判出 $k_2-1$，然后就全对了。

#### Succinct Problems

我们有一些常用的加难度方式：假设问题本来有 $n$ 个元素并给出它们之间一些 poly(n) 大小的关系，考虑将它换成 exp(n) 个元素，然后用一个 circuit 给出这些关系：circuit 输入一个/两个/若干个元素编号，输出它们的关系。

这样就直接大幅降低了输入大小并提升了难度。但 succinct 表示通常会限制我们能表示的原问题类型，因此我们需要更仔细的分析它的强度（这在之后可能会看到）。

例如，对应 set cover 问题，考虑将元素变成 $2^n$ 个（集合不变），然后给一个电路 $c(i,j)$ 输出 $S_i$ 是否包含 $x_j$。

ex11：证明这个问题属于 $\sum_2^p$。

Prf. 把最后的验证直接换成 $\forall j$（用二进制表示）。

更仔细的分析可以说明它 $\sum_2^p$-complete（咕）

ex13：我们考虑一个机器学习问题。定义 VC-dimension 为如下问题：我们给定一族函数 $h$（输出 01），每组参数 $y$ 指定了一个函数 $h_y(x)$。这族函数可以被一个 circuit $c(x,y)$ 表示。称这组函数的 VCD 为最大的正整数 $k$ 满足存在 $k$ 个输入点 $x_1,\cdots,x_k$，使得对于 $2^k$ 种情况中的每一个 $(r_1,\cdots,r_k)$，都存在一个 $h_y$ 使得 $\forall i,h_y(i)=r_i$。

定义判定性问题为，给定 $c$ 和 $k$，判断 $VCD(c)$ 是否大于等于 $k$。

a. 证明 VC-DIMENSION$\in \sum_3^p$

Prf. $\exists$ 一组输入 $\{x_i\}，$\forall$ 所有 $r$，$\exists$ 一个 $y$ 满足条件。

(1.8*) b. 证明 VC-DIMENSION 是 $\sum_3^p$-complete 的。

Prf. 我们需要让 VCD 表示 $\sum_3^pSAT$。直接做很难，考虑从简单情况开始。

首先考虑表示 $\sum_1^p=NP$，可以发现我们只需要两种 $h_y$，一种真的跑一遍 SAT，另一种输出 $0$，然后判断 VCD 是不是 $1$。$\prod_1^p=coNP$ 可以类似解决。

然后开始考虑第二层。$\sum_2^p$ 可以直接选一个点然后用上面的做法。但 $\prod_2^p$ 不那么简单。一个主要问题是 $\forall$ 看起来只能在中间段枚举，但 SAT 只有一个 bit 的输出，所以我们在两段 $\exists$ 中必须使用我们在 $\forall$ 枚举的内容（不然不可能对上答案）。那么我们只能把这个也放到最后一段，也就是找 $h_y$ 的过程。

进一步寻找可以发现，记原问题为 $\forall y\exists z M(y,z)$ 考虑让 $h_{(y,z)}$ 输出 $y$ 拼接 $M(y,z)$，那么合法当且仅当每个 $y1$ 都能被输出。那么我们类似之前的技巧，再加一类函数输出所有 $y0$。原问题只能输出一个 bit，所以我们考虑让每个 $x$ 表示输出第 $i$ 位，这样就解决了 $\prod_2^p$。

现在来到 $\sum_3^p$，我们需要在开头再加一层 $\exists$。一个想法是直接把这层的 $x$ 融到选择 $x_i$ 里面，即将原先的 $(i)$ 变成 $(x,i)$，即表示输入 $x$，然后输出结果的第 $i$ 位。但如果选两个不同的 $x$ 可能得到非预期的结果，尤其是多个最后一位。但我们只需要限制必须全选相同的 $x$，可以发现这还是能通过往 $h$ 里面加东西来解决：我们把 $h$ 变成 $h_(x,y,z)$，输入 $(x,i)$ 时我们先比较两个 $x$，如果不等就返回 $0$；否则我们跑 $M(x,y,z)$，然后输出 $y+M(x,y,z)$。这样我们必定选了某个 $x$ 的所有 $(x,i)$；根据上面 $\prod_2^p$ 的分析我们对了。

#### Polynomial Hierarchy

我们定义 PH 为所有 $i$ 下所有上面那堆东西的集合，即所有常数层交替的 quantified boolean formula 描述的语言。注意到我们显然有如下结论（考虑放空一层 quantifier）：

$$\sum_i^p\in \prod_{i+1}^p\in\sum_{i+1}^p$$

那么我们也可以只定义 $PH=\cup_{i>0}\sum_i^p$。

一些性质：

Thm. 如果 $P=NP$，那么 $P=PH$，即如果一个 quantifier 不能让我们算更多的东西，那么再多 quantifier 也不行。

Prf. 注意到 $P$ 可以随便取反，那么 $coNP=P$。然后我们就可以一层层剥掉 quantifier：考虑 $\sum_2^p$，我们可以先把里面那层 $coNP$ 换成 $P$，然后再动外层。之后的东西完全类似。

ex12：如果 $\sum_i^p=\prod_i^p$，那么 $PH=\sum_i^p$。

证明：对于更高层，我们可以换掉里面 $i$ 层的东西，这样就合并了一层交替。

我们称 $PH=\sum_i^p=\prod_i^p$ 的情况为 PH collapses 到第 $i$ 层。但我们经常相信 PH 不会 collapse。

Thm. 如果 PH 有任何 complete 问题，那么 PH collapses.

Prf. complete 问题会属于某一层，那么整个 PH collapse 到这一层。

但另一方面，对于一层内部我们有自然的 complete 问题(ex1)：图灵机可以换成 SAT，所以我们可以定义 $\sum_iSAT$：先按照 $\sum$ 的方式套 $i$ 层 quantifier（每一层可以有 poly 大小），然后给一个 SAT。可以发现这就是 TQBF 的特例。

note: 需要注意的是，在 NP 中 SAT 容易直接转化到 3SAT，但这不一定总是真的。可以发现 SAT 到 3SAT 需要加一堆新的变量然后 $\exists$ 这堆变量，所以如果问题最后是 $\exists$ 结尾那么再 $\exists$ 新变量就没问题，但别的时候就很有问题。例如 $\prod_13SAT$ 显然是 P 的，$\sum_23SAT$ 看起来像是 NP 的。更经典的例子是，对于 PP 来说直接的 complete 问题是 MajoritySAT，但 Majority kSAT 都是 P 的（ref：U群群友）。

#### Alternating Turing Machines

我们还有更抽象的从单个 quantifier 扩展到 alternation 的方式：之前我们从 verifier 出发，将 $\exists c$ 换成了很多层 quantifier 然后一个 $c$。但我们也可以回到图灵机的角度：NTM 可以看成每一步我们可以任意选择路径($\forall$)，考虑把这个换成任意 quantifier，然后我们有了如下定义：

定义 Alternating Turing Machine 为一个类似 NDTM 的图灵机（可以有多组转移），但现在每个除去 accept 和 reject 的状态有 $\exists,\forall$ 中的一个 quantifier：从某个 $\exists$ 状态开始可以得到通过当且仅当存在一种走下一步的方式得到通过；从 $\forall$ 状态开始得到通过当且仅当每一种走下一步的方式都得到通过。这里为了避免定义问题，我们要求无论选什么 path 都不能走出环。

注意到这个定义是强于 PH 的：我们允许非常数次 quantifier 转换，例如此时我们有如下结果：

Thm.(ex3) 我们与之前类似地定义 ATIME 和 AP。那么此时有 AP=PSPACE。

Prf. 首先我们可以直接拿 AP 算 TQBF，那么 $PSPACE\in AP$。另一方面，如果我们把 AP 的状态图拉出来，它只有 poly 大小，那么我们大力 dp 即可。

(**) ex7：我们还可以定义 APSPACE，这里空间是原先图灵机的空间。那么我们有 APSPACE=EXP。

Prf. $APSPACE\in EXP$ 是简单的：考虑状态图上暴力做。另一方面则非常高明：首先我们不能只有 poly 层，不然我们会得到 PSPACE。这里关键的问题在于我们不能记住指数级个状态，因此我们不能直接验证纸带。（可以跳过下面两段）

但我们有一个想法：只记录当前位置，通过 $\forall$ 分出一堆东西验证所有纸带。为了简便，我们可以认为这个图灵机只有单个 working type（上 UTM）。考虑从终止状态开始倒着走，每一步 $\exists$ 找上一个状态，但只记录指针位置。然后我们额外记录一个当前在验证的位置 $x$ 和它当前的值，只验证这个位置的值。那么每一步我们 $\exists$ 上一个状态后，可以 $\forall$ 一个分支验证当前位置向前的情况。直观上这样能验证每个位置。

换一种角度考虑，我们的状态是 $(t,s,a,b,c,f)$ 表示当前前面还有 $t$ 步（因为我们要找个时间验证是否回到了开始状态），input 在位置 $a$，working 在位置 $b$，状态在 $s$，然后我们要求 $c$ 位置是否是 $f$。转移先 $\exists$ 上一步状态往前，然后 $\forall$ 选择上一个位置和当前位置中的一个继续验证。

可以发现这个状态又相当于如下定义：$t$ 步后是否可能 input 在位置 $a$，working 在位置 $b$，状态在 $s$，$c$ 位置是 $f$。那么因为原来的图灵机是确定性的，每个时刻合法的状态构成一个图灵机的状态，那么这整个过程就是对的。也可以从之前的角度考虑，不同位置不可能分出两条不同路径回到初态，那么所有位置都合法必然通过同一条路径回去。

为了得到 PH 那堆东西，我们需要限制 quantifier 的层数。那么我们令 $\sum_iTIME(T(n))$ 表示一个 ATM 从 $\exists$ 开始，在所有情况下最多切换 $i-1$ 次且时间不超过 $T(n)$ 的图灵机能计算的语言。

然后我们有如下联系：

ex2+4. $\sum_i^p=\cup_c \sum_iTIME(n^c)$

Prf. 一方面，$\sum_i^p$ 显然可以通过 ATM 依次搞每个变量直接做到 $\sum_iTIME$。对于另一方面，考虑 $\sum_i^p$ 枚举计算路径，每一段 quantifier 的路径用 $\sum_i^p$ 的这一段来枚举。

但我们需要考虑非法路径的问题。对于 NP 部分，我们可以直接在 SAT 里面让非法路径直接false，但这里显然不行，不然 $\forall$ 的部分完全不对。可以发现正确的方式是，从前往后判，$\exists$ 段出非法路径直接false，$\forall$ 段出非法路径直接true。然后从最后往前一层一层可以证明回来。

更直观的理解是看成博弈：$\sum_i^p$ 可以看成两人轮流填东西，填 $i$ 轮。那么填不合法的人应该直接输掉，所以 $\exists$ 段非法就先手输（false），$\forall$ 段非法就后手输（true）

#### Oracle Machines

除了限定交替数的 QBF 和 ATM，我们还有第三种定义方式：Oracle Machine。

首先我们考虑 $NP^{NP}$，更具体地我们的 Oracle 是某个 NP-complete 问题，例如 SAT。考虑 $NP^{SAT}$ 的力量。我们首先可以发现如下结论：

Thm. $\sum_2^p\in NP^{SAT}$

Prf. 注意到有了 oracle 后，我们可以把 oracle 输出取反，这样就得到了 $\forall$ 的部分。

同时我们还有另一个不那么显然的方向：

Thm. $NP^{SAT}\in \sum_2^p$

Prf. 考虑把这个过程直接写出来。但如果我们每次调用 oracle 现算结果，那写出来就会是 $n$ 重交错，这很难接受。但这也有很简单的处理方式：考虑把用到的 oracle 询问先预处理了。一种简单的方式是，我们先 $\exists$ 出整个执行路径和 oracle 询问的结果，然后大力算出中间过程，再分别用 $\exists,\forall$ 验证每组询问我们猜的结果对不对。这显然可以写成一个 $\sum_2$ 的 ATM，那么它就是 $\sum_2^p$ 的。

那么 $\sum_2^p=NP^{NP}$。通过一个完全类似的讨论（验证的时候我们先验证后者），我们可以得到 $\prod_2^p=coNP^{NP}$。

更近一步，我们可以得到 $\sum_3^p=NP^{\sum_2^p}$。这里证明的后半部分只需要把两种询问结果的交替部分融到一起。(这整个部分构成ex8)最终我们可以得到如下对 PH 的定义：

$$
\sum_i^p=NP^{\sum_{i-1}SAT}=NP^{\sum_{i-1}^p}\\
\prod_i^p=coNP^{\sum_{i-1}SAT}=coNP^{\sum_{i-1}^p}
$$

事实上还有一个记号 $\delta_i^p=P^{\sum_{i-1}^p}$，它属于 $\sum_i^p\cap \prod_i^p$。

#### TISP and some magic

我们定义 TISP(T(n),S(n)) 为使用 $T(n)$ 时间和 $S(n)$ 空间的图灵机能计算的语言集合。

结合一些 alternation，我们可以得到如下类型的结果：

Thm. 我们可以选择一些 $a,b$ 使得 $NTIME(n)\not\in TISP(n^a,n^b)$。

Prf.(+ex6) 考虑如下过程：

如果 $NTIME(n)\in TISP(n^a,n^b)$，那么 $NTIME(n^c)\in TISP(n^{ac},n^{bc})$。我们会取一个很大的 $c$ 防止某个地方时间上的指数突然 $<1$。

然后考虑 TISP 部分，我们进行一些平衡下的分块，枚举每 $n^{(a+b)c/2}$ 位置的状态，然后 $\forall$ 一下验证每一段，这样的 ATIME 是 $n^{(a+b)c/2}$。那么 $TISP(n^{ac},n^{bc})\in \sum_2TIME(n^{(a+b)c/2})$。

接下来考虑处理 $\sum_2TIME$。注意到那个假设同样说明 $NTIME(n)\in DTIME(n^a)$，那么我们可以处理掉里面那层 $\forall$，得到 $\sum_2TIME(n^{(a+b)c/2})\in NTIME(n^{c*a(a+b)/2})$。

那么我们最终得到 $NTIME(n^c)\in NTIME(n^{c*a(a+b)/2})$。那么只要 $a(a+b)\leq 2$，这就和 NTIME hierarchy 矛盾。例如，我们可以知道 $SAT\not\in TISP(n^{1.2}, n^{0.4})$。

这些技巧说明，虽然我们现在完全不会证明 $NP$ 不能用线性时间/log空间解决，但我们至少证明了我们不能同时用线性的时间和log空间。

### VI Boolean Circuit Complexity (I)

> 在 OI 中，一道题目从来都是解决某个大小内的某个判定性问题，而不是解决整个判定性问题。大多数时候一位 OI 选手写出的程序都容易自然扩展为 P 中的图灵机，但也有一些特例。一些显然的例子包含打表和 Miller-Rabin.

除了图灵机（确定性，非确定性————以及更进一步的 Alternating），我们还有更多的计算模型。接下来的几部分将会初步考虑一些特殊的模型。

#### Boolean Circuit

我们使用如下方式定义一个输入 $n$ bit，输出 $1$ bit 的 Boolean Circuit：

有一个 DAG，每条边表示一个点的值（所有值都在 $\{0,1\}$ 间）算出后作为下一个点的某个输入。有如下三类节点：

1. 输入节点 $x_i$，其值由输入给定。这样的点正好有 $n$ 个，对应输入的每一位。
2. 运算节点，其有 $\land,\lor,\lnot$ 中的一个运算符。根据这个运算符它应该有一个或者两个输入，然后它的值是输出。整个求值过程显然可以按照拓扑序进行。
3. 有一个特定的运算节点是输出节点，它的值为 circuit 的输出。

我们定义一个 circuit 的大小是它的运算节点数量。（大部分情况下输入节点数量低量级，但因为size 注重常数，所以这里还是需要注意）

这里一个节点的出度没有限制，即每个节点的输出可以无限复用。如果我们限制出度为 $1$，则我们会得到 Boolean Formula 的定义。这在之后可能会用到。

但我们限制了入度是 $2$。虽然如果我们从 poly 的角度考虑，任意入度可以直接分治实现。但这在定义一些更精细的 circuit class 时会用到。

和图灵机一样，我们也可以用 01-string 表示 circuit。这在等会也会用到。

#### Circuit Family

Circuit 的一个问题是，它的输入大小是固定的，且难以直接进行扩展。因此我们很难直接拿一个 circuit 解决一整个判定性问题。

同时考虑之前提到的特例的本质。在 MR 里面我们可以选出一些数，使得它们对于某个范围内的 $n$ 都能正确判断，即它可以解决这个大小内的问题。好消息是我们可以证明，对于任意一个范围，我们都能找到一个大小不大(poly length)的 $a$ 集合来正确判断这个范围内的所有数。（大概是考虑先随机，然后数期望）那么这也算是从某种意义上解决了问题。

这相当于对于每个范围，我们可以找到一种方式来解决问题，因此我们有如下定义：

我们称一个 circuit family 为一个从 $\N$ 到 circuit 的映射 $n\mapsto C_n$。换言之，对应每个输入长度 $n$ 我们安排一个 circuit 来解决所有这一长度的问题。那么我们容易得到一个 family $C$ 判定的判定性问题。

更进一步，我们还需要限制 circuit 的复杂度：那么我们定义一个 family 属于 $SIZE(T(n))$，当且仅当 $|C_n|\leq T_n$。有时常数是重要的：我们很快会看到，一定存在不在 $SIZE(2^n/10n)$ 中的问题，但 $SIZE(2^n/n)$ 可以包含所有问题。但除去这种极端情况，有时我们又不考虑常数。

#### P/poly, and more definitions

我们来定义第一个 circuit family 的 class。和之前一样，我们一般认为 poly 是好的，那么有：

$P/poly := \cup_{c} SIZE(n^c)$

这里我们又不关心常数：$n>1$ 的时候常数可以通过调大 $c$ 直接解决，$n=1$ 的情况我们认为我们能解决（虽然好像确实要两个才行）

然后我们按照惯例考虑这个 class 和其它 class 的关系。首先考虑 circuit 的计算能力，我们有最直接的关系：

Thm. $P\in P/poly$

Prf. 按照惯例考虑 oblivious UTM，然后把位置的取值写成按照时间顺序的 formula（类似之前的 SAT 构造）

运用这一构造，我们容易得到如下结论：

Thm. Circuit SAT 是 NP-complete 的。

Prf. 把 verifier $M(x,u)$ 写成 circuit，然后把 $x$ 部分换成定值，这样证明了 NP-Hard。另一方面，考虑找每个 node 的输出，然后每个 gate 容易写成一堆 3SAT（拉一个 Truth Table 逐项构造）

##### Alternative definition

通过类似 $P\in P/Poly$ 的证明，我们可以给出一个新的定义：

考虑接受一个额外的 (thrusted) advice $\alpha_n$ 的图灵机，其中 $\alpha$ 只和输入有关。记图灵机运行时间为 $T(n)$，advice 长度为 $\alpha(n)$，那么我们把这样的 class 称为 $DTIME(T(n))/\alpha(n)$。

对于一组确定的 $\alpha_1,\alpha_2,\cdots$，我们容易得到一个图灵机判定的函数，那么 $DTIME(T(n))/\alpha(n)$ 中的函数就是所有这么多时间内的图灵机和所有建议能处理的函数。

Thm. $P/poly=\cup_{c,d} DTIME(n^c)/n^d$，因此 P/poly 可以看成 poly 复杂度的图灵机接受 poly 长度的 advice。

Prf. 一方面，对于一个 $DTIME(n^c)/n^d$ 中的图灵机和 advice 组，我们可以再次把图灵机写成 circuit。另一方面，对于每一个 poly 大小的 circuit family，我们可以直接往 advice 里面写 circuit，然后 $M$ 只需要做 evaluate。

#### More relations about P/poly

如果更大的 class 属于 P/poly，那现实意义上这说明这些问题在某个范围内可以被快速解决，这也是有趣的。但在考虑这些 class 间的关系时，我们会得到一些更神奇的结果：简单地说，一个 poly 的 circuit 能解决一些问题，则可以说明一些问题可以被足够弱的 circuit 解决。

##### Karp-Lipton Theorem

Thm(**). 如果 $NP\in P/poly$，则 $PH=\sum_2^p$. 这说明如果 PH 不 collapse(as widely believed)，则 $NP\not\in P/poly$.

Prf. 显然我们只需要证明 $\prod_2^p \in \sum_2^p$。考虑 NP 中的 SAT 问题。如果它在 P/poly 中，即存在一个 circuit family 判定是否有解。但我们不能直接找判定的 circuit，因为这样我们完全不能判定它的输出是否有理。我们必须找一个能验证的方式，可以发现直接的想法是求出它的解。那么我们容易通过这个 family 再构造一下把 SAT 的解也求出来（逐位确定）。此时考虑找一个输出多位的 circuit，对于每个 SAT 用 circuit 输出一个解，然后验证是否是真的。此时上述分析说明存在一个 circuit 把有解的全部搞对，而这显然是最优情况。

这样我们找 circuit 验证的时候，只可能把 yes 判断成 no，且一定有一个 circuit 全对。那么考虑 $\prod_2 SAT$，即是否对于每个 $x_1$，此时的 SAT 都有解。通过上面的验证，这可以看成如下问题：是否存在一个 circuit $M$，使得对于每个 $x_1$，其对应的 SAT $X$ 接受 $M(X)$ 作为一组解。

首先拿真的 $M$ 来一定能判对，然后如果答案是 false，那么显然不可能有人在 false 的点上造出一组解，因此这个问题和原问题答案相同，从而 $\prod_2^p\in \sum_2^p$。

##### Meyer's Theorem

Thm(**). 如果 $EXP\in P/poly$，则甚至 $EXP=\sum_2^p$。

Prf. 和之前类似，我们希望找到一种方式去判定这个输出是否有理。之前的过程相当于让它多输出一些东西（整组解）来判定，这里也可以考虑类似的东西。但首先我们考虑的是 general 的运算问题，而不是一个具体的 SAT，因此不能直接用之前的构造。

可以发现一个有效的验证答案方式是输出整个运算过程。具体来说，给一个图灵机让它算 $n$ 步显然是 EXP 的（$n$ 用二进制给出）。那么如果 $EXP\in P/poly$，可以考虑找一个 circuit，让它输入 $n$ 输出一些 $n$ 步后的信息，然后我们验证这个信息对不对以及它是否最后输出了 $1$。

我们不能让 circuit 直接输出整个纸带，但可以发现输出一些信息就够用了。例如考虑输出当前的 state，每个 head 的位置和当前值以及这个位置上次被访问的时刻。那么 check 只需要 $\forall t, \forall i$，当前 state 和上一个 state 加一步转移相同，同时 $\forall t'\leq t$，通过 head 的位置判定是否每个位置给出的上次访问的时刻和当前信息符合。显然每个信息都可以模拟出来，因此是 EXP 的。然后我们只需要 $\exists$ 这样的 circuit 使得 $\forall$ 验证（包括判定输出）都通过即可。

#### Uniform vs Nonuniform

我们继续考虑 $P/poly$ 这个 class 的位置。但我们很难找到一个类型包含它。因为如下原因：

Thm. 任何一个 unary language（所有接受的输入都是全 $1$ 串）都是 $P/poly$ 的。

Prf. 考虑接受 advice，那么只需要往 advice 里面写对应长度的答案即可。

Thm2.(ex8)：我们定义 sparse language 满足对于任意 $n$，它接受的语言数量不超过 $p(n)$，其中 $p$ 是一个确定的多项式。证明任何一个 sparse language 都是 $P/poly$ 的。

Prf. 只需要把所有解写进去即可。

ex9(1.9*)：我们考虑加强 ex2.30：如果任何一个 sparse language 是 NP-complete 的，则 $P=NP$。

Prf. 如果直接用 ex2.30，一个问题是之前 yes 和 no 加起来只有 $O(n)$ 个，所以我们可以把两种状态都记下来，但现在 yes 有 $n^c$ 个但 no 有 $2^n$ 个，所以我们根本记录不下来所有状态。这样会带来一些问题：考虑搜这个解，每一步我们 pad 到固定长度 $n_1=O(n)$，然后跑规约；如果规约出了 $>n_1^c$ 个串，那么一定有一部分可以剪枝；我们还知道搜索树上如果一个点有解，那么它的父亲也有解，但这里有一堆叶子，我们还是无法知道剪掉哪个。

很多叶子我们不会处理，但如果是一条链，那么处理是简单的：如果两个点结果相同，那么中间一段都可以直接扔掉（相当于直接跳到从下面开始），否则如果两两不同则可以直接扔掉叶子。如果往 SAT 上加一层前缀 $\lor$，这样有解关系就变成了一条链。但直接加一层会使得长度与叶子数成正比，这显然难以接受。但如果我们把当前所有叶子按照字典序排序，那么前缀 or 就相当于问有没有字典序更小（只固定前面）的解，这样长度就可以不超过定值 $n_2$。然后每一步我们拿出当前所有 $2n_2^c$ 个叶子，排序后每一个进行规约。如果有两个规约结果相同，那么中间部分（包含右端点）一定可以被扔掉。重复这一过程直到所有元素两两不同，然后因为包含关系，我们可以只保留右侧 $n_2^c$ 个。然后递归做就行了。



这样我们甚至可以解决如下问题：输入 $n$ 个 $1$，$n$ 编码一个图灵机和一个输入，判断是否停机。

那么 $P/poly$ 甚至能包含 undecidable 的问题，这是困难的。

当然我们也可以类似地构造不那么 undecidable 的问题：

ex3：找到一个问题 $L$ 使得 $L\in R,L\in P/poly,L\not\in P$，其中 $R$ 表示 decidable languages.

Prf. 一种有效在 $P/poly$ 中的方式是 unary language，一种有效证明不属于的方式是 time hierarchy。那么我们可以考虑 unary EXPCOM：输入用 unary 编码 $(M,k)$，输出 $M$ 在 $2^{2^k}$ 步后是否返回了 accept。注意到 $N^2\to N$ 的编码中，如果 $M$ 是常数，那么编码结果不超过 $k$ 的常数倍，那么这个问题 EXP-complete，因而显然不在 $P$ 中。

一种替代定义的尝试是，我们限制生成 circuit 的方式，这样就能显然地排除掉 undecidable 的情况。例如如下定义：

我们称一个 circuit family 是 P-uniform 的，当且仅当存在一个 poly time 的图灵机，输入 $1^n$ 输出 $C_n$。原始的 circuit family 被称为 Nonuniform 的。

但这个定义很没意义，因为它太简单了：

Thm. P-uniform P/poly = P.

Prf. 一方面，对于 P-uniform P/poly 我们只需要先把 circuit 跑出来再 evaluate，它就 $\in P$ 了。另一方面，考虑之前 $P\in P/poly$ 的构造，容易发现这是 poly time 的：实在不行准备 $T^2$ 个变量就行。

另一种方式是考虑 logspace-uniform，即把图灵机的限制改成 logspace。此时我们需要仔细考虑输出的方式。一种不需要考虑编码的做法是，我们需要在 logspace 中支持求出 circuit 的大小，单个点的符号，一条边是否存在。

但我们仍然有类似的结论： logspace-uniform P/poly = P。

Prf.(ex4) 仔细考虑上述证明。这里可以用每个时刻每个纸带位置的值（以纸带头为中心）来让所有关系都是局部的。对于每一步我们需要先判定当前使用的规则，然后整体更新。显然每一个局部步骤可以用 $O(1)$（基于图灵机）的 circuit 解决且可以预先求出，那么我们容易给整个 circuit 标号，然后只需要扫过去找到需要的位置即可。

Note. 这样的做法相当于给出 circuit 的邻接矩阵表示，但这个表示显然不是 compact 的。更 compact 的表示是对每个点给出入点标号。但我们容易证明这两者可以 logspace 转化，因此由 logspace 的传递性两种定义等效(ex10)：邻接矩阵到邻接表是容易的，只需要扫过去找到两个个 $1$。另一方向更加平凡。

虽然这两个定义都没用，但是接下来的几个 class 会用到这些定义，从而使它们能被别的 class 包含。

#### Circuit Lowerbound (I)

在图灵机上证明算法下界是极其困难的，因为我们需要考虑纸带和规则。因此一些尝试是用更简单但能力上近似的模型来证明复杂度下界。例如，根据 $P\in P/poly$ 我们可以知道，只要证明函数的 circuit size 严格大于 poly，那它就不能 $\in P$。更多模型的 lowerbound 会在很靠后的位置给出。

对于 circuit 来说，因为我们有 circuit family，因此我们可以只考虑每一个固定的 $n$ 下所有 $2^n$ 组输入输出对应的函数的复杂度。

首先考虑算下界。一种方式是数数：显然这里有 $2^{2^n}$ 组函数，而如果我们对每个 circuit 通过记录每个点的两个入度，运算符以及输入输出的位置，我们可以用 $2s\log s+O(s)$ 个 bit 表示任意一个 $s(s>n)$ 个点的函数。这样如果 $s<2^n/(2+\epsilon) n$，我们就找不到 $2^{2^n}$ 个函数，从而至少存在一个函数的 circuit size lowerbound 是 $2^n/(2+\epsilon) n$。

更进一步，我们可以认为每个点的输出都会被用到，那么考虑对于每个点找一个用到它的点，这样有效部分必然构成一个以输出节点为根的树。那么这棵树上的部分我们可以用括号序列表示，从而再少掉一个 $s\log s$。因此上一个 bound 可以优化为 $2^n/(1+\epsilon n)$。

Note. 更精细的分析可以做到 $2^n/n(1+\log n/n-O(1/n))$。

注意到 boolean formula 直接就是一棵树，那么那个东西的 lower bound 就是 $2^n/c$。

另一方面，考虑算这个东西的上界。首先，直接打表就容易做到 $2^n/c$(ex1a)：考虑一个 $n$ 层二叉树，叶子上是每种输入对应的输出，然后每一层我们通过输入的第 $i$ 位在每个点上选择对应输出，直到根我们就找到了最后的答案。可以发现这甚至是一个 boolean formula，因此它的上下界只差常数量级。

但如果我们使用 circuit 完整的力量，我们还能做到 $2^n/n$ 的量级(ex1b(0.5*))。考虑上一做法的前 $k=c\log n(c<1)$ 层，我们总共有 $2^{2^k}=2^{cn}$ 种可能的输入，因此考虑对于每种输入搞一个 circuit 而不是对每个位置，然后对于每个前 $k$ 层的位置从对应 circuit 接过去。这样后面就只剩 $2^{n/k}$ 的复杂度。取 $c=1-\epsilon$ 就可以做到 $2^n/n(1+\epsilon)$ 的上界。

##### Nonuniform Hierarchy

结合上面两部分分析，我们可以得到很好的 hierarchy 结论：

Thm. 对于 $T,T'$，如果 $n\leq (1+\epsilon) T(n)\leq T'(n)\leq 2^n/n$，则 $SIZE(T(n))\subsetneq SIZE(T'(n))$.

Prf. 根据上面两部分，我们可以找到一个合适的 $l\leq n$，使得输入 $l$ 位的函数大都不能用 $T(n)$ 个点算，但都能用 $T'(n)$ 个点算。然后把 $l$ pad 到 $n$ 即可。

上面的分析甚至可以说明随机函数都是 2^n/n-hard 的，但对于我们已知的 complexity class，我们仍然很难得到很好的下界。据说 NP 问题的最好下界还是 $5n$，NEXP 还没有超过 poly 的下界。更多的问题可以参考 ch14。目前最好的结果可以参考下一部分。

#### Sigma2E, Sym2E require maximum circuit size

插播内容.jpg

Thm(Li et al. 23) $\sum_2E\not\in SIZE[2^n/cn]$ for some $c$. 也可以进一步证明 $S_2E$。之前两者都被证明不属于 $P/poly$ 但不存在指数级别下界。

##### Upperbound vs Lowerbound

上界和下界是两个看起来完全相反的东西，但有时上界也能推出另一个下界。例如我们之前有一堆 $A\in B\in C$，然后又通过 time hierarchy 或者一些东西我们得到 $A\neq C$，那么如果我们得到 $C\in B$（下界）就自然有了 $B\not\in A$。

回到正题，对于 circuit 部分，考虑如下问题：

($2^{cn}$-Hard) 输入 $2^n$ 个 $1$，输出一个长度 $2^n$ 的 Truth Table 使得它的 circuit complexity 大于 $2^{cn}$ 级别。根据经典 counting argument 这一定有解。

如果我们能快速解出这个问题，那考虑如下手段：我们解出这个问题，然后对着 Truth Table 输出，这样我们的 circuit complexity 就大于 $2^{cn}$ 级别。坏消息是 Truth Table 高达指数级别，但我们还是可以得到如下类型的结论：

1. 如果该问题存在 $(F)P$ 的算法，那么 $E\not\in SIZE[2^n/cn]$.

Prf. 用 $P$ 的算法跑 $2^{n}/cn$-Hard，然后输出表上对应位置，这个算法是 $E$ 的。

现在 $E$ 还没有非平凡下界，所以这应当还是有用的。

但坏消息是我们不会 $\in P$ 所以也搞不出来。接下来我们考虑在某种复杂度下解决问题从而推到 $\sum_2E$。

##### Hardness vs Pigeonhole

ref. ch15

我们首先考虑对问题的转化。

在证明一定有解的时候，我们干了这样一件事：可能的函数有 $2^{2^n}$ 个，circuit 只有 $2^{c_12^{cn}}$ 个，每个 circuit 对应一个 Truth Table，那么一定有一个对应不到。

这样的鸽笼原理可以启发我们想到如下问题（本来这里还有点逻辑学，但是我不会）：

(Range Avoidance) 给一个输入 $n$ 个 bit，输出 $m>n$ 个 bit 的 circuit，求出一个不在它值域内的串。为了简便我们通常考虑 $m=2^k,n=2^{k-1}$

通过之前的分析这两个问题有一些神奇的联系，事实上也确实如此。首先 hardness 可以直接到 RA：考虑一个 circuit 输入 circuit 描述，输出它的 Truth Table。另一方面，RA 也可以通过某种规约到达 hardness：

Thm. 在 $\Delta_2^p=P^{NP}$ 规约下可以把 RA 规约到 hardness。

Prf. 假设现在有了一个 hardness 的答案，考虑如何解 RA。此时有一个构造被称为 GGM Tree：考虑将这个 hardness 的串切成若干长度为 $m/2$ 的段，然后在上面建满二叉树。在每一层上，我们先求出两个儿子对应的串，拼接得到一个长度为 $m$ 的串，然后尝试找到一个它的原像（NP 问题）。如果找不到解我们就得到了一组答案。

但如果每次都有解，我们最后得到了一个长度为 $m/2$ 的串，且对于每个位置我们都可以 $O(\log L)$ 次调用 circuit 向上走从而还原这个位置的值。此时 $L$ 就被 $poly(m,\log l)$ 的 circuit 算出了，但这显然和 hardness 矛盾。

虽然这个Thm在这里没啥用，但这个思想接下来有用。

回到正题，我们根据第一步规约，我们只需要解 Range Avoidance 就可以达到类似的效果，因此我们考虑解后者。

##### What kind of solution?

然后我们考虑需要什么样的算法来解决。首先这里输出是一个串，所以我们需要 $FP$ 的类型，例如证明 $E$ 需要 $FP$。那么 naive 的直觉是 $\sum_2E$ 需要 $F\sum_2P$，这里有一个直观的定义：

Prover 给一个串 $x$，然后 Disprover 给一个串 $y$，接下来 polynomial verifier 验证 $(input,x,y)$ 然后 reject 或者输出一个串表示答案。我们要求 verifier 必须得到合理答案（因而如果无解 verfier 必须 reject），且如果有解 Prover 一定能让 verifier 输出一个解。

但如果按照这个定义，RA 显然属于 $F\sum_2P$：Prover 给一个无法到达的输出，Disprover 尝试找一个输入（如果 Prover 给了错误的东西就会被发现），然后 verifier 验证是否 $C(y)=x$，是就 reject，否则输出 $x$。因此看起来哪里出了问题。

可以发现如果按照这个定义，verifier 的输出不是确定性的，而是会随着 Prover 给的东西变化。但这就使得这样一个函数不太良定义，因此这显然不合理。具体到我们的问题，我们之前的操作是，通过 $F\sum_2P$ 找到一个 hard circuit，再输出它。那么相当于 $\exists x,\forall y$，$x$ 通过了 $y$ 的验证且 $C_x(input)=1$。但如果有多解，那么 $x$ 就有很多选择，从而最后的输出是这些 $C_x$ 的并。这显然出了问题。

因此这里给一个更良定义的问题：我们要求如果有解，那么对于任意 $x$，如果 $\forall y$ 都不能让 verifier reject，那么 verifier 会输出一个只与输入有关而与 $x$ 无关的串。这个问题被称为 $F\sum_2Psv$，其中 sv 表示 Single Value。显然如果我们能这样解，那么过 $\exists\forall$ 后得到的 circuit 只有一组，这时再加一个 $C_x(input)$ 就没问题了。

##### Range Avoidance in $F\sum_2Psv$

我们只剩下了解决这个问题。但这里 Prover 显然不能只给一个答案：如果 disprover 需要通过声称更小的某一步无解来挑错，那这需要通过 NP 的方式解决 coNP 问题，这显然不对。

和之前的某个 Thm 一样，通用的一种验证方式是给出整个运算过程，即让 Prover 输出每个解。但这是指数级的长度，我们也不能直接像之前那样压缩。因此看起来我们需要压缩。

可以发现之前的 GGM Tree 是一个很好的压缩方式：考虑让 Prover 不只对每一对做一次比较，而是对一个长度为 $m2^m$ 的依次包含所有 $m$ 位串的大串做 GGM Tree 的压缩过程。显然第一层压缩就会出现矛盾，之前的算法也相当于只做第一层。但做多层显然不会错（只要顺序确定），我们可以利用这棵树来压缩复杂度：考虑按照后序遍历压缩，这样如果在一个点失败了，前面的部分一定可以看成 $O(m)$ 个完整子树。但每个子树我们都成功压缩到了 $n$ 位，这样我们就用 poly 大小描述了这个 certificate！!1

具体来说，Prover 跑这样的算法，然后在第一次找不到原像的时候把这个位置和之前的每个子树的压缩结果发过去。然后 Disprover 进行如下检查：

1. 如果成功压缩的部分推回去有地方不对（原串可以简单算一位），返回这个位置。
2. 如果声称不能做的地方能做，返回一组解。

然后就可以 poly 验证了。显然这样得到的答案只和 $C$ 有关。

那么考虑如下 $\sum_2E$ 中的问题：我们先这样搞一个 poly 大小的 circuit，满足它的 hardness 是 $2^n/cn$ 的，然后模拟它的输出。这就完成了目标。

##### More?

我们可以把 $\sum_2$ 换成 $S_2$。但是我还不会。

在这个结果之后，几乎每一个已经证明不在 $P/poly$ 中的类都有最大的 circuit complexity，除了 $MA_{EXP}$（see ch8）。我们能不能进一步证明 $MA_{EXP}$？

小练习：

ex5&6(2-eps*)：证明 $\forall k, \sum_2^p\not\in SIZE(n^k)$，即 $\sum_2^p$ 没有一个确定的 $n^c$ circuit upper bound。

Note. 我们还不能证明 PH 甚至 EXP 有 super poly 的 bound，这里只是说对于任意 $k$ 存在一个可能也是 poly size 但是次数 $>k$ 的。

Prf. 考虑我们刚才干的事：我们能用 $\sum_2^e$ 的复杂度唯一确定一个 circuit complexity 高达 $2^{cn}(c<1)$ 甚至 $2^n/cn(c>1)$ 的函数，然后输出它。现在考虑 scale down。我们取 $n^*=a\log n$，那么上面的东西复杂度就变成了 $\sum_2TIME(2^{a\log n})\in \sum_2^p$，但这东西的 circuit complexity 就可以高达 $2^{acn}$，其中 $a$ 可以任意取，那就做完了。

ex7(*)：证明如果 $P=NP$，那么 $EXP$ 存在一个需要 $2^n/n$ 的 circuit complexity 的 class。

Prf. 我们继续拿上面的东西证明。如果 $P=NP$，那么自然 $EXP=NEXP$ 从而 $EXP=\sum_2E$，因此我们可以在 EXP 时间内得到 $2^n/cn(c>1)$ circuit complexity 的函数。

#### Smaller Circuit Class

之前一种证明下界的方式是，我们从很大的正常 class 开始，希望依次说明每个 class 不在 $P/poly$ 里面，但我们现在的最优解还是 $MA_{EXP}$。

我们还有另一种思路：考虑找一些更小的 circuit class，逐步增加到 $P/poly$，然后我们依次说明每个更小的 class 能和之前的 class 分开。

##### NC and AC

我们显然不能继续缩小 circuit 的大小，这里也不存在空间的概念。但从并行计算的角度出发，我们可以考虑对深度做出限制。

具体来说，我们定义深度为从输入节点到输出节点的最长路距离，通过这个限制，我们可以得到如下定义：

我们定义 $NC^i$ 为满足如下限制的 **logspace-uniform**（这样我们可以把它限制到某些 class 内） circuit family 能计算的函数：circuit 的大小是 poly(n) 的，且深度是 $O(\log^i n)$ 的。

我们类似地定义 $AC^i$，唯一的区别是在 $AC$ 中我们允许 $\land,\lor$ 有任意个输入节点。

我们定义 $NC=\cup_i NC^i,AC=\cup_i AC^i$。

因为我们可以分治，所以显然有 $NC^i\subset AC^i\subset NC^{i+1}$。

一些简单的性质和关系：

首先我们可以 $NC^1$ 算 01 矩阵乘法(ex12a)：并行每一位，分治求和。然后我们容易 $NC^2$ 算矩阵快速幂(ex12b)。注意到矩阵快速幂可以做路径计数（也可以做是否有路径），那么我们直接得到：

Thm.(ex12c) $PATH\in NC^2$，因此 $NL\in NC^2$。

当然这里第一步的 $NC^1$ 可以换成 $AC^0$，因此我们有 $NL\in AC^1$

而另一方面，我们有：

ex14: $NC^1\in L$，因此 $NC^1\in L\in NL\in AC^1$，同时根据 space hierarchy $NC^1\neq PSPACE$。

Prf. 直接倒着搜，每一步我们只需要记上一步走了两个入度中的哪一个就能从终点开始定位回来，因此只需要 log 空间。

ex13:(0.3*) 证明 Formula Evaluation 等价于 Nonuniform $NC^1$。

Prf. 首先对 $NC^1$ 强行展开（多出度的点强行复制多份变成单出度），就可以得到大小为 $2^{O(\log n)}\in poly$ 的 formula。

对于另一方向，树的深度导致没法直接并行，那么考虑经典的边分治：每次断一条边，枚举下面点的取值，两边分别算是否可能，然后合并信息。我们最多递归 $O(\log n)$ 层，因此递归到最后最多是给一个子连通块，我们钦定 $O(\log n)$ 个点的取值，问是否可行，那么大小也是 poly 的。这里的问题是边分不能 logspace，它需要 $log^2$。

ex16(1.5*): $DET\in NC^2$

Prf. 组合方式是，考虑数环，我们只需要去重。记 $f_{i,l}$ 表示从 $i$ 出发，走 $l$ 步回到 $i$，中间经过的点都大于 $i$ 的方案数（带边权），然后我们只需要找一些不重复的出发点，使得它们的 $l$ 加起来和为 $n$，这样乘上 $2^{n-cnt}$（环数和逆序对）求和正好可以去重。证明忘了。

还有一个代数做法，注意到 $Tr(A^i)=\sum \lambda^i$，然后我们只需要 pow 几遍搞出线性递推，解出最低项即可。

更进一步的结论可以参考 ch14。坏消息是，我们现在的最好结果可能还是 $NEXP\not\in ACC_0$

##### Logspace reduction with NC

我们刚才证明了 $L\in NC^2$，因此对于 logspace reduction，我们可以把 reduction 算每一位的过程换成一个 $NC^2$ 的circuit。这自然可以证明如下结果：

ex15: 如果存在 P-complete(under logspace reduction) 的问题属于 NC，那么 NC=P

我们还没有考虑过 P-complete 的问题。一个直接的问题是：

给一个 circuit 和输入，求出它的结果。

Prf. 类似 ch4 ex 证明 SAT 的 logspace reduction 一样，我们写出 oblivious UTM，然后开始写 circuit，同时仔细计算空间。

ex19: 证明 LP 是 P-complete 的。

Prf. 考虑上面的 circuit eval，我们对每个点用一个变量表示它的输出。如果我们限制到 $01$ 取值，那么显然一个 and/or 的 gate 可以表示为一个线性限制，其中 and 可以用 $\leq$，or 可以用 $\geq$，not 可以用 $1-$。

考虑 relax 回实数，然后 $\max$ 输出点的取值。如果输出点能取到 $1$，那么往回推可以发现某些部分必定是 $01$ 取值，且它们可以保证最后的输出是 $1$。而如果输出是 $1$，那么那个 $01$ 方案就可行了。因此这个 LP 可以表示 circuit-eval。

#### Larger Uniform circuit

对于任何问题，nonuniform circuit family 都只需要 2^n/n 的 size，但这可能根本没法算出来。一种替代方式是，我们要求 uniform，但允许更大的 circuit。此时输出 circuit 是一个问题，但我们可以类似 logspace 时候的处理方式，得到如下定义：

我们称一个 circuit family 是 DC(direct connect) uniform 的，如果它的大小是 $2^{n^c}$ 且我们可以在 poly 时间内输出某一条边是否存在，某个点的标号和点数。注意这里邻接矩阵和邻接表是不一样的，因为邻接表要数数。

此时我们有如下结论：

Thm. PH 正好等于满足如下限制的 DC Uniform circuit family：

1. 它的深度为常数，但可以使用任意入度。
2. NOT gate 只在第一层出现。（这个条件也可以删掉，我们可以每一层同时算一个反转的版本，然后遇到 NOT gate 就交换。这样只会乘上 $2^n$ 的大小）。

即 PH 等于常数深度的 DC uniform circuit.

Prf.(ex17) 一方面，对于任何一个 PH，考虑把它写成常数层的 $\exists\forall\exists...$，然后考虑从外层开始向里面搜，每一层枚举所有情况分成指数类，然后一起求 $\land$ 或者 $\lor$。

另一方面，考虑用 PH 算 DC circuit。此时继续考虑从终点搜，如果这个点是 $\land$，那就 $\forall u$，$u$ 不是它的入点或者 $u$ 取值为 $1$，否则就 $\exists u$，$u$ 是它的入点且取值为 $1$。然后就是常数层 alternation。

而如果去掉常数深度，我们可以得到：

Thm.(ex18) EXP 正好等于所有 DC Uniform circuit family 能判断的语言。

Prf. 一方面，EXP 显然能算 DC Uniform circuit：只需要把 circuit 建出来然后暴力。另一方面，任何一个 EXP 显然可以写成指数大小的 circuit。为了让它 uniform，我们可以考虑 $T^2$ 个变量的方式，记录每个时刻每个位置的取值（以纸带为中心），然后就可以只用局部信息了。

### VII Randomized computation

> 有趣的是，我们可以再次使用 Miller-Rabin ———— 但是是另一形式来做例子。

另一种模型是在确定性的图灵机上额外考虑随机因素。在很多实际情况下随机有着有效的应用，但从理论上这个问题更加的复杂。

基础概率论知识警告。

Chernoff bound：

Markov bound（数期望）：

#### Definition: Probabilistic Turing Machines and BPP

从直观上讲，随机算法的含义是我们可以在算法过程中取随机数。从图灵机的角度，我们有更简洁的定义。

定义一个 PTM 为如下图灵机：与 NDTM 类似，我们有两组转移函数；每一时刻，我们独立均匀随机选择一组转移函数继续转移。我们要求其必须输出 $01$ 中的一个值。根据随机情况，这个 PTM 有一个概率输出 $0$，剩余概率输出 $1$。

我们称 PTM 能判定一个语言，当且仅当对于每个 $x$，$M(x)=L(x)$ 的概率不小于 $2/3$。

我们使用如下方式定义 PTM 的运行时间：称 PTM $M$ 的运行时间为 $T$，如果对于任意随机结果，图灵机停机的时间不超过 $T(|x|)$，即它的最坏时间复杂度。

我们定义 BPTIME(T(n)) 为一个 PTM 在 O(T(n)) 时间内能判定的函数集合，然后定义

$$
BPP=\cup_c BPTIME(n^c)
$$

##### More ways?

这个定义有非常多特殊的地方，但实际上很多修改都不会改变 BPP 的定义。

和 NP 一样，只部分随机可以被每步随机包含。

从时间角度，最坏复杂度和一般的期望复杂度看起来有差距，但这实际上没有太大影响：如果期望运行时间为 $T$，那么考虑如果运行时间大于 $7T$ 就直接切断(TLE)随机输出一个，这样最坏只改变 $1/7$ 的输出结果。如果考虑 counter 的时间也只是多一个常数倍，所以问题不大。（Note. 一般情况运行时间都是 chernoff，所以切断的概率极小）

我们要求如果正确则输出 $1$ 的概率至少是 $2/3$，否则至多是 $1/3$。但我们有通用的方式将小的差距放大————只要概率不太离谱。根据经典方式，考虑随机若干次取众数，那么根据 Hoffding，如果两个概率间有 $2c$ 的差距，我们只需要 $O(c^{-2}\log \epsilon^{-1})$ 就可以做到 $1-\epsilon$ 的误差。那么在 poly-time 内，只要是 $\frac12+n^{-d}$ 和 $\frac12-n^{-d}$ 以上的差距我们都可以解决。~~我们也可以定义不以 1/2 为中心的类型，但这太怪了~~

但我们也不能太离谱，例如 NP 需要区分 $0$ 和 $\geq 2^{-p(n)}$，PP 则需要区分任意两个 $2^{-p(n)}$ 的概率，如果用说明的方式就指数了。这里 B 正好表示 Bounded-error：我们至少有 $n^{-c}$ 级别的额外正确率。

另一个角度是考虑每次选择的 $1/2$。我们考虑将 $1/2$ 换成一些别的 $p$。那么我们考虑用一个数表示另一个。直接表示看起来很难，但我们可以考虑级数，通过期望正确的步数而不是最坏情况来模拟。此时有两个方向：

1. 我们有一个 $p$ 概率的 coin，然后希望模拟 BPP 的 $1/2$。一个很好的想法是每轮丢两枚硬币，如果它们不同就用第一枚的结果（由对称性两者都是 $p(1-p)$ 概率），否则重来。期望复杂度 $\frac 1{p(1-p)}$。此时我们甚至对 $p$ 没有任何要求。

由此我们可以发现，一个任意概率的硬币（只要不是确定性）都不比 $1/2$ 弱。然后我们考虑它们是不是真的比 $1/2$ 强。可以发现在一定程度上我们确实可以得到：

ex5: 证明存在一些 $p$ 使得如果用这个 $p$，图灵机可以解决 undecidable 的问题（with bounded error）

Prf. 考虑 majority vote，如果次数足够多 $(2^{2n})$ 我们就可以还原出 $p$ 的二进制表示的前很多($O(n)$)位。那么我们就可以当 TM with advice = circuit family 用，然后拿一个 unary HALT 就行、

因此不可计算的硬币显著地更强。但另一方面我们可以说明：

Thm. 可计算的 $p$ 不会带来更强的能力。更具体的，如果 $p$ 可以被快速计算，即存在一个多项式 $f$ 使得 $p$ 的二进制第 $i$ 位可以被 $f(i)$ 时间计算，那么我们可以常数时间模拟 $p$ 的硬币：

Prf. 考虑看成我们逐位随机一个二进制数，和 $p$ 进行比较。如果我们比出来了就可以直接结束。那么每一步我们算出 $p$ 的这一位，再均匀随机一次。如果两者大小不同则返回大小关系，否则继续比下一位。根据之前的解释这显然正确，复杂度可以看成 $\sum \frac{i^d}{2^i}$，这是经典算数问题(ex2)。（考虑展开成下降幂，然后我们需要考虑 $\sum 2^{-i}\binom in$，这相当于选 $n$ 个位置，然后最后一个位置之前每一个位置乘 $1/2$，那么可以看成确定 $n$ 个位置乘 $2^{-n}$，每两个位置中间任意放空位 $\sum 2^{-i}=2$，因此答案是 $1$。所以这是只和 $d$ 相关的常数）

因此对于可计算的硬币，它和 $1/2$ 的硬币在计算能力上可以认为没有区别。

我们总可以 majority vote 得到答案，因此似乎可以说 BPP 是现实意义上可以计算的。但还有一个问题是，完美的随机在现实中并不存在。我们可能需要考虑在更弱的随机数生成器上考虑这些算法。这个讨论留到 ch21。

##### one-side error

BPP 是 general 的 efficient 随机类，但我们也遇到过这样的算法：如果答案是 $1$ 它一定输出 $1$，否则它有概率输出 $0,1$，或者反过来。一个经典例子是 bloom filter：每个数随一个 hash，询问看是否出现，然后多个独立过程取交。

那么我们可以定义单侧错误：

我们记 RTIME(T(n)) 为 $T(n)$ 时间内 PTM 能使用如下条件判定的语言集合：如果答案是 $0$ 那么它一定输出 $0$，否则它有至少 $2/3$ 的搞了输出 $1$。这是一个只会 false negative 的算法类。然后我们类似定义 $RP=\cup_c RTIME(n^c)$。

此时有更简单的 amplify 手法(ex4)：跑很多次取 $\lor$，那么容易发现任意至少 $n^{-c}$ 级别的输出 $1$ 概率都不改变 $RP$ 的定义。

我们还可以有另一个方向的 false positive，也就是 coRP。

显然 $RP,coRP\in BPP$。同时考虑这个定义容易发现 $RP\in NP$。

一个经典例子是接下来会讲到的 Miller-Rabin。

##### zero-side error? 

还有一种（可能稍微常见的）随机算法：我们一定输出正确答案，但我们的用时是期望的。

具体来说，我们定义 ZTIME(T(n)) 为 PTM 在如下条件下判定的问题集合：M 必须在任何情况下给出正确答案，但我们只要求它的期望用时是 $O(T(n))$。我们类似的定义 ZPP。

类似之前的分析，期望时间和最坏时间可以通过一些手段转化：

ex6a：考虑另一种定义 ZPP 的方式，我们要求 PTM 最坏时间不超过 $O(T(n))$，但此时它除了输出答案还可以输出 `?`。此时要求变为如果不输出 `?` 则答案必定正确，且输出 `?` 的概率不超过 $1/2$。证明两者等价。

Prf. 对于原来的 ZPP 定义，只需要让它超过 $2cT(n)$ 步就停下输出 `?` 即可变成现在的定义。对于现在的定义，考虑一个新算法不断跑这个 PTM 直到输出不是 `?`，那么期望时间是 $2cT(n)$。

类似地，$1/2$ 也可以换成直到 $n^{-c}$。

结合两种定义，我们可以得到如下结论：

Thm.(ex6b) $ZPP=RP\cap coRP$。 

Prf. 一方面，用 cutoff 的定义显然 $ZPP\in RP\cap coRP$。另一方面，对于 $RP\cap coRP$ 的问题，考虑两个算法分别跑一遍，那么无论答案是啥我们都有 $2/3$ 的概率判断对，否则输出 `?` 就行了。

上面的 $p$-coin 到 $1/2$-coin 也可以看成这种形式：如果相同我们就输出 `?`，否则输出答案。

同时 `?` 也可以简化一些问题的解法。例如(ex1)考虑用硬币均匀随机 $1$ 到 $n$，那么我们取一个大一点的 $2^l$，然后均匀随机，如果在 $[1,n]$ 内就返回，否则输出 `?`。

##### Randomized Space Complexity

我们可以用 worse-case space complexity 的方式，定义 UTM 的空间复杂度。

如果我们考虑 $\log$ 的空间，我们自然可以从 BPTIME 得到 $BPL$，从 RTIME 得到 RL。

一方面，我们显然可以 configuration graph 上数路径（worse case复杂度保证没有环），因此显然 $RL\in BPL\in P$(ex9)。

但另一方面，L vs RL 的问题还是 open 的。而如果我们把空间放大，我们有 $PSPACE\in RSPACE\in BPPSPACE\in PPSPACE = PSPACE$。证明可以看群友博客。  

一个知名的 RL 例子是：

Thm.(ex11) $UPATH\in RL$。这里问题表示无向图连通性。

我们可以证明，对于一个无向图，从一个点走到另一个点的期望时间是不超过某个 poly(n) 的：（Note. 有向图上一条链就能卡到 $2^n$(ex10)，所以这对某个 NL-complete 的问题没有任何帮助）

Prf. 我们考虑图上随机游走，然后看 $t$ 步后的概率分布。直观上想，如果图满足一点性质，那么我们应该会收敛到一个确定的分布。

我们记点 $i$ 的度数（可以带权，此时按照度数随机出边）为 $d_i$，那么可以发现(ex11a)，无向图上一个满足 $Gv=v$ 的分布是 $p_i=\frac{d_i}{\sum d_i}$。而对于有向图，只要它满足每个点入度等于出度，那么这也对。

考虑如何扩散到这一分布。直观上讲，考虑当前和这个位置偏差最大的地方，那么只要图连通，随着它走下去另一个方向的值应该可以扩散过来。但我们还需要它扩散到每一个时刻，因此我们可以发现，只要图连通且所有有向环长度的 $\gcd$ 是 $1$，那么任何初始状态都会达到这一分布。在无向图上，长度是 $2$ 的环显然存在，因此条件变为只需要不是二分图(ex11b)。当然如果是二分图，那一个做法是换成 Lazy Random Walk：每一步一半概率随机走，一半概率停。

但我们也不一定要扩散。考虑直接从 stable 的分布开始随机，只要图连通，那么对于每一个 $u$ 我们都会经过无限次 $u$。那么这样随机走可以看成经过期望若干步后，从 $u$ 开始走，然后不断回到 $u$。设最后 $u$ 出现的概率为 $p$，那么每两次 $u$ 出现之间的期望长度就直接是 $1/p$。因此在满足如上条件的边权下，从一个点出发回到自身的期望用时直接是 $\frac{\sum d_i}{d_i}$(ex11c)。

Note. 这可以直接说明 Numbers 第一问答案为 $\prod n$：显然给定边权满足该条件。

然后我们考虑 $u$ 走到 $v$ 的用时。考虑选一条路径走过去，如果这一步走错了，那么在那个点上，我们期望 $\frac{\sum d}{d_i}$ 步回来一次，每一层有 $\frac 1{d_i}$ 的概率成功回到原路（这里我们假设最小边权为 $1$），因此回去期望不超过 $\sum d$ 步。每一次我们有 $\frac 1{d}$ 的概率正确向前，否则期望不超过 $\sum d$ 步回来。因此总共的期望步数不超过 $O((\sum d_i)^2)$，无向图下这就是 $O(n^4)$ 的(ex11d&e)

#### Examples of randomized algorithms

##### K-th element

每次随机一个数，大小分开，然后选一侧。

根据经典方式，有至少 $1/4$ 的概率我们将大小减为 $3/4$，所以是线性。也可以猜一个常数然后归纳。

##### Primality Testing

经典 Miller-Rabin.jpg

基础二次剩余姿势：如果 $p$ 是质数，那么 $a^{p-1}$ 模出来自然是 $1$，因此模出来不是 $1$ 自然寄了。但有的合数这样不能判出来，因此考虑算 $a^{(p-1)/2}$。根据经典知识对于一个 $q^k$，算出来的结果中 $1,-1$ 占各半（根据它在乘法群中的位置），还可能有别的东西（但此时自然判出来合数）。而如果 $p$ 可以分解为两个不同的 $q^k$，那么根据 CRT 两边取值独立，从而有 $1/2$ 的概率搞出来不是 $1,-1$，而质数搞出来一定是 $1,-1$。如果是 $p^k$ 则高位大概率不是 $0$。

因此二次探测后只可能合数判为质数，且错误率不超过 $1/2$，因此这是 coRP 的。~~当然过了几十年就 P 了~~

##### Polynomial Identity Testing

我们考虑一个代数电路：每个位置只可以是加减乘。现在输入有常数和变量 $x_i$，你需要判定它的输出是否恒为 $0$。

根据 Schwartz-Zippel Lemma，如果我们在 $s$ 范围内随机取值，那么一个 $d$ 次非零多项式变为 $0$ 的概率不超过 $\frac {d}{|s|}$。

我们可以归纳证明，一个 $m$ 大小的 circuit 最多得到 $2^m$ 的次数，那么我们可以考虑取 $100*2^m$ 量级的数随机带入求值，就有高概率判断正确。

但我们不能算 $(2^m)^{2^m}$，因此我们可以考虑随机取一些模数。显然一个 $(2^m)^{2^m}$ 范围内的数的因子数量只有 $m2^m$ 级别，因此我们可以随机一些 $100m2^m$ 量级的模数算取模的结果，然后我们错误的概率就很低了。

与之前的问题不同，这个问题是否在 P 中是 open 的，而且好像这个在 P 中可以反向说明某些 lower bound（好像是 $P\neq NP$，但是忘了）

##### Perfect Matching Testing

如果我们给每条边一个 $x_i$ 然后算行列式(tutte)，那么多项式非零当且仅当有完美匹配。

那么用之前的方式，我们可以给每条边随机取值，把二分图邻接矩阵放到 $n\times n$ 然后求行列式看是否非零。这在 OI 中都很常用。

Note. 算行列式可以并行，因此我们有 Randomized $NC_2$ 算匹配的做法，甚至还有非常强的 derandomize 做到确定性 $Quasi-NC_2$（群友博客）。

#### Relation with other classes

我们考虑一些更有趣（困难）的问题：讨论 BPP 和那些不随机的 class 之间的关系。

除了用 naive 的枚举去掉随机外，我们还有更高明的去除随机方式：先把错误概率通过经典 BPP 方式放到足够小，然后通过其它方式解决。

Thm1.(*) $BPP\in P/poly$

Prf. 考虑 advice 直接给随机结果，但这里 $2^{T(n)}$ 种方式中每一个输入都有 $2/3$ 正确，这不保证存在一种方式全对。

但我们可以考虑使用 majority vote 的方式扩大这个正确概率，因为我们只用到了 $\log \epsilon^{-1}$，这里甚至可以放到 $1-2^{-n^c}$。但只要我们的错误率小于了 $2^{-n}$ ，那么随机一个输入期望错的次数就小于 $1$，这样就一定存在全对的随机方式。

Note. 我们的总错误数量仍然是指数的，但是这个增长比方案数增长低阶。


Thm2.(Sipher-Gacs) (*) $BPP\in \sum_2^p\cap \prod_2^p$。

Prf. 首先因为 BPP 显然对称，我们只需要证明 $BPP\in \sum_2^p$。那么现在我们需要用 $\exists\forall$ 的方式区分两种概率。我们可以让错误概率到 $2^{-n^c}$，但错误数量仍然可以是指数级的，因此我们需要更精细地设计判断方式。

一个 naive 的方式是，考虑将 $2^{T(n)}$ 分成上下两段，然后问是否存在一个高位使得任选低位结果都是 $1$。那么这样可以区分 $2^{-T(n)/2}$ 和 $1-2^{-T(n)/2}$ 的概率：简单来说如果不到 $\sqrt s$ 个 $0$ 那么一定存在一行全是 $1$，如果不到这么多个 $1$ 那么不可能存在一行全是 $1$。但我们错误数量的增长还是比 $T(n)/2$ 块的，所以这样做不出来。

我们需要区分 $2^{T(n)-f(n)}$ 和 $2^{T(n)}-2^{T(n)-f(n)}$ 出来。确定性的做法还有一些思路，例如选若干段 and/or 之类的，但这样都会被安排从而很难进一步。但我们可以从随机的角度考虑问题：考虑随机选出 $k$ 个长度为 $2^l$ 的段 or 起来，看是否全 $1$。那么为了干掉 $2^{T(n)-f(n)}$，我们需要 $k2^{T(n)-f(n)}<2^l$。另一方面，考虑后者正确的概率。每个位置 or 不出来的概率在随机下只有 $2^{-kf(n)}$，那么只需要 $2^{l-kf(n)}\leq 1$ 就行。

总结起来，我们需要 $\log k+T(n)-f(n)\leq l\leq kf(n)$。那么取 $k=\frac{T(n)}{f(n)}$ 级别的东西就可以保证正确。这个值是 poly 的，因此我们 $\exists\forall$ 一下就行。

##### Some open problems

一个经典问题是 complete problem 是否存在。根据之前的想法，一种直接的尝试是问它被 $1/3-2/3$ 判定的结果是啥。但这就出现了问题：如果结果在中间部分，那这个问题就没有很好的定义。如果我们只看 $2/3$，那么这是 PP-complete 的。

关键的问题正好在于，我们无法判断一个 PTM 是否一定输出概率不在 $[\frac13,\frac23]$ 之间：根据 Rice's Theorem(ex1.15)任何这种问题都是 undecidable 的。

这一问题也出现在了尝试构造 Hierarchy theorem 时。一种直接的想法是抄一个 NTIME hierarchy，但问题在于我们在模拟 $M(x-1)$ 时，如果 $M$ 输出概率在中间，那我们就不是一个正确的 PTM。但判断这个东西是 undecidable 的。

#### Randomized Reductions

我们还可以把随机过程放到规约过程中。

定义一种用 PTM 实现的规约函数 $f$ 是一个随机规约，如果对于每个 $x$，$Pr[A(f(x))=B(x)]\geq \frac 23$，即规约过去后有至少 $\frac23$ 的概率正确。记为 $\leq_r$。

我们可以定义 $BP\cdot NP$，表示能被这样规约到 SAT 的问题集合。因为不同 NP-c 可以确定性规约，所以这个问题选取不影响结果。

Note. 考虑这东西的定义：我们先随机一些东西，然后 poly 计算，接下来的 NP 过程可以看成一个有无限计算能力的 prover 返回一个结果，然后我们确定性验证，要求 $2/3-1/3$。那么这东西定义上就和 AM(ch8) 相同。

ex7. 我们定义 非确定性 circuit 为，我们额外输入一个 $y$，然后它的输出是 $\forall y, C(x,y)$。然后我们可以定义 $NP/poly$。现在请证明 $BP\cdot NP\in NP/poly$。

Prf. 照抄 $BPP\in P/poly$ 的方式。

ex8. 证明如果 $coNP\in BP\cdot NP$，则 $PH=\sum_3^p$。

事实上我们可以证明如果 $coNP\in NP/poly$，则 $PH=\sum_3^p$。

可以发现这个形式类似 Karp-Lipton，因此我们可以考虑类似的证明思路。但现在我们针对的是 coNP，所以我们不能直接像之前那样拿出解：此时的解是输出 No 的情况，因此我们可以确保任何 No 都是正确的输出，但我们更希望 Yes 都是正确的。

考虑更直接的验证：考虑 circuit-SAT，对于一个需要判断的 NP/poly 的 circuit $C$，我们先 $\forall$ 一个 circuit $C_1$ 和输入 $x$，如果 $C_1(x)=0$，那么 $C_1$ 不应该被 coNP 接受，因此 $\forall y, C(C_1,y)=0$。

另一个方向也可以验证：$\forall$ circuit，要么($\exists$) 存在一个 $x$ 使得结果为 $0$，要么存在一个 $y$ 使得 $C$ 找到正确答案。

那么此时 $\forall\exists\forall$ 就只需要 $\exists C$，然后先 $\forall\exists$ 做那堆判定，然后 $\forall\exists$，把最后一层换成我们的输出。


### VIII Interactive proof system

考虑这样一类计算模型：一个 prover 尝试向一个 verifier 证明一个命题；用判定性问题的语言，相当于我们有一个 $L$，然后需要验证是否 $x\in L$。 例如，我们可以将 NP 看成如下形式： prover 给出一个 certificate，然后 verifier 通过某种 poly 算法验证。这里我们考虑一种更广泛的证明方式：prover 和 verifier 之间可以交换多轮信息，即交互式证明。

与 NP 类似，我们有一些自然的要求：

1. 我们可以证明一个正确的命题。
2. 我们不可以证明一个错误的命题。
3. prover 可以使用无限的计算资源，但 verifier 必须只使用有限计算资源。通常来说我们要求 verifier 是 poly 的。

接下来我们更具体地分析这一定义。

#### Interactive Proof Schemes

一个交互式证明采用如下形式：双方轮流发送 01 串，从 prover 开始。每一次操作的消息可以通过输入和之前的整个交互过程给出。

我们要求交互轮数不超过 poly，每次的信息长度也不超过 poly。

##### Deterministic IP

一种简单的形式是让 prover 和 verifier 都是确定性的。此时相当于两者可以用两个确定性函数 $f,g$ 表示，然后其交互过程可以看成如下形式：

$$
a_1=f(x)\\
a_2=g(x,a_1)\\
a_3=f(x,a_1,a_2)\\
a_4=g(x,a_1,a_2,a_3)\\
\cdots
$$

最后 $f$ 可以通过之前的所有信息输出一个答案。

我们要求 $f$ 是一个 poly 的图灵机，但 $g$ 可以是任意函数。和 NP 类似，我们要求如果 $x\in L$ 那么存在一个 $g$ 能够使得结果为 $1$，否则对于任意 $g$ 结果为 $0$。

我们要求交互轮数事先给出，但它可以和输入长度有关。我们用 $[k(n)]$ 表示用了 $k(n)$ 轮的 protocol。

在 $f,g$ 都是确定性的情况下，我们将这一方式能判定的语言记作 $dIP[k(n)]$，同时令 $dIP=\cup_c dIP[O(n^c)]$。

这是最直接的定义，但很遗憾的是：

Thm. $dIP=IP$

Prf. 只要 verifier 是确定性的，那么 prover 可以模拟 verifier 的过程。问题可以之间看成能不能找到一个满足 verifier 条件的交互过程，从而这属于 NP。另一方面显然 NP 是一个一轮的 dIP。

##### Probabilistic verifier and IP

上一个结论说明我们至少需要让 verifier 是随机的。那么我们可以沿用 ch7 的很多定义。一种描述随机的简单方式是拿一个随机串 $r$，然后剩下部分都确定性，即如下过程：verifier 先随机某个长度的 $r$，在接下来的过程中 verifier 可以看到 $r$ 但 prover 不行。

显然我们还需要 ch7 的判定形式。即：

1. (completeness) 如果 $x\in L$，则存在 $g$ 使得 $Pr[result=1]\geq 2/3$。
2. (soundness) 否则，对于任意 $g$ 我们都有 $Pr[result=1]\leq 1/3$。

我们定义这样方式判定的语言为 $IP[k(n)]$，类似地 $IP=\cup_c IP[n^c]$。

随机性的引入可以带来很大的影响。一个例子是判定 Graph Non-isomorphism。我们不知道这个问题是否在 NP（即 dIP）中，但有一个非常经典的 IP protocol：

Verifier 随机拿出一张图，随机重排点，然后询问 prover 这个结果是从哪张图来的。如果两张图不同构那么 prover 可以全部答对，但如果两张图同构则 prover 无法区分，因此只有 $1/2$ 概率正确。

###### Basic Properties of IP

1. 将 prover 变为随机的不会改变 IP 的定义。

Prf. 注意到我们的 prover 可以对每个 $x$ 分开算(ex2)，因此我们也可以对每个 $x$ 分开考虑。此时每种策略会有一个输出 $1$ 的概率，那显然最大化输出 $1$ 的概率的方案是固定使用概率最大的策略。因此 prover 随机不如确定。

2. Prover 可以换为一个 PSPACE 的图灵机。进一步 $IP\in PSPACE$。

Prf. 考虑大 DP 算 prover 的策略：状态设为在之前的过程下最后输出 $1$ 的最大概率。（注意到我们是要求任意 $g$ 下的最大概率大于 $2/3$ 或者小于 $1/3$，因此这里应该考虑最大）每一步转移暴力枚举可能的 $r$ 向下考虑。

进一步，把 prover 换成 PSPACE 后我们只需要枚举 $r$ 计数，这显然属于 PSPACE。

3. 我们可以类似 BPP 地做 amplification(ex6)。根据完全相同的分析，我们可以将 $2/3-1/3$ 变为 $1-n^{-c}$ 和 $n^{-d}$。这里虽然 Prover 能看到不同轮的信息，但只要我们每轮独立随机，那么 Prover 就不能干更多事（因为我们能做的 prover 本来就能做）。但这并不等于 $1$。我们认为概率是 $1$ 当且仅当对于任意情况结果都正确。

Note. 我们可以并行地做这件事，从而不增加轮数。

4. 如果我们把 completeness 的数换成 $1$（上一条的定义），那么 IP 的范围不变。

Prf. 等会再证。

5. (0.4*)但如果我们把 soundness 的数换成 $0$，那么得到的又变回了 NP。这说明可能犯错是重要的。

Prf. 首先显然每个 NP 的证明方式满足 soundness=0。考虑满足 soundness=0 的 IP protocol，这说明如果答案为 $0$，则对于任意一个 $r$ 和任意一组交互过程（其中 verifier 的输出我们不做任何限制），最后 verifier 都输出 $0$。而另一方面，如果答案为 $1$，那么 $2/3$ 的概率一定存在很多输出 $1$ 的交互过程。因此这东西显然属于 NP。

Note. 一组交互过程不一定对应实际交互的情况。例如可能两种不同的输入被 verifier 变成了同一个输出（例如 GNI 的例子），此时 prover 不可能能区分两者，进而它只能对一半。但如果我们分开看，每个 $r$ 都可以单独找出一组合理的交互过程，但它们放到一起就矛盾了。

##### Public coins and Arthur-Merlin

上述 protocol 属于 private-coin，即 prover 不可以看到 verifier 的随机串。但我们也可以让 prover 看到 verifier 的随机，此时我们得到如下定义：

我们定义 public-coin protocol 为满足如下条件的 IP protocol：每当 verifier 行动（除了最后输出）时，他随机一些 01bit，然后输出所有随机结果。

因为某些原因（方便区分（确信）），我们称 public-coin 中的 verifier 为 Arthur，prover 为 Merlin。因此这种 protocol 也被称为 Arthur-Merlin protocol。

我们定义从 Arthur 开始的 protocol 为 $AM[k]$。特别地这里我们一般考虑常数，因为非常数很困难。

特别的，我们定义 MA 为 2-round, Merlin 先行动的 protocol(as its name)。可以发现这相当于把 NP 中的 verifier 换成 BPP。更一般地，我们定义一个 `A,M` 交替的串表示按照这个顺序交互的 protocol 判定的所有问题。

Note. 按照定义我们就有 $AM[2]=BP\cdot NP$：Arthur 的随机串是规约部分的随机串，Merlin 可以算出最后的 NP 问题然后给一组解，接下来 Arthur 规约过去并验证解。推回去只需要看成拿随机串规约到 Arthur 最后的判定。

###### 2 rounds vs k rounds

多轮的 AM 看起来比最简单的 $AM[2]$ 强：Merlin 前面给出的信息必须对后面 Arthur 大部分的随机正确。但事实上我们有如下结论：

Thm.(ex7) $\forall k\geq 2, AM[k+1]\in AM[k]$

Prf.(1.2*) 我们的关键点在于证明上面那种情况不会带来更强的证明，即 $MAM\in AM$。只要证明了这一点我们就可以把 $k>2$ 的情况去掉一层，而 $k=2$ 的情况我们只需要 $AMA\in AMAM\in AAM=AM$。

考虑一个大矩阵，其中行是 Arthur 的随机串，列是 Merlin 第一轮的输出，位置的值是确定前两者后 Merlin 能否找到一个让 Arthur 输出 $1$ 的值。那么 MAM 相当于判定是否存在一列中 $1$ 的占比至少是 $2/3$，且如果不满足则任意一列 $1$ 的占比至多是 $1/3$。

如果我们把它直接变成 AM，问题就相当于有 $1$ 的行是否占比超过 $2/3$。显然，如果原来 Merlin 有一列满足要求，那么把这么多列并起来也没有问题。但如果原来不满足要求，现在很多 $1/3$ 并起来就可能大于 $2/3$。

因此考虑对这个做 Amplification：我们只需要并行最后两轮 AM，就可以把 $1/3$ 减小到指数级。可以发现这个过程不改变第一轮 Merlin 输出的信息量，即列的数量不变。那么我们只需要把 $1/3$ 减小到确定的 $1/{3*2^k}$ 就行了。

因此常数轮的 $AM$ 完全等价于 $AM[2]$，即 Arthur 随机一个串给 Merlin，Merlin 返回一个结果，Arthur 确定性判定。我们也可以用这种方式定义 $AM$。

#### Power of public coins

##### Set lowerbound protocol

一种有效的 AM protocol 是证明一个集合的下界：有一个集合 $S$，双方可以快速验证 $x$ 是否属于 $S$（换言之，$S\in AM[2]$）。现在 Verifier 希望区分两种情况：$|S|\geq K$ 或者 $|S|<K/2$。

直观地想，考虑把所有元素映射到一个大小为 $cK$ 的集合，然后随机选一个数 $a$。那么前一种情况中存在一个映射到 $a$ 的元素的概率显然大于后者。具体来说，我们考虑 2-independent 的 Hashing 方式：对应任意大小不超过 $2$ 的集合我们有 $Pr[f(a)=x,f(b)=y]=Pr[f(a)=x]*Pr[f(b)=y](a\neq b)$。一个最简单的这类函数是 $f(x)=Ax+b$，其中操作在 $F_2$ 下进行。

考虑上面两种情况分别的概率。显然后者的概率不超过 $\frac 1{2c}$，而对于前者我们需要给一个下界。一种大力去重方式是 $1\geq n-\frac12 \binom n2$，即计算每个数属于的概率求和，再减去每对数属于的概率求和除以 $2$。根据 2-independence，我们算出来可以得到 $\frac 1c-\frac 1{4c^2}$。

可以发现任意 $c>1$ 都行，那么我们取一个让 $c$ 是常数的 $cK=2^s$，然后用上述构造：Arthur 随机 $A,b$ 和需要的结果 $y$。然后再 Amplify 一下即可。

Note. 我们可以利用 pow 的方式将 $/c$ 甚至 $/n^c$ 变成 $/2$。但区分两个足够接近($2^n$ and $2^n-1$) 的数对上述问题来说是困难的（强行 amplify 需要 $2^n$ 次才能放到 $e$ 级别的差距），因为这 PP-complete。

一个经典例子还是 Graph Non-isomorphism。考虑如下构造：我们选 $P\in\{G,H\}$，然后取出 $T\sim P,\pi\in Aut(P)$。如果我们固定一个 $P$，那么根据经典群论知识这相当于 Kernel*Image，因此方案数是 $n!$。可以发现如果 $G,H$ 同构，那么合并起来还是只有 $n!$ 种可行输出，否则有 $2n!$ 种。那么我们对这堆东西做 set lowerbound 即可。

##### Set lowerbound with Perfect Completeness

ex5(0.6*): 证明我们可以在 AM 内做到上述问题的 perfect completeness。

如果沿用上面的方式，则相当于要求如果有解，那么 $Ax$ 要能覆盖到每一个取值。但随机一个 $A$ 显然很难保证覆盖(derandomization 状态)。

但可以发现上面只在下界部分用到了函数的独立性质，上界部分只用了 Markov，所以对任意函数成立。那么我们改成 Merlin 先发 $A,b$，然后 Arthur 随机 $y$ 不会影响之前的算法。这样函数从随机变成了 $\exists$，但这好像还不行，因为我们不能随机一个 random oracle 发过去，只能用线性函数。

注意到上一章的 $BPP\in P/poly$ 提供了一些完全覆盖的方式：如果我们能让随机的期望错误数量小于 $1$，那么就存在一个对的。但这里现在每个位置的期望错误率还是常数，因此我们考虑多随机几次减小概率。可以发现只需要 $O(n)$ 个随机函数并起来就可以让单个位置期望错误率是 $O(2^{-n})$，这说明存在 $O(n)$ 个函数，它们的 $Ax$ 覆盖整个值域。那么只需要 Merlin 发过去这些函数，然后 Arthur 随机一个 $b$ 验证即可。

另一方面，我们还需要让这 $O(n)$ 个不能完全覆盖小的那一侧。那么我们只需要把这边的 gap 也放到 $O(n)$ 即可。这只需要上一个 Direct Sum($(1+1/c)^{c\log n}=poly(n)$)。

Note. 指数小的误差是不能做的，不然干掉 PP 了。

Perfect Completeness 的性质 可以用来解决一些问题：

Thm. 如果 GI 是 NP-complete 的，则 $\sum_2\in \prod_2$。因此人们不相信 GI 是 NP-complete 的。

Prf(*). 考虑一个 $\sum_2$ 问题，如果 GI 是 NPC 的，则它可以看成 $\exists x_1, GNI(f(x,x_1))$。

根据之前的方式，GNI 有 AM[2] 中的 perfect completeness protocol。那么 complete 侧可以写成 quantifier 的语言：$\exists x_1,\forall r,\exists a_2 V(f(x,x_1),r,a_2)$

但这是 $\sum_3$ 的。类似之前 $MAM\in AM$ 的方式，我们考虑交换前两层，这样这边显然还是对的，然后考虑类似之前的方式说明另一边：如果答案是 No，那么对于任意一个 $x_1$，随机 $r$ 有解的概率可以小到 $2^{-n}$，且这个过程不改变 $x_1$ 的大小。那么将 $x_1$ 放进去最多让有解概率乘上 $2^{x_1}$，所以可以被压缩掉。

Note. 这个例子同样可以说明如果 $coNP\in AM$ 则 $PH=\prod_2$。

##### From private coins to public coins

最关键的一个问题是考虑 IP 和 AM 在轮数相同时的区别。显然 private coin 不弱于 public coin。但 GNI 的例子也提供了一个将 IP[k] 变为 AM[k] 的方式：Set Lowerbound。

Thm1. $IP[2]\in AM[4]$

另一个证明：$IP[2]$ 的本质是，Verifier 把很多个 $r$ 输出到同一个 $a$，Prover 可以对于每个 $a$ 选择一个数去满足尽量多的 $r$，需要判定总和 $>2/3$ 还是 $<1/3$。直观上看，这相当于有很多个数，问它们的和大还是小。这很像一个 Set Lowerbound，但我们并不能把数加起来。实际上验证一个数也是复杂的：可以让 Prover 先返回它的输出和 Claim 的大小，然后再跑 Set Lowerbound 看是不是有那么多满足的 $r$。

那考虑怎么做 Sum-Lowerbound。我们可以判断一个数的大小，也可以判断有多少个数（都是 Set Lowerbound），但不能同时判断 $2^n$ 种数的个数。问题是种类数很多，因此先考虑取个整：将数下取整到最近的 $2^c$(这个技巧在某个 JOISC 里面用到了)。这样最多放小了 $2$ 倍，我们可以随便 Amplify gap 解决问题。考虑 $n$ 类怎么做。直接的方式就是并行跑 $n$ 个 Set Lowerbound，但也有更简单的方式：考虑 Amplify 到 $n$ 倍以上，这样大的部分一定存在一个 $2^i$，使得 $2^i$ 乘上至少是 $2^i$ 的数个数就大于了小的那部分的上界。然后直接跑一个就行了。这样对多轮更有利（但好像常数轮都可以做）。

Prf.(1.8*) 首先考虑描述这个 $IP[2]$：Verifier 会把每个 $r$ 映射到一个 $a_1$。然后 Prover 需要从 $a_1$ 返回一个 $a_2$，然后 Verifier 通过 $r,a_2$ 判定。可以发现有两种情况会使得 Prover 搞不对：一种是对 Verifier 不接受任何 $a_2$，另一种是多个不同的 $r$ 映射到同一个 $a_1$，但它们接受的 $a_2$ 不同。即 Prover 只能对每个 $a_1$ 找一个 $a_2$。那么输出 $1$ 的概率可以看成最大的 $\{(r,a_1,a_2)\}$ 大小，满足 $x,r$ 在 Verifier 处第一轮输出 $a_1$，$r,a_1,a_2$ 在 Verifier 处第二轮 accept 且对于整个集合，相同 $a_1$ 必定对应相同 $a_2$。

这也是一个集合，但我们还有相同 $a_1$ 对应相同 $a_2$ 的条件，这是难以验证的。一种想法是类似 GNI 的方式问有多少种不同 $a_1$（如果超过 $2^m/3$, Verifier 就一定能搞出来），另一种想法是只验证一个 $a_1$。但一种极端情况是一个 completeness $1-2^{-n}$ 的情况被分成了 $2^{m-n}$ 组，每组大小 $2^{n}$，而一个 soundness $2^{-n}$ 的情况被分成了两组，第一组大小 $2^{m-n}$，第二组没法得到任意解，这就难处理了。

考虑把上面两种方式合并起来：询问是否有 $a$ 组 $a_1$，每一组中我们都存在一个 $a_2$，使我们可以找到 $b$ 组得到 $a_1$ 且接受 $a_2$ 的 $r$。那么这个只需要两轮 set lowerbound 就可以验证。直接用一次看起来还不行，但这里我们可以任意选 $a,b$。

现在考虑区分大小为 $s$ 和 $2^m-s$ 的集合。考虑取 $s\leq \frac{ab}{2^k}$，这样任选一组 $ab$ 小的情况有解的概率都不超过 $2^{-k}$。然后让 $a$ 枚举 $2^i$，$b$ 取对应需要的最小值。这样 Union bound 一下 soundness 还是很小。然后考虑另一侧，如果一个东西每一步都找不到，即对于每一组 $a_i,b_i$，都没有 $a_i$ 个大小至少 $b_i$ 的集合，那么最坏情况是对每个 $i$ 有 $a_{i+1}-1$ 个大小正好是 $b_i-1$ 的。但因为每次 $a_i$ 乘 $2$，这样影响也不大，可以算出最坏情况是 $\sum (a_{i+1}-a_i)b_i$。如果每次让 $b_i\geq \frac K{2^i}$ ，那么这样不超过 $K\log K$，而这和 $2^m-s$ 还有很大差距（在 Amplify 足够的情况下。这里只用了 $\log$。），因此如果是大的情况有非常大概率可以。

Thm2. $IP[k]\in AM$

Prf. 我们接着之前的方式考虑。用上面的方式考虑第一轮交互，可以发现我们大概只需要把 $r,a_1,a_2$ 被接受换成 $a_1,a_2$ 在接下来的交互中有大概率被接受，然后对后面的东西继续证明。这里我们需要多重 bound，所以需要 amplify 到足够大然后每层降低需求。

#### IP=PSPACE: Arithmetic techniques

##### Sum of Multivariate Polynomial

考虑如下问题：给一个容易快速计算的多元多项式，现在每个变量可以在一个集合中取值，对所有情况求和。

一个简单的例子是 #kSAT：我们把每个 clause 暴力展开，然后乘起来。因此这个问题显然 #P-complete。然后我们可以在 IP 中解决这一问题（判定和是否正确）：

我们首先约定一个足够大的 $F_p$，在这上面做运算。每一轮我们尝试消掉一个变量。首先 prover 给出如果对其它变量求和，得到的关于第一个变量的多项式。接着 verifier 先验证对第一个变量求和是否正确。如果正确，则其对第一个变量任意取一个值，然后递归验证后面的求和是否和 prover 给出的多项式相符。

Prf. 首先 prover 真的按照这样去做就做到了 completeness=1。然后如果 prover 拿了一个错误的值，那么他给出的多项式必然是错的，因此下一轮取值正确的概率不超过 $1-\frac dp$，其中 $d$ 是多项式次数(Cauchy-Schwarz)。因此 soundness 不超过 $1-(1-\frac dp)^n$，只需要 $p$ 正常地大即可。

##### IP protocol for TQBF

考虑把 TQBF 写成代数形式，那么直接地方式是把 $\exists$ 写成求和，$\forall$ 写成乘积。但这样得到的东西有 $2^n$ 次，这显然不行。

但我们的求值点只有 $0,1$，所以理论上我们可以把高次的 $x_i^k$ 变成一次，从而做到只有 $n$ 次。或者说，考虑如下算符：

$L_{x_i} f=(1-x_i)f|_{x_i=0}+x_if|_{x_i=1}$

可以发现 $L$ 之后不影响 $0,1$ 的取值，同时次数确实降低了。因此我们考虑每乘一下就对所有算符做 $L$，这样中间次数都不超过 $2n$。此时我们有三种操作：$\sum_{x_i\in \{0,1\}},\prod_{x_i\in\{0,1\}}$ 和 $L$。注意 $L$ 可以多次改变同一位置变量的值。

然后考虑从外向内验证，每一次要求返回内层求和后关于外层最初变量的多项式，如果过不去当前算符就 reject，否则随机一个取值 $a$ 继续向内验证。 $\square$

因此 $IP=PSPACE$。

Note. 代数技巧是 non-relativlize 的。事实上随机一个 oracle 有 $1$ 的概率 $IP^O\subsetneq PSPACE^O$。

我们可以用这个证明直接说明 $IP$ with completeness=1 等价于 IP，因为上述证明显然 completeness=1。

Thm. 如果 $PSPACE\in P/poly$，则 $PSPACE=MA$。

Prf. 我们知道 prover 只需要 PSPACE，那么考虑 Merlin 直接把 prover 对应的 circuit 发过去，然后 Arthur 随机验证。

简单的推论是如果 $EXP\in P/poly$ 则 $EXP=MA$：先 $PSPACE\in EXP$，再用上面一行，最后用 Meyer's Thm。

另一个类似的证明是积和式：考虑枚举第一行选哪个，问题可以规约到 $n$ 个更小的积和式上。那么考虑在这上面插值，得到一个多项式环上的行列式，其中 $x$ 取 $1,2,\cdots,n$ 就得到原来的 $n$ 个积和式。那么我们问多项式上的行列式，然后验证求和，接下来随机带入一个值继续验证。

#### Multiprover IP

在另一种 IP 模型中，我们有两个 prover。他们可以在开始前共同确定策略，但 IP 开始后他们不能再交换任何信息。这样得到的 class 被称为 MIP。

直观说明 MIP 可能更强的方式：~~囚徒困境~~ 单个 prover 时他可以用之前的问题来构造答案，但多个 prover 时我们可以通过换一个 prover 询问来避免这种情况。

事实上在接下来的 PCP 章节我们会看到 MIP=NEXP。这里有一些更简单的练习：

ex11. $MIP\in NEXP$

Prf. 考虑直接搜 Prover 策略对应的表。

ex12. 这里的定义只用了两个 prover。但我们可以证明 poly 个 prover 和两个 prover 等价。

Prf.(0.7*) 考虑之前的思路：通过换 prover 避免使用之前的信息。那么考虑先和一个 prover 模拟整个交互，然后尝试用第二个 prover 验证。直接的验证方式是和他模拟一个 prover 的交互，但因为这就给出了信息，我们不能再模拟其它 prover 的交互。但这已经可以解决问题了：考虑随机一个 prover 验证，那么如果第一个 prover 给出了不正确的操作（有一步使用了其它信息）则我们有 $\frac 1{poly}$ 的概率发现；而如果一个 Thm 是不对的，则 prover 想证明它有 $2/3$ 的概率需要造假。因此跑很多轮，第二步验证失败直接 reject，否则 majority vote 即可。

#### Self-reducibility

在之前 $IP=PSPACE$ 的证明中，我们相当于把求和递归为了一个小一点的求和。从这一方式出发我们可以得到如下一些定义：

1. 一个问题是 Downward self reducible 的，如果存在一个 poly 的图灵机使得如果我们能解决所有大小小于 $n$ 的问题，我们就能解决大小为 $n$ 的问题。即令 $L_k$ 为一个解决所有大小小于等于 $k$ 问题的 Oracle，则 $R^{L_{k-1}}(k)=L_k$。
2. 一个问题是 Random self reducible 的，如果我们能将解决它规约到解决同问题下若干个输入 $r_1,\cdots,r_k$，且每一个这样的输入单独看都是均匀随机的。

上面的两个证明都用到了 Downward 的性质。

ex9. 如果 $L$ 满足 Downward，则 $L\in PSPACE$。

Prf. 直接拿出 $R$ 开始搜。

一个 Random 的应用是，如果我们可以解决大部分的输入，我们就可以用 random self reducible 来(with high probability)解决所有输入。例如，对于积和式，考虑随机一个 $R$，算 $perm(A+xR)$。显然这是关于 $x$ 的多项式，那么我们可以插值得到 $x=0$ 的解。

#### Program checking

考虑如下问题：给一个语言 $L$，给一个程序 $f$ 和一个输入 $x$。我们需要判定 $f$ 是否正确，至少是在当前输入下。有如下限制：

1. 如果 $f$ 是完全正确的，那么我们输出 yes 的概率至少是 $2/3$。
2. 如果 $f$ 在当前输入就不对，那么我们输出 yes 的概率只多是 $1/3$。

这被称为 Program checking。

例如，考虑 Graph Isomorphism。如果程序输出 Yes，我们可以用 Downward 的方式来判定正确性(ex10)：考虑枚举一对点删掉，问程序是否同构。如果找到一组就继续递归，如果出问题就 reject。

如果输出是 No，那么我们需要判定 GNI。一种想法是用之前的 IP protocol：我们每次随机一张图重排，问结果和第一张图是否同构。如果两张图不同构则答案唯一，同构则原程序得到的是均匀输入从而无法判定。

类似刚才的思路，如果 $L\in IP$ 且正确的 prover 可以 $P^L$ 地实现，那么 $L$（至少在这一方向）存在 checker：直接和那个 prover 跑 IP 即可验证。

ref. ch17(#P), ch22(PCP). ch19/20

### IX Basic Cryptography

因为某(ming)些(zi)原(tai)因(chang)密码学的人喜欢简写，这里列举一些用到的简写：

1. PPT 表示 probabilistic polynomial time ~~我本来想写BPP~~
2. $U_n$ 表示均匀随机
3. OWF: One-Way Function
4. OWP: One-Way Permutation
5. PRG: PseudoRandom Generators
6. 在没有特殊说明时，secure 指 computationally secure

#### Encryption Schemes

密码学的一大基本任务是传递信息；更进一步的，“安全”地传递信息。

我们记明文（一个 01 串）为 $x$。现在 Alice 想把 $x$ 发给 Bob，但直接发出去则任何一个监听消息的 Eve 都可以得到 $x$。为了做到信息安全，我们采用如下的加密方式：Alice 和 Bob 事先约定一个(随机)的 Key $k$，这个 key 对 Eve 是未知的。然后 Alice 用 $k$ 对 $x$ 加密，Bob 也用 $k$ 解密密文。

我们认为 Alice 和 Bob 都必须是 efficient 的，即 P 或 BPP。这里我们选择使用 P。

记 Alice 的算法为 $E$(ncyption)，Bob 的算法为 $D$(ecyption)。我们用下标表示 Key，参数表示明文/密文，例如 $E_k(x),D_k(y)$。那么这样的 Encryption Schemes 首先需要让 Bob 能够正确解密，即：
$$
\forall x,k, D_k(E_k(x))=x
$$

我们通常只考虑一个长度的问题，记明文长度 $|x|=m$，Key 长度 $|k|=n$。

这个条件只考虑了正确性，还没有考虑传输的安全性。例如，$D_k(x)=E_k(x)=x$ 也满足上一个定义。

直观上看，“安全”意味着 Eve 不能从 $E_k(x)$ 中得到任何关于 $x$ 的信息。但我们还有一个 $k$，因此在 $k$ 随机选取时，Eve 实际看到的是一个 $E_k(x)$ 的分布，记为 $E_{U_n}(x)$，其中 $U_n$ 表示 $n$ 位均匀随机01串。Eve 可以从分布推断信息，由此我们可以得到如下若干定义。

##### The Limitation of Perfect Security

一种极端情况是 Eve 有 +inf 的算力。此时如果两个分布有一点不同，Eve 一定能用足够的算力把它区分出来。因此为了做到完全的安全性，我们有如下定义：

Perfect Security: 对于任何 $x$，让 $k\sim U_n$ 得到的分布 $E_{U_n}(x)$ 完全相同。

一种满足 Perfect Security 的方式是，我们让 $m=n$，然后直接 $E_k(x)=x\oplus k$。显然(ex1)任意 $x$ 都会得到均匀分布。这也被称为 One-Time Pad。

这一方式显然有很大的局限：我们需要先约定和数据一样大的 key。且这个东西显然不能复用(One-Time)，否则多 xor 几下就能得到一些东西。

更困难的是，这些局限对所有的 Perfect Security 都成立：

ex2: 如果 $n<m$，则不可能存在 Perfect Security。

Prf. 考虑一种可能的密文 $y$，所有分布等价意味着每个 $x$ 都能映射到 $y$，也就是说 $y$ 可以通过不同的 $k$ 还原到每个 $x$。但 $x$ 的数量 $2^m$ 多于 $k$ 的数量 $2^n$。

更近一步，使用 PPT 也无法解决问题：

ex4: 如果我们把加密换成 PPT，然后要求解密完全成功，则如果 $m\geq n+10$，则一定存在两条消息的密文能被以 $\frac 9{10}$ 的概率区分。

Prf. 相当于给之前的证明带权。考虑每个密文 $y$ 里面放若干对应明文 $x$，每个 $x$ 权值为 $x$ 生成当前 $y$ 的概率。那么总权值和为 $2^m$，且每个 $y$ 中最多有 $2^{m-10}$ 个 $n$。那么所有 $x$ 的密文覆盖的权值和是 $2^{m-10}*2^m$，因此存在一个 $x$ 使得它的密文覆盖的权值和不超过 $2^{m-10}$，也就存在另一个 $x'$ 使得 $E_k(x')$ 可以被 $x$ 加密得到的概率足够小。

更进一步，我们还是只需要 NP 的判断。

##### Computational Security

上一部分的问题说明，我们需要一些更弱的安全定义，即对 Eve 的算力做出限制。我们通常限制 Eve 为 PPT，或者 PPT/poly（因为我们通常关心一个大小的问题，同时 /poly 是可以被预处理的）。

使用随机算法就需要考虑它的正确率。但与之前不同的是，这里即使是一个 $10^{-100}$ 或者 $n^{-10}$ 的攻击成功率都被认为是不安全的：如果重复这一攻击，则只需要期望 poly 的时间就能成功，这是不能接受的。

因此我们定义一个函数是小量(记作 $Negi$)的，当且仅当对于任意 $c$ 它都是 $o(n^{-c})$，即它的衰减比任何 poly 都快。我们可以认为，在只使用 poly-time 的情况下，Negi 级别的东西不会造成可见的影响。我们也把要求的错误率限制在这一范围内。

我们还需要考虑在有限时间内能推断出的信息。能推断出部分信息也是一种成功，因此这里我们要求 Eve 无法从密文中推断出 $x$ 的任何一个 bit。具体来说。Eve 可以看成一个 PPT(/poly) 的 $A$(dversary)，它输入 $E_k(x)$ 输出一对 $(i,b)$ 表示认为 $x_i=b$。显然有平凡的 $1/2$ 正确率方式，因此我们定义

Computational Security: 对于任意 $A$，$Pr_{x,k\sim U}[A(E_k(x))=(i,b) s. t. x_i=b]\leq 1/2+Negi$，即判断正确的概率比平凡多不了多少。

显然 Perfect Security 满足更强的 Computational Security(ex3)。具体来说，
$$Pr_{x,k\sim U}[A(E_k(x))=(i,b) s. t. x_i=b]\leq 1/2$$

Prf. 任何输入得到相同分布，因此我们可以固定分布分别看 $A$ 和随机 $x$，这样随机 $x$ 使得正确率只有一半。

###### Semantic Security

我们还可以用更广泛的方式描述信息：信息可以是一个关于 $x$ 的函数 $f(x)$。我们想要从 $E_k(x)$ 推断 $f(x)$。与此同时，虽然 $k$ 是随机的，$x$ 显然不一定是均匀随机的，而可能是一些别的能计算的分布：每次从这个分布中采样一些 $x$ 出来通信。

具体来说，我们定义一个长度为 $m$ 上的 $01$ 串上的分布 $X_m$ 是可采样的，如果存在一个 probabilistic poly 算法生成它。我们的安全定义为，对于任意一个这样的分布，在其之上 $A$ 都不能通过 $E_k(x)$ 更好地推断 $f(x)$。即 $\forall A,X_n, f$，存在一个 $B$ 使得 $Pr_{x\sim X_m,k}[A(E_k(x))=f(x)]\leq Pr_{x\sim X_m}[B(1^n)=f(x)]+Negi$。

Note.显然 B 的最优解是全输出 $0$ 或 $1$。事实上我们不用 /poly 就能几乎达到这一点：随机采样求值，然后 take majority 就可以高概率判断出 $p$ 是否大于 $1/2$。我们还可以用算设期末的方式做到解决所有 $p$：做多轮，每轮加倍采样次数从而判断出更高的概率。

ex9a: 证明 Semantic Security -> Computational Security

Prf. 如果存在 break computational security 的方式，那一定存在一个 bit 使得 predict 这个 bit 时正确率更高，此时可以固定这个 bit（输出别的 bit 时随机输出一个）使得这个 bit 判断正确的概率 Non-Negi，然后用这个作为 $f$ 上均匀分布即可。

ex9c: 证明 Semantic Security 等价于如下形式：我们的分布中只有两个均匀分布的串 $x_0,x_1$，其中 $f(x_i)=i$。

Prf. 显然原来的比这个强。另一方面，如果我们能 break 原来那个，考虑 $A$ 在原来每个 $f(x)=1$ 的 $x$ 上的表现和在每个 $f(x)=0$ 的 $x$ 上的表现。因为总正确率是 $\frac12+Non-Negi$，那么两边表现最好的加起来的表现也是 $\frac 12+Non-Negi$。

###### What if P=NP?

我们希望上面的定义能够支持更高效的加密方式。但这里限制了 Eve 的算力，而我们并不知道 PT 或者 PPT 有多强，更具体地我们不知道它和我们的加密之间的差距。例如，很多加密可以看成 BPP vs NP，但如果 P=NP 则这个直接炸了，例如如下结论：

如果 P=NP，则对于任何一个 $m>n$ 的加密方式，我们总能让它不 Semantically Secure。具体来说我们可以找到一对 $x_0,x_1$，使得存在一个 poly 算法能区分这两的输出。即 $Pr_{i\in\{0,1\},k\sim U^n}[A(E_k(x_i))=i]\geq \frac 12+c$。具体来说这里可以做到 $\frac 34$。

Prf. Naive 地，我们考虑造点 NP 的判断方式。显然如果 $E_k(x_0)$ 可以到密文但 $E_k(x_1)$ 不能到，我们就能完全正确判断这部分，然后剩下输出 $x_1$ 就够了，这是可以用 NP 写出来的。然后考虑能不能找到一对 $x_0,x_1$，使得 $x_1$ 加密的结果能被 $x_0$ 覆盖的概率足够小。

考虑随便拿一个 $x_0$，此时它的 $E_k(x_0)$ 覆盖了不超过 $2^n$ 个密文。为了能解密，每个密文最多对应 $2^n$ 个原文。那么我们考虑所有 $x_1$，只有 $\frac{2^{2n}}{2^{n+m}}\leq \frac12$ 的情况会映射过来，因此一定存在一个 $x_1$ 使得覆盖概率足够小。

因此为了让这些定义工作，我们肯定需要一些假设。但 $P\neq NP$ 也没那么好用，我们有一些更好用的假设(Crypto Primitives)。

#### One-way functions and permutations

我们称一个东西是 one-way 的，如果算 $f$ 很简单，但算 $f^{-1}$ 很困难。

##### One-Way Functions

我们称一个 poly computable 的函数 $f$ 是 OWF，如果它很难被算出一个原像。具体来说，对于任意 $n$ 和任意 PPT $A$，
$$
Pr_{x}[A(f(x))=x' s. t. f(x')=f(x)]\in Negi
$$

或者写成 $f(A(f(x)))=f(x)$。

Thm.(ex5) 如果 OWF 存在，则 $P\neq NP$。

Prf. 我们直接问上述问题的判定性版本：给一个 $y$ 和一个前缀 $x_p$，问是否存在满足这个前缀的原像 $x$。显然解决这个就可以 poly 找到解。这个问题显然在 NP 中，但如果它在 P 中就说明 $f$ 可以被逆向出来。

我们还有一些简单性质：

ex6a: 如果存在 OWF，则存在可以 $O(n^2)$ 甚至更快计算的 OWF。

Prf. 考虑如果存在一个 $O(n^{c})$ 的 OWF，我们往后面 pad $n^{c/2}$ 个 $0$，那么逆向还是得逆向前面部分，这还是 hard 的。

ex6b: 我们甚至还有 universal OWF：如果存在 OWF，那么如下操作定义的 $f^*$ 一定是 OWF：将输入分成 $\log n$ 份，分别放入表示为 $1,2,\cdots,\log n$ 的图灵机分别跑 $O(n^2)$ 步（不停机就输出全 $0$），然后拼接输出。

Prf. 显然逆向需要逆向每一段，我们总能枚举到那个很快的 OWF，那么逆向那一段的算法就逆向了原来的 OWF。

一些常用的人们还不会的逆向包含：

1. Multiplication and Factoring。给两个大质数 $p,q$，我们容易算出 $pq$。但反过来分解质因数现在人们还不会。

2. RSA/Rabin。RSA 函数通过如下方式定义：考虑 $n$（通常 $n=pq$）和 $e$ 使得 $(e,\varphi(n))=1$。我们令 $f$ 为 $f(x)=x^e\pmod n$（我们只考虑互质的情况）。与之类似的是 Rabin 函数：我们取 $n=pq$（$pq$ 都是 $4k+1$ 型质数），要求 $x$ 是模 $n$ 的二次剩余，然后让 $f(x)=x^2\pmod n$（这不满足 RSA 的限制）。

值得一提的是，这里如果我们知道 $n$ 的质因数分解，那么逆向非常简单：解 RSA 只需要算 $e^{-1}\pmod{\varphi(n)}$（Note. 算 $\varphi$ 和分解等难），后者只需要分开做质数情况（至少有一个最经典的 RP 算法）然后 CRT 合并。这样的性质对于 Public-Key Encryption 是很有用的：加密可以由任意知道 $n,e$ 的人进行，但解密只能由知道分解(trapdoor) 的人进行。（虽然 PKE 看起来(black-box) 比 OWF 难多了）

我们还可以证明解 Rabin 和分解等难：

ex7: 如果我们能以 1/polylog 概率在 polylog 时间内逆向 Rabin 函数，则我们可以分解 $N=pq$。

Prf.(0.75*)我们的做法非常简单：随机 $x$，然后让它逆向 $x^2\pmod n$。

注意到我们有四种方式得到同一个输入（CRT 一下），但逆向只会返回其中一种，那么如果逆向返回的和我们的值正好在模一个质数下不同（1 vs -1），那么两个值做差得到的就是某个 $p$ 的倍数但同时不是另一个的倍数。因此我们只需要不断用逆向结果减去 $x$ 和 $N$ 取 $\gcd$ 即可。

但对于 RSA 我们还没有这样的等价。

上述结论也相当于说，如果我们能解决 Non-Negi 部分的输入，我们就能解决整个原问题（通过分解）。这也是一种 Self-reduciblity。我们还有另一个例子：

ex8: 如果我们能解决固定 $g,Z_p$ 下一小部分输入的离散对数问题，我们就能解决整个问题。

Prf. 我们随一个 $x$，问 $k*g^{-x}$ 的结果，然后将答案加上 $x$。显然我们的询问是均匀随机的。超过 $p-1$ 的问题可以稍微处理一下。

##### One-Way Permutations

称一个函数是 OWP，如果它是 OWF 且它是单射。

OWP 显然不弱于 OWF。同时我们还有 Black-box separation。

对于 OWP，我们有更直接的感受它的强度的方式。

ex16(*) 如果 OWP 存在，则存在两个可 PPT sample 的 graph family $A,B$，使得 $A,B$ 是 computationally indistinguishable 的，但 $A$ 一定能被三染色，$B$ 一定不能被三染色。

Prf. 直接看 3col 很难看出东西。但我们只需要记住：3col 是 NP-c 的，存在方式从 SAT 规约到它。

同时，我们需要把 distinguish 变回之前的那些模型。最简单的方式是使用 predict next bit：我们将从 $f(x),r$ 预测 $<x,r>$ 的问题变为判定是否 $<x,r>=1$。那么因为任何 PPT 不能比随机显著好地判定这个东西的值，它就不能 distinguish 这两个分布：因为两个分布概率相同，所以 distinguish 这个等价于更好地判定下一位。

另一方面，这个问题显然可以写成 SAT，然后就显然可以写成 3col。

#### Pseudorandom generators

新年快乐。

另一种 Crypto Primitive 是伪随机生成器：我们可以生成一些看上去随机的字符串。

首先，这里的生成指可以确定性地通过更小的随机串生成更大的串。即我们的输入是 $n$ 位（随机）串，然后我们确定性地生成一个长度为 $l(n)>n$ 的串。

然后我们还需要定义什么是随机。我们很难说一个串是否足够随机（理论上编码复杂度是可行的，但这东西 undecidible）。我们可以讨论一个分布的随机性，但显然我们不能做到和随机分布一致，或者统计上差 eps（因为我们只有 $2^n$ 项，绝大多数东西我们都生成不了）。但与之前一样，我们可以从 computational 的角度定义随机，即任何一个 PPT 都不能很好地分辨两个分布。

具体来说，我们称一个 poly 的 $G:\{0,1\}^n\mapsto \{0,1\}^{l(n)}$ 是一个安全的 PRG，如果对于任意 PPT $A$ 我们都有
$$
|Pr[A(G(U_n))=1]-Pr[A(U_{l(n)})=1]|\in Negi
$$
其中 $G(U_n)$ 表示将 $U_n$ 作为输入得到的输出分布，剩下的类似。

这里的这个定义可以进一步扩展：我们称两个相同大小的随机串分布 $X,Y$ 是 computationally indistinguishable 的，如果 $\forall PPT A$，

$$
|Pr[A(X)=1]-Pr[A(Y)=1]|\in Negi
$$

那么这个定义可以重写上面 PRG 的定义(ex15b)，也可以重写 Semantic Security 的定义(ex15c)，同时我们有简单的结论：

ex15a: 如果 $X,Y$ 是 CI 的，那么对于 poly-time 的 $f$，$f(x),f(y)$ 也是。

Prf. 我们可以把分辨的函数 $A$ 换成 $A\circ f$。

因此它们确实看起来等价，且经过别的东西后还是看起来等价。

#### Reductions between different primitives

事实上我们可以知道 OWF, PRG, PRF 和 Signature 都可以互相规约，OWP 看起来比它们强。但这些太难了我不会，这里证一个简单的命题：用 OWP 构造 PRNG。

##### PRG <-> unpredictable functions

我们考虑另一种伪随机的定义方式。在日常应用中，我们经常让 RNG 生成一串数，此时前面的数变成了已知信息。那么此时一种安全的定义方式是，给定 $y=G(x)$ 的一段前缀，我们不能在 $poly(n)$ 的时间内很好的 predict 下一位。即 $\forall B$
$$
Pr_{x\i\sim U_n, y=G(x), i\in[l(n)]}[B(1^n,y_{1,\cdots,i-1})=y_i]\leq \frac12+Negi
$$
Note. 这里的 $1^n$ 只是为了 padding 复杂度。

Note2. 对 $i$ 的期望容易和存在 $i$ 相互转化，因为 Negi 还是你 Negi。

首先我们可以知道满足之前条件的 PRNG 一定满足 unpredictability：predict 可以看成对 $G(x)$ 的一种 test，那么它不能得到比真随机的 $\frac12$ 显著好的结果。

另一方面，我们也有另一个方向的结论：

Thm. 如果对于当前 $G$ 存在一个 $A$ 能够 break PRG 的性质，那我们就存在另一个函数 break predict next bit。

直观上看，搞整个函数和依次 predict 是相同的。但我们需要更正常的方式把 predict 每一位串起来。在另一些课程中我们看到过，串联两个东西的一种经典方式是，考虑一个的前缀和另一个的后缀拼起来，然后一步一步推过去。

Prf. 考虑 Hybrid Argument。记 $X_i$ 表示前 $i$ 位按照 $G$ 生成，之后均匀随机。考虑 $A(x_l=U_l),A(x_{l-1}),\cdots,A(x_0=G(U_n))$，这个序列逐渐偏离了一个 non-Negi 的值。因为它只有 poly 长度，那么必定存在一步的变化是 Non-Negi 的。关注这一步，相当于如果随一个之前的前缀，后面也随机，这一位上如果是 $G$ 生成($A(x_{i-1})$) 和随机生成 ($A(x_i)$) 的结果是有 Non-negi 的差距的。例如，如果此时 $G$ 生成下一位时输出 $1$ 概率更大，那么因为上一个分布是对于每个 $k$ 考虑这一位的两种情况，可以发现下一位相反时输出 $0$ 的概率更大。那么我们考虑随机一个试看看，如果结果 $1$ 就输出，否则倒着输出。

因此我们考虑如下 predict 方式：我们假设 $A$ 在 $G(U_n)$ 上的结果更大。随机后面所有位（包含当前位），然后跑一个结果出来，如果它是 $0$ 就反转当前位输出，否则直接输出。那么第一步猜对时我们得到 $0$ 导致反转的概率 Non-Negi 地小于第一步猜错时反转的概率，那么正确率就是 $\frac12+Non-Negi$ 的。

由此我们可以进一步得到如下结论：

##### PRG: Different stretches

ex10: 如果存在 $l(n)=n+1$ 的 PRG，那么我们可以直接构造 $l(n)=n^c$ 的 PRG。进而不同 $l$ 级别的 PRG 都是等价的。

Prf.(0.6*，没有手把手教一遍 1.6* 往上) 考虑拿着 $n+1$ 的 $G$ 开始用。每次我们把前 $n$ 位拿出来 PRG 一次然后和后面拼起来，直到长度足够。

为什么这能对？如果存在 $A$ 能够 break 后面的 $G'$，那么它能在某一步更好的 predict 某个 bit。考虑利用它来攻击原来的 PRG。首先如果 $A$ 能 predict 前 $n$ 位中的某一个，那么 PRG 的假设可以说明前 $n$ 位每一轮之后都是 Computationally Secure 的，这就矛盾了。如果它能 predict 后面某一位，那这一位的生成过程一定是某一步 $G$ 之后把最后一位拿出来，之后再也不变。考虑这一步 $G$ 的情况。在这之前的前 $n$ 位 computationally 是个随机分布，之后我们对前面继续操作直到最后，但这部分都和拿出来的这一位无关。如果我们能通过前面操作的结果 predict 之前拿出来的这一位，那我们就可以直接 predict 原先的 PRG 的最后一位：如果我们拿到了前 $n$ 位，我们可以用刚才的方式扩展出前面最后的情况，然后就可以用之前的 $A$ 还原。

现在我们只需要最后一步。

##### OWP -> n+1 PRG

我们用一个高明构造完成最后的问题。

Thm. 如果 $f$ 是 OWP，那函数 $G(x,r)=f(x),r,(x\odot r)$ 是 PRG。其中 $\odot$ 表示点乘再模 $2$。

Prf. 考虑反证，通过 break $G$ 推出 break $f$。因为 $f$ 是 perm，前 $2n$ bit 是个完全随机分布，因此我们只能 predict 最后一个bit。所以我们只需要说明，如果存在算法能够以 $\frac 12+Non-Negi$ 的概率通过 $f(x),r$ 反推 $x\odot r$，我们就有足够的概率逆向 $f(x)$。

此时我们可以只关注单个 $x$。存在足够多的 $x$ 使得这个 $f(x)$ 下的反推成功率不小于 $\frac 12+Non-Negi$(Note. 两个 Non-Negi 不一样)。那么我们只需要做单个的问题。直接看 $f(x)$ 没法做，我们考虑直接扔掉 $f(x)$ 看后面，那么相当于如下问题：有一个未知的 $x$，每次我们问 $r$ 时可以得到一个 $x\odot r$，但它的正确率只有 $\frac 12+Non-Negi$。现在我们要还原 $x$。

Easy Case： $p>\frac 34+Non-Negi$。

考虑一种直接的方式：我们随其它位置，然后让某个位置取 $0,1$。此时如果两个回答都对，我们就能确定这个位置上 $x$ 的值。但如果 $p$ 足够大，都对的概率至少有 $\frac 12+Non-Negi$，因此我们只要每一位多随机几次就能找到答案。

回到困难的情况，(**)这里的问题是正确的 $r$ 是可以被安排的，我们甚至可以使得每一位上两个回答正好错一个的占比 $1-Non-Negi$，这就全错了。这里甚至可以有一些情况只有 $n^{-c}$ 的情况输出非零。但好消息是我们拿到一个解可以去验证它到底对不对，因此我们不需要考虑别的情况，只需要看能不能以足够概率找到正确的解。一种想法是，我们考虑对于每一对 $x,x\oplus e_i$，我们不再询问两个值，而是询问一个猜另一个，避免任何被安排的问题。随机一组 $x$ 我们很难猜对(ex13)，但有一些简单的方式让我们需要猜的情况数很小：考虑随机一组某个大小的基，然后拿出它张出的整个线性空间。此时我们只有 $O(|X|)$ 的情况数量需要枚举。

更近一步，我们可以发现这样选不影响之前的“多随机几次就能找到答案”：容易证明这样随机是 pairwise independent 的，那么我们数方差就可以解决问题。

ex13: 如果我们随机 $n$ 个 $r$，那么通过所有的 $x\odot r_i$ 我们有常数概率还原 $x$，因此我们显然不能直接猜。

Prf. 直接考虑线性基一个一个插入，那么满秩率是 $\prod_i(1-2^{-i})$。

ex14: 算数。

结合上面的三步，我们最终得到了一个从 OWP 到 PRG 的构造。

仔细看一下这个构造，它得到的结果相当于 $f^{k+1}(x), r, f^k(x)\odots r, f^{k-1}(x)\odots r,\cdots$，相当于给了前面的东西我们也很难预测 $f^{k-1}(x)$ 的表现。事实上我们确实有如下结果：

ex11. 对于任意 poly 级别的 $k$，如果 $f$ 是 OWP 那么 $f^k$ 也是。

Prf. 如果逆向了 $f^k$，考虑逆向后跑 $k-1$ 次 $f$，就逆向了 $f$。

Note. $k\in poly$ 是关键的，不然是个人都会解 $k=(2^n)!$。

但这东西对 OWF 就无效了：

ex12. 假设 OWF 存在，找到一个 OWF，使得 $f^{n^c}$ 不是 one-way。

Prf. 考虑上述证明的问题，可以发现如果 $f^k$ 原像不存在，那这样就搞不回去了。例如这里可以先找一个 OWF，然后我们再构造一个：让前一半跑 OWF 然后移到后一半，剩下的填 $0$。显然这还是 OWF，但显然两轮后所有数输出都一样。

##### Encryption from PRG

非常直接的方式：我们拿 PRG 生成一个和 $x$ 等长的 $G(k)$，然后跑 One-time Pad。

因为 $G(k)$ 是 computationally secure 的，因此这个串看起来是随机的，所以后面再加 OTP 还是对的。

进一步我们还有：

ex9b: 证明这样做是 Semantically Secure 的。

Prf. 可以发现 Semantic 定义的前半段相当于对 $G$ 的如下 Test：我们采样一个 $x$，然后异或，再跑 $A$。而如果我们把 $G(k)$ 换成随机，则 $A$ 拿到的输入就是纯随机，此时 $A$ 输出概率性结果不如 all in 一种结果，因此 这种情况下它比不过定义的右边。

因此这说明 $A$ 可以区分 $x\oplus G(y)$ 的分布和纯随机分布。用一个采样 $x$ 再异或的操作，这组合起来就相当于我们可以区分 $G(y)$ 的分布和随机分布。

##### Pseudorandom Functions

我们还可以定义 PRF：对任何 PPT 都看起来像随机函数的 poly 函数 $f$。为了定义随机，我们首先需要用上随机函数的分布，即这个函数可以写成 $f_k:\{0,1\}^{|k|}\mapsto \{0,1\}^{|k|}$ 且 $f_{U_n}$ 看起来和随机函数一样。

然后我们还需要定义“看起来像随机函数”。这里的问题是函数的显式表示是指数大小，任何一个 PPT 都不能显式输入函数。因此我们使用 Oracle 的定义：distinguisher $A$ 此时可以调用 $f_k$。我们要求它不能很好地区分这个函数分布和随机函数分布，即
$$
|Pr_k [A^{f_k}(1^n)=1]-Pr_g[A^{g}(1^n)=1]|\in Negi
$$

这也可以看成一个指数级的串，其中 distinguisher 只能问 poly 位。

###### PRF <-> PRG

我们可以直接从 PRF 得到 PRG：考虑用 $f_k(0),\cdots,f_k(i)$ 作为 PRG。那么任何一个 distinguish 后者的算法都可以直接通过问前这么多位变成 distinguish PRF 的算法。

反方向也是成立的：

Thm. 如果存在 $l(n)=2n$ 的 PRG，则存在 PRF。

Prf. 我们考虑一个 GGM Tree：定义 $G_0(x)$ 表示 $G(x)$ 的前半段，$G_1(x)$ 表示后半段。然后我们得到
$$
f_k(x)=G_{x_n}(G_{x_{n-1}}(\cdots(G_{x_1}(k))))
$$
或者说，我们重复 $n$ 轮如下操作得到一个长度 $n2^n$ 的串表示它的 truth table：从 $k$ 开始，每次将当前串划分为一堆长度 $n$ 的串，然后将每个串 $x$ 变成 $G(x)$ 再重新拼接。

或者我们也可以看成一棵树，根是 $k$，每次 $G$ 完分成两半，根据 $x$ 的值决定走哪一部分，直到走到叶子。

现在我们只需要证明，如果存在算法能够 distinguish 这个 function，它就能 distinguish $G$。

Prf. 考虑任何一个 distinguish 算法 $f$，假设它询问了 $T$ 位，那么我们只需要调用 $O(nT)$ 次 $G$ 就可以得到需要的询问：把它们到根上的全部调用一遍。如果存在 PPT 很好地区分，那么存在一个随机方式能够很好地区分，从而我们只需要关注一种随机情况。此时没用到的树上节点都可以看成随机一个 $2n$ 串继续分，那么我们只改变了 $nT$ 个节点就使得 $f$ 的输出有了直接的变化。那么我们继续考虑 Hybrid Argument：从上往下每次把一个 $G$ 变成随机。此时一定存在一步使得前后变化 Non-Negi。但此时两者只差一步 $G$，它的输入是完全随机（上面的先删掉），从它到整个 function 的过程可以模拟出来。因此我们可以通过模拟输出再调用 $f$ 来 distinguish 这一步的 $G$。

#### Zero-Knowledge Proofs

一些上一章的扩展。

字面意思上，我们称一个 IP 是 Zero Knowledge 的，如果 verifier **只** 知道了这个命题是真的，不知道任何其它信息。

更严谨地说，对于 NP 中的语言，我们使用如下方式定义 ZKP：

1. 首先它需要满足正常的 Completeness 和 Soundness。更近一步，我们要求 Completeness 中合法的 Prover $P$ 只有 PPT（但 soundness 中的 $P^*$ 可以任意），但它可以事先拿到这个 NP 问题在这一输入下的一个 certificate $u$。
2. 如果答案是 Yes，则对于正确的 Prover $P$，任意一个 PPT Verifier $V^*$ 和 $P$ 交互的结果（分布）都可以被一个不知道 $u$ 的 Simulator $S^*$ 模拟出来。即对于任意 $V^*$，存在 $S^*$ 满足其**期望**运行时间为 poly，且 $S^*(x)$ 输出的交互过程分布和 $<P,V^*>$ 的交互过程分布相似。

第二点使得只要 Verifier 相信了答案是 Yes，整个过程就可以被模拟出来，从而它确实是 ZKP。

对于相似的不同定义可以得到不同级别的 ZKP。其中包含：

1. Perfect Zero Knowledge(PZK) 要求分布完全相同。
2. Statistical Zero Knowledge(SZK) 要求分布的统计差距小于一个常数。
3. Computational Zero Knowledge(CZK) 要求两个分布不能被任何 PPT 有效区分。

##### GI in PZK

关于 GI 的一万个知名 IPS 之一.jpg

假设输入图是 $G_0,G_1$，certificate 是 $G_1=\pi(G_0)$。考虑如下方式：

1. Prover 随一个 $\pi_1$，然后输出 $\pi_1(G_1)$
2. Verifier 随一个 $i\in\{0,1\} 并输出，相当于要求 Prover 给一个 $G_i$ 到上一轮 Prover 输出的 $\pi_1(G_1)$ 的同构。
3. Prover 直接输出 $\pi_1$ 或者 $\pi_1\circ \pi$。
4. Verifier 验证这个排列是否将 $G_i$ 映射到了第一轮给的图。

Completeness: 如果同构显然上述策略给出了完全正确的方案。

Soundness: 如果无解，那么第一轮输出的图最多和 $G_0,G_1$ 中的一个同构，那么第二轮之后 Prover 只有一半概率得到解。

Zero-Knowledge：考虑如下 Simulator：我们随一个 $G_i$ 开始随同构，然后把这个结果给 Verifier。如果 Verifier 输出的 $i$ 和我们一开始随的一样我们就能回答问题，否则我们直接 restart。如果两图同构，则第一步之后我们的分布和从一张图开始随同构的分布相同，且我们有 $\frac 12$ 的概率猜对 $b$，然后就可以了。

##### Bit Commitment With OWP

一种证明的常见需求是，Alice 先随机一个数但不告诉 Bob，之后 Bob 提供一些信息后 Alice 再揭示这个数。问题是我们需要保证 Alice 不能在知道更多信息后修改这个信息，即 Commitment。一个更通俗的描述是，Alice 把这个数放到一个盒子里，用到时 Bob 再拿出来。

借助之前的 $f(x),r, x\odots r$，我们容易得到一个简单的 protocol 来发送一个 bit $b$：

1. Alice 发送 $f(x), r, x\odots r\oplus b$
2. 在验证阶段，Alice 只需要发送 $x$，然后 Bob 验证是否合法。

显然 Alice 不能改 bit，同时提前 predict 相当于通过 $f(x),r$ 预测 $x\odots r$，也就相当于 break $f$。

一个简单的例子是双方平等地随一个数：第一个人 commit 一个 bit，第二个人直接随一个 bit，然后第一个人 reveal。

基于此我们可以给出如下结果：

##### OWF -> NP in CZK

为了简便我们还是只证明 OWP 的版本。

ex17b: (Bit Commitment -> Hamiltonian Cycle)

考虑如下方式：

1. Prover 使用上述方式 commit 一个图（邻接矩阵），声称这个图和 $G$ 同构。
2. Verifier 随机发送一个 $i\in\{0,1\}$。
3. 如果 $i=0$，Prover reveal 整个图并给出同构的 $\pi$。否则，Prover reveal 当前图中的一个哈密顿回路。
4. Verifier 进行验证。

Completeness 和 Soundness 都和之前的 GI 类似。对于 CZK，同样考虑类似的操作：我们先随一个 $i$，如果 $i=0$ 就重排，否则造一个环然后别的地方随机输出。因为 commitment 是 computationally secure 的，Verifier 看不出任何差距，因此我们有 $\frac 12$ 的概率猜对，且 Verifier 最后也看不出没有 reveal 的地方我们有没有乱搞。

ex17a: 如果存在任意 NP-c 语言 $L$ 的 CZK，则 $NP\in CZK$。此时我们可以将规约放松到 Cook reduction。

Prf. 直接把每次 Oracle 调用用 CZK 处理。

### X Quantum Computer Science

你有一个负数概率，甚至复数概率。

线代警告（$\C$ 警告）

在这里我们只考虑一些必要的操作。例如，我们不会考虑 Mixed state 的使用，在更多 basis 下的测量等等。

#### Basic QC model

为了简便，我们不考虑那堆物理基础，直接从 qubit 和 computational basis 开始。

##### Qubit model

一个纯态 qubit 的 state 可以被表述为 $a|0>+b|1>$，其中 $a,b$ 都是复数，且 $|a|^2+|b|^2=1$。

众所周知(?)，单个 state 时给它全局旋转一个 $e^{i\theta}$ 没有意义（除非两个不同角度的东西加起来）。即我们一般不关心 global phase。这样的话一个态总可以写成 $\cos(\phi/2)|0>+\sin(\phi/2)e^{i\theta}|1>$。

为了简便，我们常常忽略归一化系数。

为什么写 $\phi/2$？因为有 global phase 和 $\theta$ 提供的角度，我们只需要 $\cos,\sin$ 都是非负的部分。这样 $\phi\in[0,\pi],\theta\in[0,2\pi]$，那么这可以看成一个球面坐标表达式。在这个被称为 Bloch Sphere 的球面上，Z 轴上下表示 $|0>,|1>$，X 轴前后表示 |0>+|1> 和 |0>-|1>，Y 表示的东西则在前者上多一个 $i$ 的系数。

这有什么用呢？所有常见的单qubit操作都可以看成球面上性质非常好的变换。

但我们首先需要定义什么是操作。根据一些物理定律，操作可以看成 $|0>,|1>$ 构成的向量空间上的矩阵变换，则操作必定是 Unitary 的：$AA^\dagger=I$，这里表示共轭转置。

一些常见的操作：

1. $X=\begin{bmatrix}0&1\\1&0\end{bmatrix}$，相当于翻转 $0,1$，也相当于球面上沿 X 轴旋转 $180$ 度。
2. $Y=\begin{bmatrix}0&-i\\i&0\end{bmatrix}$，相当于沿着 Y 轴旋转。
3. $Z=\begin{bmatrix}1&0\\0&-1\end{bmatrix}$，相当于沿着 Z 轴旋转。
4. $H=\frac 1{\sqrt 2}\begin{bmatrix}1&1\\1&-1\end{bmatrix}$。非常常用的操作，相当于沿着 $(X+Z)/2$ 旋转。
5. $S=\sqrt Z,T=\sqrt S$ 相当于沿着 Z 轴旋转更少的角度。

##### Multi-partite model

单个 qubit 是没什么意思的。这一套东西的关键在于多个 qubit 之间并不总是独立的，而可以进行纠缠。

单个 qubit 的态是 |0>,|1> 下的空间，多个 qubit 的状态则可以是所有 $2^n$ 个 $|0...0>,\cdots,|1...1>$ 张成的空间。例如，对于态 $(\frac 1{\sqrt 2})(|00>+|11>)$ 而言，如果两个人分别进行测量，则每个 qubit 得到 $0/1$ 的概率都相同，但两个 qubit 必然得到相同的结果。 

我们可以类似定义 $n$ 个 qubit 上的一般操作，那么它是 $2^n\times 2^n$ 的 Unitary 矩阵。比如说，我们可以定义交换操作为
$$
SWAP=\begin{bmatrix}1&&&\\&&1&\\&1&&\\&&&1\end{bmatrix}
$$
不难验证它交换了两个态。

另一个例子是 CNOT：拆解到 basis，然后将 |10> 和 |11> 交换。

###### Unitary Constraint

事实上很多常见的操作并不直接满足 $AA^T=I$。例如：

1. 常见的赋值操作显然不可逆，因此不 unitary。但 `a^=b` 是可逆的，遇到这种情况可以新开一个变量（就像某些fp语言的写法）
2. 上一条并不代表我们复制了一个态，而是我们在态当中将一个值复制了一份。$|\phi>|0>$ 到 $|\phi>|\phi>$ 的变化显然不 unitary。
3. 类似地，对于 `c=a^b`，我们可以写成 `c^=a^b`，只要新变量用的够多它就是对的。

###### Locality Constraint

另一个问题是描述一个大的操作就可以需要指数大小，这显然是我们不希望看到的（复杂度理论/实践）。 因此我们只允许局部 $k$ 个 qubit 的操作：可以看成变换矩阵别的位置 direct product 一个 $I_2$。例如，我们可以局部交换两个 qubit，别的位置不变。这样一次操作就可以由常数 $(2^{2k})$ 个复数系数表述。更进一步，我们可以随便截断一下(ex8)，以较小的误差将描述变为 poly 长度。

##### The class BQP

现在我们使用上述定义我们的量子计算过程：

1. 有 $m(n)$ 个 qubit，初始为 $|x0..0>$。其中前 $n$ 位为输入。
2. 接下来进行 $l(n)$ 次操作，每次为局部 $k$ 个 qubit 的一个变换矩阵。
3. 测量，由第一个 bit 给出结果。因为测量是随机的，我们要求正确率 $>2/3$。

我们要求操作是 uniform 的，也就是一个 TM 能够 poly 地输出这些描述。

###### Partial Measurement

有一个常见的不同之处是，我们可能先做一些测量，然后根据测量结果对剩下的位置做别的东西。

可以发现如果后面不再动这次测量的 qubit，则这里先测和后测完全等效。原因大概是考虑先测的时候只按照 basis 写开，变成 $\sum_i |a_i>|b_i>$，然后相当于每个 $a_i$ 影响后面的过程，这可以拆成一堆 unitary 过程，那么最后测是一样的(ex6+ex7)。

因此有些时候我们会选择先测，这样的好处只有描述起来简单。

#### Important QC algorithms

非常好问题：这东西有啥用？ 

常用操作：$H^n$（严格意义上应该写 $H^{\otimes n}$ 表示 direct product，但是我懒）。注意到每个 qubit 做一次 $H$ 正好相当于 FWT，这很有用。

##### Grover Search

现在给一个 $f:\{0,1\}^n\mapsto\{0,1\}$，保证只有一个位置 $w$ 是 $1$，找出这个位置。

显然经典算法需要 $2^n$ 步（再弱一点，SETH）。考虑 Q 怎么做。

定义 $|s>=(\frac 1{\sqrt{2^n}})(\sum_x |x>)$。这是个 FWT，所以 $|s>=H^n|0>$。

首先我们可以算 $f$，那么在 Q 下，我们容易实现如下映射：从 $|x>|b>$ 变到 $|x>|b\oplus f(x)>$。

这看起来只对额外 qubit 进行了操作，但是是这样吗？取 $|b>=|0>-|1>$，那么翻转正好是翻转系数。那么可以加一个 $|0>-|1>$ 过来，进行这一步操作，然后拿走这个 $|0>-|1>$。这还是一个线性变换，可以发现 $|x>\mapsto (-1)^{f(x)}|x>$。

那么从几何角度看，这就相当于在线性空间上，以 $|w>$ 为法向的超平面做一个镜像，把 $|w>$ 这一维镜像掉。

我们也可以沿着 $|s>$ 为法向翻转：我们需要做 $I-2|s><s|$，但 $H^n$ 一下这个就容易了。

那么我们可以在 $|s>,|w>$ 的二维平面上看这件事。这两个向量的内积是 $\frac 1{\sqrt{2^n}}$，所以它们的夹角几乎是 $\frac \pi 2-\frac 1{\sqrt{2^n}}$。我们可以沿着它们的法平面镜像，那么二维上面取个负号就相当于沿着它们的方向镜像。

考虑 $|w>$ 的正交向量 $|w>^*$，这个向量和 $|s>$ 的夹角几乎是 $\frac 1{\sqrt{2^n}}$。那么考虑一些反复横跳操作：考虑沿着一个翻过去，另一个翻回来，那么夹角会增加二倍 $\frac 1{\sqrt{2^n}}$。这样只需要 $O(\sqrt{2^n})$ 步，就可以从 $|s>$ 差不多转到 $|w>$，然后测量就非常高概率得到 $|w>$ 了。

##### Simon's algorithm

考虑如下问题：给定 $f:\{0,1\}^n\mapsto\{0,1\}^m$，满足存在 $a$ 使得 $f(x)=f(y)$ 当且仅当 $x=y$ 或 $x=y\oplus a$。求出 $a$。

经典算法还是需要指数时间（在 $O(\sqrt {2^n})$ 之前，我们都可以胡乱回答）。但对于 Q 我们有更好的算法。

考虑先 $H^n$，然后把 $f$ 算出来。现在相当于得到了一个 $\sum |x>|f(x)>$。

然后考虑测量右边，这样左边一定只剩下两个 $|x>+|x\oplus a>$。但我们并不知道 $x$ 是多少。如果这里直接测量，那么只能得到一侧的值，这显然没有用。

但我们可以 FWT！考虑再 $H^n$ 一次。此时态为：
$$
\sum_y ((-1)^{<x,y>}+(-1)^{<x,y+a>})|y>
$$
那么这个值非零当且仅当 $<x,a>=0$。因此每次做完这个再测量，我们会得到一个满足 $<x,a>=0$ 的 $x$。这个空间的维数为 $n-1$，且里面每个东西随机出现（系数都一样）。那么根据简单线代知识(ex9)，期望 $O(n)$ 轮就能满秩，此时即可唯一解出 $a$。

##### QFT

上面是系数上的 FWT，然后我们自然考虑更一般系数的 DFT：给定状态为 $\sum f_i|i>$，我们希望变换为 $\sum_i (\sum_j f_j\omega^{ij})|i>$。 

考虑 $2^n$ 的情况，前面忘了，中间忘了，根据 FFT 的思路，我们做第 $i$ 轮的时候需要在第 $i$ 位上旋转 $w_{2^i}^{j}$，其中 $j$ 是更低位当前写出来的值。那么这可以拆成 $n$ 步操作：每一步是下面某一位到这一位的一个 rotation。这样总共需要 $n^2$ 个 gate。

##### Shor's Algorithm

经典质因数分解。

根据经典(?)结论，质因数分解和求出 $\varphi$ 等难。可以看之前的某道题。

根据神奇结论，随机一个数的阶是 $\varphi$ 的概率不小于 $\frac 1{O(\log\log n)}$，因此只要能求阶就能算分解。

那么考虑求出阶。类似之前的情况，考虑先算 $\sum |x>|a^x>$，这个随便快速幂。然后测量右边，问题变为有一个周期 $a$，需要找到它。

和刚才 Simon's algorithm 类似，考虑测量右侧(此时得到 $\sum |k*o(a)+b>$)，然后左侧 QFT 完直接测量。直观感受我们应该得到满足 $y*o(a)/N$ 非常接近整数的方案，因为每个 $y$ 的系数是 $\sum \omega_N^{k*y*o(a)}$，这个值不接近 $1$ 时等比数列求和一下就没了。具体证明懒了。

如果 $y*o(a)/N$ 非常接近整数，那么拿 Stern-Brocot Tree 随便逼近一下就完事了。因为具体细节写出来又得写几页(ex11~16)，我懒了。

#### Relation with other classes

如果我们允许提前测量，那么显然 $BPP\in BQP$，因为我们可以 $H$ 一下然后直接读一个随机 bit。

注意到 BPP 也有一个类似这样的表示(ex4)，唯一的区别在于每一次操作不是 Unitary matrix，而是一个 Stohastic Process:矩阵元素非负，每一列和为 $1$，代表转移概率。这相当于写出 BPP 每一步所在状态的概率（类似态的表述）。显然 BPP 也能做这个：直接存一个随机结果。

另一方面，对于 BQP，如果我们只用实数而不是复数，则它的性质不变(ex5)：实部虚部分别存即可。

这说明 BQP 和经典概率的一大直观区别来源于这里“概率”可以为负，然后相互抵消。

考虑另外的方向。

##### BQP in PSPACE

Naive 的想法是直接维护每一步后 $2^n$ 个系数，但这是指数空间的。

但注意到我们没必要记住整个系数，只需要直接 dfs 系数即可，这样就是 poly 递归深度了。精度问题容易解决。

##### BQP in PP

PP 相当于数数，因此我们需要构造一个 $[0,1]$ 间的随机变量表示接受概率，它的期望大于某个界当且仅当 BQP 接受（>2/3 和 <1/3）。

那么考虑直接算接受的概率，即 $\sum c_i|i>\mapsto \sum c_i^2$。平方显然用同时跑两个处理。对于随机算 $c_i$ 的步骤，考虑之前那个递归，直接随每一步转移到哪，然后系数就是这样转移的系数（非法转移就是 $0$）。这样一个问题是系数可以为负 ，因此可以在外面加一个数。

Note. 正是加的这个数使得 BQP 不一定 in BPP，因为这一加 gap 就变得指数小了。

#### Concrete Examples

我们以 qoj5172[序程来未] 为例。题目请自行看 qoj。

##### ex1 - 1bit RNG

自己算算 Rx 多少度。

##### ex2~4 - 2bit RNG(3 measure)

随便凑凑系数，能凑出来的。

##### ex5 - State Preparation

自己算 Bloch Sphere 的旋转。

##### ex6 - State Identification

注意到给的是 正负 Y 轴，把它转到正负 Z 轴再测即可。

##### ex7 - Elitzur-Vaidman bombs

非常经典的问题。

考虑先 $H$ 一下：

1. 如果有炸弹观测，那么有一半概率炸，否则态坍缩到 $|0>$。
2. 否则态还是 $|0>+|1>$，这样等会再 $H$ 就变回 $|0>$。

那么等会再 $H$ 一下然后测量，只有坍缩的改变可能得到 $|1>$。这有 $1/4$ 概率。

##### ex8 - Pauli Matrices

手搓 XYZ 练习。

##### ex9 - SWAP

众所周知 `x^=y^=x^=y`，所以就是三个 CNOT 拼一起。

##### ex10~11 - 2-bit State Preparation

慢慢手搓，拿 Control-rotation.

##### ex12~13 - Uniform state with single 1

给定 $n$ 个 qubit，生成所有有单个 $1$ 的态加在一起的结果。

大概一个一个 rotate 过去分裂：

1. 先 |1000..>+|010...>
2. 然后对右边分裂，继续做

控制好每一步的系数。

##### ex14 - C(5,2)

用力手搓分裂。我 15 步操作暴打 std。

##### ex15 - C(6,3)

直接搓恶心至极。但注意到拿出最后一 bit，相当于 C(5,2) 加最后一位 1，和 C(5,3) 加最后一位 0。那么先 C(5,2)，再随机最后一位。如果最后是 0 就把前面全翻转。

##### ex16~17 - Function Oracle(easy)

将最后一个 bit 异或上前面的某个函数。

第一问是 bitcount，这直接分开做。

第二问是 [cnt=1]，那么容斥。

##### ex18 - Grover Search

Idea 和 Grover Search 正好相同：我就以 $|->=|0>-|1>$ 为目标做一次 CNOT，这就相当于翻转 control 上 $|1>$ 的系数。然后 H 一下就测出来了。

##### ex19 - Special RNG

本质上是准备 ex16 的态。

##### ex20 - Another Parity Game

最初被用来说明量子纠缠效果的实验的另一个版本。

大概想法是，每个人拿到一个数然后决定怎么转，这样转的总结果就说明了两个数的关系。具体忘了。

### XI PCP and Approximation

> 一个出人意料的连接

#### Approximation Problems

NP-completeness 的理论说明，有大量的问题在 $P\neq NP$ 的情况下无法被 poly 地解决。因此，一种部分解决的方式：高效求出问题（通常是 NP-Hard 的）的一个近似解，也成为实践和理论中的一大重要话题。

在近似时，优化与计数问题都可以得到近似形式。特别的，这里通常情况下要求求出一组解。

一个算法的近似比 $\rho$ 的定义有时有着不同的习惯：一种定义为它的解($sol$)和最优解($opt$)的比 $\rho=\frac{sol}{opt}$：对于各种最小化问题（set packing，规划等），此时 $\rho\geq 1$，且越小越好；对于最大化的问题（满足的数量等），$\rho\leq 1$ 且越大越好。

另一种定义是，无论如何都可以通过是否求逆让 $\rho\leq 1$，越大越好。这里采用后一种定义。

##### Examples of Approximation Algorithms

各种 NP-Hard 问题通常称为经典的近似目标。例如如下例子：

##### Max-3SAT

问题描述：给一个 3CNF(常规地，我们要求每个 clause 大小都是 $3$ 且每个 clause 内一个变量最多出现依次)，找一种赋值方式最大化满足的 Clause 数量。

Naive 的 $1/2$ 贪心：依次填变量，每个变量时考虑只剩下这个没填入的 clause，贪心满足较大的一半。

Naive 的 $7/8$ 随机(ex3)：随机一组方案，期望数量就是 $7/8$。那么根据 Markov 不等式（因为答案是整数）可以发现期望 $\Omega(\frac 1m)$ 的概率找到一组至少这么多的解。

不那么 Naive 的确定性 $7/8$(ex4)：某门课告诉我们有一些比较有用的 derandomize 期望的方式：考虑每一步确定变量时最大化确定前面这些变量时的条件期望（在这里就是每个还没被满足的 Clause 贡献 $1-2^{-c}$，满足的贡献 $1$），这样每一步都有一种赋值方式使得条件期望不减。

##### Vertex Cover

经典的 $1/2$ 做法：每次找一条没有被 cover 的边，把两个端点都选上。这样每次和答案的交至少加一。

##### Knapsack

背包问题是一个经典的任意精度近似的方式(ex12)：对于任意 $\epsilon$，考虑将权值（注意不能是重量，因为重量限制是跳变）取整到 $n\epsilon^{-1}$ 份，这样误差不超过 $\epsilon$ 倍。然后按照权值做 dp 就 $O(poly(n,\epsilon^{-1}))$ 了。

##### CSP

有一个和 SAT 类似的问题：我们把每个 Clause 换成任意的 boolean function（输入为若干个变量），然后同样最大化满足的函数数量。定义一个问题的 arity(不会翻译) $q$ 为单个函数输入变量数量的最大值。

显然 kSAT 是 qCSP 的一个特例，其中每个函数都是 $\lor$。

类似 2SAT，2CSP 也可以判定是否有满足全部函数的解(ex13)：接受 $1/2$ 种情况的函数都相当于限制单点或者限制两点相同或相反，处理完后即只剩下 2SAT 形限制。但显然 Max-2SAP 也是 NP-Hard 的。

对于一般的 qCSP，也可以类似之前的方式得到一个 $2^{-q}$ 的确定性算法(ex14)：每次最大化条件期望。

##### Approximation Hardness: a Challenge

传统的规约方式，即把一个 NP-complete 的问题规约到一个 $\rho$-近似问题，通常难以直接证明一个近似的困难性。一种显示困难的方式是(ex11)，如果把 CircuitSAT 规约到 3SAT，即找到一组解，通过 verifier 的 circuit 后变为 $1$；但即使找不到解，随便输一组进去模拟计算，只会有一个 clause 无法满足。这不可能得到任何 $\rho$ 的界。

但神奇的是，人们成功找到了另一种描述近似问题的方式：

#### Probabilistically Checkable Proof

> 直观的例子：助教改作业(bushi)

##### Definitions

我们称一个 Probabilistically Checkable Proof(PCP) 为如下形式的 Verifier-Prover 问题：

1. 与普通的读完整 Proof 不同，现在 Prover 只进行一些随机，然后根据随机读取若干位。
2. 因为上一条，我们不要求完全的正确率，而是允许一些错误。但我们只允许单侧错误：如果可以被证明，那么存在一种必定接受的方式。
3. 因为 Verifier 不读整个 Proof，我们不显式限制 Proof 的长度。

更严谨地，我们通过如下方式定义一个 $(r(n),q(n))-PCP$：

考虑一个 Proof $\pi$，Polynomial-time 的 Verifier（首先知道输入 $x$） 首先进行 $r(n)$ 位的随机，然后通过这些随机确定 $q(n)$ 个位置，询问 $\pi$ 中这些位置的值，然后决定是否接受。这里询问位置是非自适应的，不能根据之前的询问结果来决定接下来询问的位置（这在证明中有用到）。我们要求：

1. 如果 $x\in L$，则存在一个 $\pi$ 使得 Verifier 以 $1$ 的概率接受。
2. 否则，对于任意一个 $\pi$，Verifier 接受的概率不超过 $\frac12$。

这里还没有考虑常数问题，因此我们称 $PCP(r(n),q(n))=\cup (c*r(n),d*q(n))-PCP$。

Note:

1. 显然可能 probe 的位置数量不超过 $2^{r(n)}q(n)$，因此我们可以认为 Proof 只有这么长。
2. 但即使这样，Proof 也可以是指数长。
3. 但即使这样，Verifier 也只能是 polynomial-time，不然 Verifier 就直接对着 $x$ 算了。
4. 根据上一条，我们有 $PCP(r(n),q(n))\in NTIME(2^{O(r(n))}(q(n)+poly(n)))$，因为 Verifier 可以先猜一个 Verifier，然后枚举 $2^{O(r(n))}$ 种情况算概率。例如，$PCP(\log n,1)\in NP$。
5. (ex1)在常数意义下，限制中的 $1/2$ 可以换成任意常数：重复做 $c$ 次即可。
6. (ex2)如果 verifier 自适应，则可以把 $q$ 变为 $2^q$。但这没有仔细讨论。

ex6: 证明 $PCP(0,\log n)=P,PCP(0,poly)=NP$。

Proof: 注意到 $0$ 的意思是说错就一定错。那么后者显然是 NP 的定义。前者里面显然 PCP 可以啥都不做算 P，另一侧就枚举 proof。

ex7: PCP(poly,poly) 可以搓 IP，所以可以造 perm。

ex8: 如果 $NP\in PCP(o(\log n),1)$，则 $P=NP$。因此我们不能做到更好。

Proof: 注意到 $PCP(o(\log n),1)$ 可以写回一个更小的 SAT，那么如果能做就可以不断向下规约，从而多项式实践解决。

##### Examples

例如，考虑判定图不同构的问题 GNI。我们可以设计如下 $PCP(poly(n),1)$ 的方式：定义 Proof 是一个长度为 $n$ 个点图数量的串，每个位置表示这个位置对应的图与 $G_1$ 同构还是与 $G_2$ 同构。

Verifier 使用如下方式验证：随机一个 $G_i$ 进行重排，判断 Proof 给出的这一位是不是 $i$。

如果图不同构，那么上面的 Proof 就做到了 $1$ 的正确率。反之，每一位被 $i=1,2$ 问到的概率相等，从而正确率只能是 $\frac12$。

另一个例子是考虑积和式的证明，ch8给出了一种方式：每一轮将枚举第一行得到的 $n$ 个子矩阵做插值拟合，得到这 $n$ 个子矩阵的积和式的一个多项式拟合（其取 $1,2,\cdots,n$ 时为对应积和式），然后随机选择一个 $x$ 代入继续验证。那么每一轮本来需要询问代入前 $k$ 个 $x_i$ 后当前的一元多项式，现在用 $|F|^n$ 个多项式编码 PCP 的证明即可。

##### L-PCP

我们考虑另一个定义：$L-PCP(r)$ 表示一个 logspace 的 verifier，可以随机 $O(r(n))$ 位，可以单向读证明一次（不能倒回去）。

ex9：证明 $L-PCP(\log n)=NP$。

Proof(0.9*): 属于是显然的，因为验证 log 个随机 bit 很容易做。考虑另一个方向。直观的想法是随机一个 clause 验证，但这样只有 $1/m$ 查到错误的概率。然后直观的想法是重复做，但这样随机 bit 数不够。

然后我们用一个 itcs 讲的技巧：我们不需要全独立随机，只需要 pairwise 的独立。这样如果每一轮都是 $1/m$ 查到错误，做 $O(m)$ 轮后算方差就可以限制住查不出来的概率。

暴力的 pairwise-independent 做法是 $Ax+b$，但这样还需要 $\log^2 n$ 的随机。

那咋办呢？把 $GF(2)$ 换成 $GF(p)$，做模 $p$ 意义下的线性组合，这样一次就输出 $\log$，且参数还是 $\log$。 

ex10: 考虑再换一个定义：verifier 只能读连续的 $O(\log n)$ 个 bit，或者说 1/2-Gap $\log n$ CSP，但每个函数是连续 $\log n$ 个变量。证明这个定义属于 $L$，因此它很弱。

Proof(0.5*): 如果限制全部堆在一起，那直接搜就行了。但问题是这里可能不同的函数串起来，难以解决。这看起来比较 $NL$。但好消息是我们还有个 Gap。

但我们可以尝试把这东西扔掉：选择一个 $c\log n$ 的距离，沿着这个距离的倍数切开。这样可以只扔掉 $1/c$ 的函数，从而剩下的部分 Gap 仍然存在。然后每段爆搜即可。

#### PCP Theorem

非常震撼的结果：

Thm. $NP=PCP(\log n,1)$

Thm2(Scale up). $NEXP=PCP(poly(n),1)$

完整的证明留到之后的某一章。这里我们先考虑它的意义。

##### Connection with the hardness of approximation

PCP 看起来与近似无关，但首先可以发现，PCP 的过程可以被描述为另一个看似无关的问题：qCSP。

> qCSP 是 k-SAT 的一种扩展：有 $n$ 个变量，$m$ 组限制，每个限制是只和 $q$ 个变量取值有关的函数。我们需要满足尽量多比例的限制。
> 类似地，我们考虑 qCSP 的近似，即 GAP-CSP。它需要判定比例为 $1$ 的情况和比例小于 $\pho$ 的情况。

Note. 2CSP 是简单的(ex13)：去掉限制单变量的条件，然后变成一些 2SAT。

Note. 之前随机 3SAT 然后数期望的方式在这里显然成立(ex14)，只是 $7/8$ 变成了 $1/2^q$，因为每个 clause 期望可以是 $1/2^q$。

那么这个问题自然地描述了 PCP 的过程：随机 $O(\log n)$ 位，再读取 $O(1)$ 位相当于有 $poly$ 种随机情况，每种情况是否满足是一个 $O(1)$ 位相关的函数。PCP 的定义说明这个要么能被全部满足，要么只能满足不超过一半。那么自动有：

Thm. PCP Theorem <=> $1/2$-gap q-CSP is NP-Hard(for some q)

从这里出发，我们可以说明更多的近似是困难的。

###### Approx hardness for MAX3SAT

每个 qCSP 是一个 $q$ 个变量的函数，它可以被大力写成 $2^q/q$ 大小的 circuit。然后用 circuit 转 3SAT 的方式暴力搞过去，则答案为 $1$ 对应全部能被满足，答案为 $0$ 则存在一个位置不被满足。因此这样至少是 $\frac 1{2^q}$ 级别的 gap，而这是一个常数。

然后就可以开始规约了：与之前不同的是，这里需要是一个保留 "gap" 的规约。

###### Approx hardness for VC/IS

考虑从 3SAT 规约到 VC/IS。那么首先考虑之前的规约：每个变量两个点相连，每个 clause 三个 literal 成环，变量取值和literal相连。那么如果满足则存在 $n+2m$ 的方案：每个变量选一个，每个 clause 选满足的之外的两个覆盖三元环；否则一定不存在。

但这个东西不好变成 GAP 的版本，因为 gap 出比 $n+2m$ 多一点的情况时，我们不能防止在变量那一侧多选东西。

考虑一个避免这种情况的规约(ex6)：我们直接把变量侧扔掉。考虑每个 clause 7个点，对应满足这个 clause 的7种变量取值。每个 clause 内部点连边，然后不同 clause 之间冲突变量连边。这样最大独立集就是选出尽量多的满足的 clause，且不矛盾。这样就不存在双选变量的问题。那么这自动给出了 IS 和 VC 的近似界：$p/1$ 与 $6/(7-p)$。

对于 IS，我们还能有更好的结果：如果 IS 存在一个常数近似比例，那么就可以存在任意常数近似比例。这直接说明 IS 的任意常数近似都是 NP-Hard 的。

证明：考虑随便做点 Tensor Product。一种方式是点变成大小不超过 $k$ 倍的集合，两个集合间有边当且仅当它们的并是独立集。这样近似于把独立集的大小变成 $S^k$（实际上是 $\binom Sk$，但也可以把集合变成可重集）。那么考虑这样 pow 完再近似，就得到了原来更接近的近似界。

ex16：规约到下述问题：给一些有理系数线性方程，找出最多的有解方程子集。

Proof. 如果限制取值 $0,1$ 就是直接 3SAT。那考虑每个方程放点奇怪系数（多个质数幂），这样取非 $0/1$ 一定全错。

ex17：规约到下述问题：给一些 $GF(2)$ 线性方程，找出最多的有解方程子集。

Proof. 手搓每个 clause 怎么写。这里懒了。

#### Example: a simple version of PCP theorem

我们用 Walsh-Hadamard Code 证明 $NP\in PCP(poly,1)$，剩下的之后再说。

##### Walsh-Hadamard Code

如果我们直接写一个串，那它显然没法一步读任何整体信息处理。但如果我们直接存整体信息，我们又需要验证它的正确性。因此考虑对串进行一些编码，这个编码需要满足能读出整体信息，同时还能确保正确性。

Walsh-Hadamard 是这样一个构造：对于 $n$ 位串 $s$，我们记录 $2^n$ 个位置，第 $i$ 个位置表示 $\langle s,i\rangle$ 模 $2$ 的结果。

首先考虑验证正确性。但一个问题是，如果我只改一个位置，这怎么可能高概率验证出来？

因此考虑放松要求：我们允许编码有 $\epsilon$ 比例的误差。考虑此时如何做点随机验证。

一个想法是验证线性性：$\langle s,i\oplus j\rangle=\langle s,i\rangle+\langle s,j\rangle$。我们有如下定理：

存在一个 $\epsilon$ 的上界，使得这之内上述验证错误率不超过 $\epsilon$ 推出误差不超过 $\epsilon$。另一个方向容易得到常数倍的界。

然而这是一个布尔函数练习题。考虑换成 $\{-1,1\}^n$ 然后抄傅里叶分析。那么这个相当于 $f^3$ 上 $0$ 位置的值，或者说 $f$ DFT 后所有位置的三次方之和。那么做一点放缩（假设 $s_0$ 最大）

$$
\sum s_i^3\geq s_0^3+\sum (1-s_0)s_i^2\geq s_0^3+(1-s_0)(1-s_0^2)=2s_0^3-s_0^2-s_0+1
$$

然后解点方程就行了。中间一步用到了正交基的 Parseval Inequality.

然后考虑如何提取信息。因为这里存的都是线性东西，可以想象我们能提取任何一个 $\langle s,i\rangle$。但如果我们确定性地搞，就很容易被骗过去。因此考虑随机一个 $y$，问 $y,i\oplus y$ 的结果。这样根据 union bound 可以限制错误率。

那么现在有一个编码，我们可以高概率验证合法性，高概率得到 $\langle s,i\rangle$。

##### NP-Hardness from QUADEQ

QUADEQ：给 $GF(2)$ 上的二次方程组，求它是否存在解。

NP-Hardness证明(ex15)：可以描述 and,or，然后是一个 SAT。

然后是构造 poly 大小的 PCP 证明。考虑我们需要编码什么。因为这里只有线性信息，因此考虑要求编码 $x,xx^T$，即答案和答案的二次型。

考虑如何验证：我们需要验证 $xx^T$ 的正确性和方程的正确性。对于前者，按照经典矩阵乘法方式考虑两边随机向量乘起来验证，然后用之前的方式得到线性结果。对于后者，一个问题是我们要验证 $m$ 个线性方程。那么考虑类似之前的方式，随机一个线性组合加起来验证。

### XII Decision Tree

证明 $P\neq NP$ 可以看成一个下界问题：证明 SAT 不能多项式时间解决。但下界问题非常难，人们都不会做。在接下来的章节里面，我们考虑一种折中的方式：考虑一些比图灵机更简单的模型，先考虑这些模型的下界，然后希望这个证明能用在 $P$ 和 $NP$ 上。

一个函数 $f:\{0,1\}^n\mapsto \{0,1\}$ 的复杂度是啥？我们可以用 Kolmogorov 描述，但这 undecidable。我们可以用 Circuit Complexity 描述，但人们都不会做 circuit lowerbound。

#### Decision Tree complexity D

决策树（显然）是一个树形结构：每一个点上可以

1. 读取输入的一位 $x_i$，然后根据这一位的结果走到两个节点。
2. 作为一个叶节点直接结束，返回 $0/1$ 中的一个。

这也可以看成一个交互的过程：每次根据之前的询问结果读一位，然后继续做交互。

那么这个树可以计算一个函数：对于输入，按照决策树的方式模拟过程，然后得到结果。

一个决策树的 cost 是最坏输入下询问的次数。一个函数的决策树复杂度 $D(f)$，是所有计算它的决策树中代价的最小值。

##### Adversarial Method

那我们怎么做 Decision Tree 的下界呢？一个好用的方式是考虑交互的形式：左侧决策树通过交互尝试算某个东西，但右侧每次询问的结果可以由我们决定。我们考虑最坏输入下询问的次数，相当于我们希望通过给出询问的结果让这个交互持续地尽量长。

那么这是一个对抗的交互（与下一章相反）：选择询问的一方希望尽快确定答案，回答询问的一方希望尽量不确定答案。这里有一些例子：

1. OR-function。回答一方每次回答 $1$，就不可能提前停止。因此 $D(OR)=n$。
2. AND-OR function: 有一个深度为 $n$ 的二叉树，每层交替为 $and/or/and/...$，叶节点为输入。我们证明 $D(And-Or)=2^n$，即这东西也不可能提前停止(ex2)：考虑叶节点，如果这里是个 and，那么询问一侧时如果返回 $0$ 则另外一个就不用问了（这显然不好）。而如果返回 $1$ 就相当于这个 and 没用，其结果正好是另一个没被问的儿子的值。那么考虑这个二叉树，就相当于是按照叶节点父亲的算符确定这个叶节点的值，使得算符结果等于另一侧儿子的值，这样把父亲节点合并掉，剩余不变。这样操作后每一步都不能建筑，因此需要问满 $2^n$ 步。
3. Graph-Connectivity：给一张图，问是否连通。考虑每次返回 $0$，除非再返回 $0$ 就切断了。那么这样已经问出来的每个连通块之间剩余边都问过了（否则这次不会返回 $1$），从而还是需要问满。

#### Certificate Complexity C

考虑我们如何说明 $f(x)=0/f(x)=1$。如果我们只需要指出一些位，并说明这些位上的值就确定了 $f(x)$，那就可以了。

因此对于 $f(x)=0$ 的 $x$，称它的一个 $0$-certificate 为一个下标的集合，使得只要这个集合上和 $x$ 相同的串 $x'$ 都满足 $f(x')=0$。类似地我们定义 $1$-certificate。

一个串的 Certificate Complexity 是它的最小 certificate 的大小。一个函数的 Certificate Complexity 是所有串 Certificate Complexity 长度的最大值。

那么我们有如下结论：

1. $C(f)\leq D(f)$。

证明：把决策树的路径拿出来就是一个 certificate。

反方向是不一定的，因为可能对于每个 $x$ 有完全不同的 certificate，但我们现在不知道要问哪一个。但我们有

2. $D(f)\leq C(f)^2$

关键结论是，不会有不交的 0-certificate 和 1-certificate：不然一个串可以同时被证明为 $0,1$。

那么考虑找一个 0-certificate，问里面的所有位置。在这些位置确定后，剩余每个串的 1-certificate 长度都至少减少了 $1$。那么这样做 $C(f)$ 轮就完事了。

有一些显示这个关系的例子：

1. Graph-Connectivity。显然 $0$-certificate 是一个划分，这最坏情况下需要给出 $1/2$ 的边，因此这里 $D$ 和 $C$ 同级。
2. And-Or function：如果要证明 $0$，我们只需要遇到 Or 两边递归，遇到 And 只需要证明 And 的一边。那么这里 $C$ 只有 $2^{n/2}$，也就是 $D$ 的根号。

#### Randomized Decision Tree R

考虑在决策树中引入随机。一个等效表示方式是，我们直接随机整个决策树。也就是说，我们有一个决策树的概率分布。一个输入的代价是代价的期望，这样一个随机决策树的代价是所有期望代价的最大值。

那么显然 $R\leq D$。同时有些情况下 $R$ 可以比 $D$ 更好。比如，考虑三个 $0/1$ 的中位数。根据 Adversary 的想法显然 $D=3$。但是如果我们随机打乱再问，就对于每个坏的输入($011$) 有 $1/3$ 的概率直接确定。因此 $R\leq 8/3$。

##### Yao's Minimax lemma

考虑对偶。我们有一个矩阵，行是决策树，列是输入，元素是对应的代价。上面的复杂度是说，我们按照某种方式组合一下行，使得得到的行里面最大的元素尽量小。根据 LP Dual 的结论，这个答案等价于如下结果：按照某种方式组合一下列，使得得到的行里面最小的元素尽量大。由此得到如下结论：

考虑找到一个输入的分布 $\mathcal D$，使得这个分布下每个确定性决策树的最小用时都不小于某个 $C$。这个 $C$ 的最大值就是最小的 $R$。

注意这里我们先给出分布，因此确定性决策树可以对着分布处理。这和之前的问题有所不同。

一个例子还是三个数的中位数。考虑分布是所有非全部相同的 $6$ 种情况均匀出现，可以验证下界是 $8/3$、

#### Sensitivity S / Block Sensitivity BS

我们继续考虑如何限制 $D$。定义一个位置 $x$ 上的敏感度为有多少个下标 $i$ 使得 $x$ 上翻转 $i$ 后 $f$ 就改变了。定义所有位置敏感度的最大值为问题的敏感度 $S(f)$。

那么显然 $S(f)\leq D(f)$：如果有一个改变的位置没有问到，那不可能能确定答案。

这个定义可以自然的推广：之前是有一个改变的位置没有问到，但改变可以不只是一个位置。我们定义 Block Sensitivity 是，最多能找到多少个不交的下标集合，使得翻转每个集合后 $f$ 都改变了。那么显然 $BS(f)\leq D(f)$。证明和刚才一样：如果有一块没有问到就不对。

显然 $S\leq BS$，因为前者是后者的特例。

考虑另一个方向。我们有一个有趣的结论。

Thm. $C(f)\leq S(f)*BS(f)$

Proof(1.2*). 因为 $S$ 不大，我们可以缩小每个 block 的大小：如果有一个 block 大小大于 $S$，那么因为只有翻转 $S$ 位会有不同，我们可以找到一位翻回来使得它还是一个 block。这样我们可以找到每个 block 大小不超过 $S$ 的一种方案。考虑就用这些当 Certificate，大小为 $S*BS$。如果这不行，那那个东西可以构成一个新的 block，矛盾。

#### Polynomial method Deg

如果我们不允许 $x^2$ 的出现（因为 $0/1$ 下 $x^2=x$），那显然(ex5/6)每个函数有唯一多项式表示。考虑用它的度数 deg 来考虑问题。

显然 $deg\leq D$(ex7)：决策树显然可以写成 $D$ 次多项式，但反过来 $D$ 次多项式不一定是 $D$ 次决策树。

还有一些神奇的结论，证明不考虑：

1. $BS\leq 2deg$
2. $D\leq deg^2*BS\leq 2deg^3$

#### More examples

ex3: 考虑 $k$ 组 $k$ 个变量，每一组内 Or，然后 And。

1. 显然 $C=k$，因为一边只需要给一组，另一边每一组给一个。
2. $S\geq k$，因为可以一组翻到 $1$ 就行，这一组内部有 $k$ 种可能翻过去。
3. $BS\leq k$，因而它们都等于 $k$：如果答案是 $0$，那每一个 block 必然在一个取 $0$ 的组里面占据一个。如果答案是 $1$，那每个 block 必然包含一整组里面的所有 $1$。
4. 容易验算 $deg=k^2$。用 Adversary 可以类似 And-Or 地证明 $D=k^2$。
5. 对于 $R$，考虑 Yao's Minimax。分布为每一组里面只有一个 $1$，那再怎么搞期望也要 $O(k^2)$ 步才能确定。

ex4: 考虑 $k$ 组 $k$ 个变量，合法当且仅当有一组是 00...01100...0 的形式。

1. $S=O(k)$，因为如果答案是 $1$ 那么只能动这一组，否则一组里面翻一位能到 00...01100...0 的话翻的位也只有一两种可能。
2. $BS=\Omega(k^2)$：考虑全 $0$，每次翻两个。

这说明 $S,BS$ 是很不同的。

好像说最近有结果说 $BS\leq S^3$ 还是 $S^4$，忘了。

ex1(**)： 证明如果函数与每一位相关，则 $s=\Omega(\log n)$。

Proof. $D$ 非常好证明：决策树上每个下标都出现一次。但这样证明 $S$ 完全不行。

反证。条件只有对于每个 $i$，存在一个位置 $(x,x\oplus 2^i)$ 不同。考虑能不能推出更多。可以发现如果一个 $(x,x\oplus 2^i)$ 不同，那么与 $x$ 相邻的那些 $(x',x'\oplus 2^i)$ 也几乎不同：因为 $S$ 很小，换过去只有 $o(\log n)$ 的改变。那么每一个不同的 $(x,x\oplus 2^i)$ 都可以找到 $n-o(\log n)$ 个与 $x$ 只差一位的 $y$ 使得 $(y,y\oplus 2^i)$ 不同。

然后我们希望让这样的 $y$ 很多，这样就可以直接数数(!)。可以发现，上述限制说明这样的 $y$ 至少有 $2^{n-o(\log n)}$ 个：按照一个 bit 分治，如果一侧没有就直接继续，否则考虑更小的那一侧，递归过去只会让那个值减一。因此需要递归 $n-o(\log n)$ 层就需要 $2$ 的这么多次方的点数。

这样总共的 $y$ 就是 $n2^{n-o(\log n)}=n^c2^n$，平均一下就说明 $S$ 不可能是 $o(\log n)$。

### XIII Communication Complexity

在一般情况下，我们考虑 2-party communication：两个人分别知道长度为 $n$ 的串 $x,y$，然后希望计算 $f(x,y)$。直观定义的方式是，两人轮流根据自己的输入和交互历史发消息。消息长度可以任意，但不能是空串。要求最后一条消息正好是 $f(x,y)$。

定义交互的复杂度为所有长度为 $n$ 的串的情况下，双方发送信息长度总和的最大值。当然，这里至少需要不能发送空串，不然可以使用如下方式得到 2 的complexity：跑 $2^n$ 轮，在 $(x)_2$ 轮发一个 bit，然后就可以得到答案。实际上啥都不发也是传了信息，所以这不对。

一个更好的定义方式是，每一轮 protocol 根据之前交互决定谁发一个 bit，代价就是轮数。

通信复杂度记作 $C(f)$。（请自行flush上一章的记号）

显然的上界是 $C(f)\leq n+1$：先把一个人的输入发过去，然后第二个人发结果。

和上一章一样，我们会考虑很多种 lowerbound 的方式。

#### Fooling Set

考虑判断两个人的串是否相等：$EQ(x,y)=[x=y]$。我们可以证明这个函数有非常大的下界：

考虑 $2^n$ 种交互 $(x,x)$ 的过程。如果两个 $(x,x),(y,y)$ 的交互过程完全相同，那么 $(x,y)$ 的交互过程也和它们相同：对于每个人，他得到的信息都和 $(x,x),(y,y)$ 种的一组相同，那么他的表现也是相同的。

但 $(x,y)$ 的输出显然和 $(x,x),(y,y)$ 的输出不同，因此这种情况必然导致矛盾。所以 $2^n$ 种过程必然两两不同，从而交互至少需要 $n$ 的复杂度。

这样的一种分析方式被称为 Fooling Set: 一个大小为 $M$ 的 Fooling Set 是 $M$ 组输入 $(x_i,y_i)$，使得所有 $f(x_i,y_i)=b$，其中 $b$ 是一种固定值。同时对于任意两组不同的输入 $(x_i,y_i),(x_j,y_j)$，$f(x_i,y_j),f(x_j,y_i)$ 中至少有一个不是 $b$。对于这样的一组集合，我们可以复用刚才的分析(ex1)，从而 $M$ 组交互过程必须两两不同。那么必然有：

如果 $f$ 存在大小为 $M$ 的 Fooling Set，则 $C(f)\geq \log_2 M$.

另一个例子是判断集合是否有交：考虑这样的 Set: $(A,\overline A)$。那么对于每一对 $(A,\overline A),(B,\overline B)$，至少有一侧组合的交会变成 $1$。因此 $C(Intersect>0)\geq n$。(但接下来我们会看到一个形式类似，却可以做到更好的问题)

Ex2: 对于刚才的问题，对于任意通信方式，任取一个集合 $S$，则必定存在 $x\in S$ 使得判断 $EQ(x,y)$ 的复杂度至少是 $\log |S|$.

证明：显然还是直接上鸽笼原理。

#### Tilings

我们从另一个角度，考虑所有可能的输入随着交互的“决策树”的变化。完整的交互方式可以看成一个决策树：根是初始的情况，每个节点上交互方式决定一个人输出一个 bit，然后根据这个 bit 情况分成两个子情况继续，这可以看成节点的两个儿子；叶节点上即为求出答案的步骤。

考虑每个节点上存在的状态。初始节点上为所有状态 $\{0,1\}^n\times\{0,1\}^n$。假设当前点是第一个人操作，那么他按照自己的串将状态分成两部分（历史信息在状态中体现）。那么可以发现每个节点上的状态形如 $A\times B$，其中 $A,B$ 分别是一个子集。

考虑把 $f$ 看成一个矩阵 $M(f)$：行是 $x$ 的值，列是 $y$ 的值，值是 $f(x,y)$。那么每个状态 $A\times B$ 是一个子矩阵。在分到叶子节点时，操作结束，因此此时剩下的 $A\times B$ 必须全部是相同的答案。所有叶子节点将状态划分为若干子矩阵（不一定连续！），每个子矩阵内权值相同。

我们定义 $\chi(f)$ 为将 $M(f)$ 划分为值相同的子矩阵，至少需要划分多少个。由于叶子数和深度有关，我们很容易得到：

$$
\log \chi(f)\leq C(f)
$$

一个简单的观察是，如果有一个 Fooling Set，那么其中任意两个位置 $(x_i,y_i),(x_j,y_j)$ 不能在同一个子矩阵中，否则 Fooling Set 的性质会使得这个矩阵寄掉。那么 Fooling Set 的结果自动被 Tiling 包含。

Ex5(1.7*): 证明 $C(f)\leq O(\log^2 \chi(f))$.

证明：什么东西是 $log^2$ 的？做 $O(\log)$ 轮，每轮发一个数。问题相当于，有一堆矩形，然后一个人拿到一个行号，一个人拿到列号，他们希望找到交点所在的矩形。首先前面已经说过直接集合交是不能做的，所以这里需要利用矩形划分的性质。

一个关键的性质是，两个矩形不能同时行相交和列相交。那么答案一定满足要么只和一半的东西行相交，要么只和一半列相交。虽然双方不知道答案，但这说明：

1. 要么第一个人可以找到包含自己拿到的行的矩形，使得其只与一半的矩形行相交。
2. 要么第二个人可以找到包含自己拿到的列的矩形，其只与一半的矩形列相交。

注意到因为答案包含对应行，所以答案一定在相交的一半中。这样这一方就可以说出这个矩形的编号，从而双方同时扔掉一半的矩形。这样做 $O(\log \chi)$ 轮就可以了。

#### Ranks

我们继续从矩阵 $M(f)$ 的角度考虑。考虑矩阵的秩，它看起来与之前的东西无关，但我们有如下表示方式：

Ex6: 矩阵的秩等于最小需要多少个秩为 $1$ 的矩阵加起来得到原矩阵。

证明：注意到秩就相当于线性空间维数，那取一组基组合，每个基就是秩为 $1$ 的矩阵。

非常好的消息是，全 $1$ 矩阵的秩为 $1$，那么子矩阵（Tilling）划分就是一种组合，因此有

$$
rank\leq \chi\leq 2^C
$$

那么这又是一种通过 bound $\chi$ 以得到下界的方式。需要注意的是，划分显然不考虑域，所以取任何一个域做 rank 都可以得到界。显然取 $R$ 是界最好的，取有限域可能无法分析出较好的界。

一个简单的例子：考虑判断是否等于，那么矩阵是单位矩阵，自然满秩。

然后我们考虑一些 Rank 和 Fooling Set 的对比。

Ex7: 考虑一个随机矩阵的情况。根据基础的线代知识，随机矩阵满秩的概率是常数。但如果使用 Fooling Set，我们得到的 $\chi$ 的界可能只有 $O(\log n)$ 级别：考虑一个大小是 $10\log n$ 的集合，选的方式是 $\binom{n}{10\log n}^2*(10\log n)!\approx 2^(20\log^2 n)$，但它是 Fooling Set 的概率是，每一组对角有 $3/4$ 概率合法，所以是 $(3/4)^{50\log^2 n}$，所以 Union Bound 可以得到有的概率指数小。这说明随机情况下 Rank 比 Fooling Set 强。

Ex8a: 我们先考虑一个 Tensor Product。证明矩阵 Tensor Product 完的秩是原先两个秩乘起来。

证明：对 Tensor 完的矩阵消元，先把第二个矩阵当整体矩阵消元，然后得到以第二个矩阵为单位的分块上三角（总共 $rank(A)$ 组），然后每一块再消元，最后每一组剩下 $rank(B)$ 行。

Ex8b(0.7*)：证明如果存在大小为 $S$ 的 Fooling Set，则矩阵秩至少是 $S^{1/2}$，因此算秩的下界不会显著差于 Fooling Set。

证明：显然可以只考虑 $S$ 的子矩阵，那么是一个对角线是 $1$，其余位置每一对对称的不全是 $1$ 的矩阵 $M$。那么同时考虑 $M^T$，它们只在对角线上同时为 $1$。从而考虑 $M\otimes M^T$，考虑所有 $(i,j)\times (i,j)$ 的位置，那么这些位置是 $(i,i)$ 的所有行和对应所有列的一个子矩阵，且根据上面性质这部分是对角阵。所以 $M\otimes M^T$ 至少有 $S$ 的秩，那 $M$ 就至少有 $S^{1/2}$。

Ex9: 证明把 $0/1$ 换成 $+1/-1$ 不会太影响秩（在 R 下考虑）

证明：加一行全 $1$ 就能互相转换，所以差不超过 $1$。

Ex10(0.3*)：证明内积函数的秩是 $2^n$。

证明：考虑取 $0/1$ 然后直接消，然后消到一半发现完全不对劲。

事实证明选的域和元素类型都很影响分析。考虑取 $+1/-1$，那么先对着大块消一下就变成了分块上三角（右下乘二），然后继续做就是满秩。

这里也不能用 $F_2$，不然秩是 $\log n$。

Ex11(0.5*): 证明如果 $M(f)$ 的行两两不同，则 $C(f)\geq \log n$。

证明：首先注意到矩阵有 $2^n$ 行，我们需要证明秩至少是 $n$。这个时候取 $F_2$ 就有用了：如果秩小于 $n$，那么 $F_2$ 下不存在 $2^n$ 个不同的线性组合，从而直接去世。所以秩至少是 $n$。

#### Discrepancies

> Discrepancy n. 差异

对于一个 $2^n\times 2^n$ 的 $M(f)$，将元素看成 $\pm 1$，然后使用如下方式定义它的 Discrepancy：取一个子矩阵，最大化和的绝对值，然后除以总元素数将其归一化：

$$
Disc(f)=2^{-2n}\max_{A,B}|\sum_{x\in A,y\in B}M_{x,y}|
$$

直观来说，就是找到一个子矩阵，使得一种数比另一种数尽量多。

首先考虑这个怎么用。注意到同色矩阵的 Disc 贡献就是它的大小（占总矩阵的大小比例）。那么考虑之前的划分，每个矩阵的大小不会超过 Disc，所以显然有

$$
M(f)\geq 1/Disc(f)
$$

所以，为了做通信复杂度的下界，我们需要 Bound Disc 的上界。但这东西外层有个集合 Max，这非常难算。事实上给一个矩阵精确计算好像都是 NP-Hard 的(todo)，所以我们需要考虑更好的证明方式。

##### Eigenvalues

一个基于特征值的结论是，假设 $M$ 对称，则 $Disc\leq \lambda_{\max}/2^n$。（$\lambda_{\max}$ 表示所有特征值模长的最大值）

证明（基础线代知识）：子矩阵求和可以看成两边分别有一个 $01$ 向量 $s_A,s_B$，然后求 $s_A^TMs_B$。两边向量模长乘积是不超过 $2^n$，显然中间的线性变换 $M$ 对内积的放大不超过 $\lambda_{\max}$ 倍（拆一下必然能算）。

一个有力的例子是，考虑算内积的函数 $f(x,y)=\sum x_iy_i\pmod 2$。考虑不同的两行 $x,y$，一列 $z$ 在这两行位置上不同当且仅当 $z$ 和 $x\oplus y$ 内积为 $1$，那么两行都是一半相同一半不同，从而两两正交。那么 $M^TM=M^2=2^nI$，所以特征值都是 $\pm 2^{n/2}$，由此 Disc 不超过 $2^{-n/2}$，这就是一个 $n/2$ 的下界。

##### $\mathcal E$

考虑一个更容易计算的值：

$$
\mathcal E(M)=E_{x_1,x_2,y_1,y_2}M_{x_1,y_1}M_{x_1,y_2}M_{x_2,y_1}M_{x_2,y_2}
$$

然后考虑它和 Disc 的关系。我们首先考虑针对一个完整矩阵的元素和。由于这个对称性，首先可以把上面的某一个值缩起来，得到

$$
\mathcal E(M)=E_{x_1,x_2}(E_y M_{x_1,y}M_{x_1,y})^2
$$

然后可以注意到，平方的期望大于期望的平方，那么可以得到

$$
\mathcal E(M)\geq (E_{x_1,x_2,y}M_{x_1,y}M_{x_1,y})^2
$$

再做一轮就得到，$\mathcal E(M)\geq(E_{x,y} M_{x,y})^4$，这就是整个矩阵 Disc 贡献的四次方。

但我们还需要考虑子矩阵。此时就可以体现 $\mathcal E$ 的另一个好处：它（相对于加一行）是单调的。

证明：考虑加一行后，两行之间产生的贡献，那是一个 $E_{x,y}v_xv_y$ 的形式，所以加进来的东西非负。

那么根据单调性，$\mathcal E(M)\geq Disc(M)^4$，同时前者又是更好计算的。

还有另一种稍微复杂一点，但是在接下来有用的证明方式：考虑将子矩阵的限制写成 $g(x)h(y)$，其中每个函数取值 $0,1$。那么我们需要把 $g,h$ 加到不等式里面。可以发现在每一次缩期望的时候，我们得到的中间步骤是 $E_{\text{其它维坐标}}(E_y \cdots)^2$，那么此时把 $g(x)^2$（不包含 $y$ 的那个）扔进去显然是正确的放缩方向。

再考虑内积的例子(ex12)，换为 $\pm 1$ 后内积是 $(-1)^{\sum x_iy_i}$，那么四个内积乘起来后还是可以分位考虑每个 $x_iy_i+x_iy'_i+x'_iy_i+x'_iy'_i$。这可以看成四元环的导出子图边数。在 16 种情况中，这个值只有四种情况取奇数：只取相邻两点。那么每一位的贡献是 $3/4-1/4=1/2$，乘起来即刻得到 $\mathcal E=2^{-n}$。那我们也得到了 $\Omega(n)$ 的下界。

#### Short Summary

考虑上面这些方法的优劣程度。

1. Ex5 说明 $\chi$ 得到的界最多和 $C$ 差平方级别，这是相对接近的。同时 Fooling Set, Rank, Discrapency 都是限制到 $\chi$，所以它是更强但更难证明的。
2. Ex8 说明 Rank 一定不比 Fooling Set 差太多。随机矩阵的例子则说明 Fooling Set 可能比 Rank 差很多。
3. 考虑判定相等（单位矩阵）的例子，此时 Rank=n，但 Disc 至少是 $1-2^{-n}$，因为矩阵几乎全是 $0$。这说明 Disc 也可能很差。

但 Rank 是否很差呢？这是不知道的：

Log Rank Conjecture: 存在 $c$ 使得 $C=O(\log^c rank)$。

Theorem in NW94(todo): $Disc^{-1}=O(rank^{3/2})$

#### Multiparty Communication

之前的（某一个）定义很容易扩展到多个人的情况：每次选一个人出来说话，每次说一个 bit。这里一般用 $k$ 表示人数。

但另一个需要考虑的问题是，每个人能看到多少信息？一个直接的想法是每个人有一个私密的串 $x_i$，但这里我们可以考虑另一个有趣的情况：

有 $n$ 个串 $x_i$，第 $i$ 个人可以看到**除了**第 $i$ 个串之外的所有串。

脑筋急转弯：给三个 $01$ 串，逐位求中位数后求 $1$ 的奇偶性。

答案：注意到每个人可以看到两个串，考虑每个人在一位上看到两个 $1$ 就 $+1$，然后三个人只分别说自己统计的结果。可以发现一位上 $0,1,2,3$ 个 $1$ 分别统计 $0,0,1,3$ 次，所以奇偶性下求和就是对的。

然后我们来考虑之前的方法应该怎么用。一个最有效的东西还是 Tilling，但现在一个情况下的状态不再是一个 $A\times B\times C\cdots$ 的情况了：如果每个人只看到自己的串，那是上述情况，但现在每个人可以看到除了自己之外的所有串。为此，我们定义如下的东西：

1. 第 $i$ 维上的一个 Cylinder，是一个可以写成 $[(x_1,\cdots,x_{i-1},x_{i+1},\cdots,x_n)\in S]\times [x_i\in \{0,1\}^n]$ 的集合。换言之，改变 $x_i$ 这一维不改变值。
2. 一个集合是 Cylinder Intersection，当且仅当它可以写成每一维选一个 Cylinder 交起来。
3. 换言之，一个集合 $S$ 是 Cylinder Intersection，当且仅当存在函数 $g_1(x_2,x_3,\cdots),g_2(x_1,x_3,\cdots)$ 使得

$$
x\in S\Leftrightarrow g_1(x_2,x_3,\cdots)g_2(x_1,x_3,\cdots)\cdots=1
$$

也可以说

$$
\forall i,\exists x_i',(x_1,\cdots,x_{i-1},x_i',x_{i+1},\cdots,x_n)\in S\implies (x_1,\cdots,x_n)\in S
$$

那么之前的 Tilling 还是可以用，但是这更难划分了。

我们再考虑 Discrapancy，显然把 $A\times B$ 换成 Cylinder Intersection 就可以用，但这更难算了。所以我们还是考虑 $\mathcal E$，那么此时可以按照如下情况考虑：

$$
\mathcal E(f)=E_{x_1^1,x_1^2}E_{x_2^1,x_2^2}E_{x_3^1,x_3^2}\cdots[\prod_{t_i\in\{1,2\}}f(x_1^{t_1},x_2^{t_2},\cdots)]
$$

换言之，之前是每维随两个然后四种组合乘起来，现在变成 $2^k$ 种组合。

可以发现，如果我们写成 $g_1(x_2,x_3,\cdots)g_2(x_1,x_3,\cdots)\cdots$ 的形式，那么之前的第二种证明仍然成立(ex14)：每一次对一维缩起来平方的时候，把不包含这一维的 $g_i^2$ 放进去即可。那么结论是

$$
Disc\leq \mathcal E^{1/2^k}
$$

也就是说证明出来通信复杂度会除以 $2^k$。

考虑一个例子：广义内积，对位相乘，求和模二。

$$
GIP(x_1,\cdots,x_k)=(-1)^{\sum_{i=1}^n\prod_{j=1}^k(x_j)_i}
$$

那我们来算 $\mathcal E$，那么还是可以分位，考虑一位的问题，相当于每个人随两个 $01$-bit，然后看这 $2^k$ 个组合里面有多少个能组出全 $1$，考虑这个的奇偶性。那么立刻可以发现是奇数当且仅当每组都是 $01/10$，所以一位的贡献是 $(1-2^{-k})-2^{-k}=1-2^{1-k}$，所以 $\mathcal E=(1-2^{1-k})^n$。然后是数学技巧：

$$
(1-2^{1-k})^n\leq e^{-n/2^{k-1}}=exp(\Omega(n/2^k))
$$

那么再除 $2^k$，得到一个 $\Omega(n/4^k)$ 的下界。

Open question：证明任何一个 $\Omega(n/2^{o(k)})$ 的下界。(todo: ch14)

#### Interesting Ideas from Communication Complexity

Ex3(*): 证明单带图灵机判断一个串是否是回文串需要 $\Omega(n^2)$ 的时间。

Proof: 通信体现在哪里？我们考虑单带图灵机上 $(i,i+1)$ 两个位置中间的部分。每次图灵机经过这个位置时，只会从一侧向另一侧传递 $\log |S|$ 的信息量，其中 $S$ 为状态集合。这可以看成一个通信方式！每次传递的信息是当前图灵机状态，每个人得到信息后在自己这一侧模拟图灵机，在其返回时把新的状态发送过去。

那么考虑如下问题：左边有 $x_{[1;i]}$，右边有 $x_{[i+1;n]}$，然后需要通信求出 $f(x)$。如果这个问题的通信复杂度为 $C$，那么因为图灵机来回经过这个位置时的状态可以看成一种通信，这说明任何一个算 $f$ 的图灵机都需要经过这里至少 $C/c$ 步，其中 $c$ 是一个只与图灵机相关的常数。

回到原问题，对于每个位置考虑上述分析。每个位置处需要比较两侧前缀和后缀公共部分是否相等，这是第一部分分析过的问题，其至少需要两侧长度最小值的通信复杂度，因此总步数是 $\sum \min(i,n-i)$ 级别的，这就是 $\Omega(n^2)$。

Ex4: 证明空间为 $S(n)$（多带模型，自然不考虑输入 Tape）的图灵机判断 $\{S|S\}$ 需要 $\Omega(n^2/S(n))$ 的空间。

Proof: 同上，只是本来的通信量只有状态，现在有状态和工作带上的全部内容，所以一次是 $S(n)$。

Ex13: 有一张图，A 拿到一个独立集，B 拿到一个团，双方需要求出两个集合交集的大小。要求 $O(\log^2 n)$ 的通信复杂度。

可以发现无论是尝试集合交还是复杂度都和 Ex5 很像，所以可以参考 Ex5。

注意到如果交点存在，那么要么它的度数小于一半，要么大于一半。然后考虑：

1. 如果 A 在独立集里面找到一个度数很大的点，那么只要 A 说出这个点，B 就知道与其相邻的点都不在 A 的独立集中，从而双方同时扔到一半的点。
2. 如果 B 在团里面找到一个度数很小的点，那么类似地可以扔掉一半的点。
3. 如果都不满足，那么两个集合必定不相交，可以直接结束。

所以还是 $O(\log^2 n)$

Ex15: 考虑一个随机 Protocol：两个人可以分别随机（不能无代价 Share），要求正确率不小于 $2/3$。请在 $O(\log n)$ 的通信复杂度内判断等于。

Sol: 字符串哈希。$n$ 次多项式只有 $n$ 个根。

Ex18：证明给函数矩阵计算通信复杂度是 EXP 的。

Sol: 首先通信复杂度不超过 $O(\log n)$（直接发下标），所以先搜决策树（$2^{2^{O(\log n)}}$），然后每个点上搜决策函数（$(2^n)^{2^{O(\log n)}}$）

Ex19: 考虑 Streaming Algorithm：空间小于输入，依次读输入，读完就不能返回。现在问题是给一堆数，值域 $n$，输出众数出现的次数。证明不能在 $o(n)$ 的 Streaming Space 内近似（$3/4$）这个问题。

Proof:可以简单地看成一个通信：在某一步之后，前面的部分给后面留下了空间大小的信息，然后后面需要求出答案。那么考虑一个简单的情况：前面每种数最多出现一次，此时需要 $O(n)$ 的信息记录每种数是否出现。如果用更少的信息，那么必然有两种集合不同的情况被映射到了一起，此时显然直接错：找到不一致的数 $x$，再输入一个 $x$ 就结束，此时必然无法区分 $1/2$ 的差距。

##### Karchmer-Wigderson games

我们首先给出一些精细的定义：

Circult：Fan-in 2，中间层只能是 $\land,\lor$，输入上可以有一层 $\lnot$，$\lnot$ **不计入**深度。

Communication on Relation：有一个关系 $R$，双方拿到 $x,y$ 后开始通信，需要双方**确认**一个 $s$ 使得 $(x,y,s)\in R$。换言之可以的输出不唯一，且输出**不计入**通信复杂度，但双方需要在不再交流信息的情况下得到**相同**的答案。

Karchmer-Wigderson game(Ex18): 有一个函数 $f$，双方分别拿到 $x,y$，满足 $f(x)=0,f(y)=1$。现在双方需要通信确认一个下标，使得 $x,y$ 在这个下标上不同。

证明(1.4*)：这个问题的通信复杂度**正好等于**计算 $f$ 的最小 Circuit 深度。

Proof: 首先证明通信复杂度不大于深度。考虑直接沿着 Circuit 从上往下做，假设当前根节点为 $\land$，那么 $y$ 一方两个儿子的求值结果都是 $1$，而 $x$ 一方必定有一个 $0$。那么此时可以让 $x$ 说出求值为 $0$ 的是哪一侧（Circuit 是给定的，可以放进 Protocol），然后这个点上双方节点不同，所以可以到这里继续做。深度次之后可以到达输入节点，那么这个下标就是答案。如果是 $\lor$，那么镜像操作。这样步数正好等于深度。

然后考虑另一个方向：深度不超过通信复杂度。那么通信里面一个类似 Circuit 的东西是通信的决策树，考虑从这个下手。

回忆决策树的性质：每个点上可能的状态形如 $A\times B$，每个点上一方通过自己的串将状态分为两部分，或者整个状态直接得到一个下标然后结束。

考虑归纳如下结论：对于每个点，我们可以找到一个对应深度的 Circuit，使得其正确判断 $A\times B$ 中所有 $A\cup B$ 输入的结果。对于终止情况，此时存在一个下标区分 $A\times B$ 中的所有状态，那么这个下标作为输入 bit（可能需要 $\lnot$）就可以达到要求。

然后考虑中间的节点。假设当前点上 A 操作，那么他把 $A\times B$ 分成两部分 $A_1\times B,A_2\times B$，然后根据归纳下面有两个 Circuit 分别对两部分正确求出答案。这两个 Circuit 对 $B$ 都输出 $1$，对 $A=A_1\oplus A_2$ 则是至少有一个输出 $0$。因此可以发现两个的输出 $\land$ 起来就是对的。

这样就可以直接把决策树对应回 Circuit，可以发现这个和另一个方向几乎完全一致。

Ex17(1.3*)：证明算 $n$ 个 $0/1$ 的奇偶性需要 $2\log n$ 的深度。

这个上界是正好 $2\log$ 的（Communication Game直接二分双方发和，Circuit 直接分治然后两层 Xor），所以很神(kun)奇(nan)。

分析一下，Fooling Set 很难搞到 $>1\log n$，Rank 和 Discrepancy 在这里不太好定义，所以只能考虑 Tilling。

对于每种答案 $i$，我们都有 $(x,x\oplus e_i)$，它们是矩阵上的一个排列。那么一个矩形如果覆盖了 $\epsilon$ 比例的这些元素，它就需要 $\epsilon^2$ 的大小。均值一下可以发现，如果有 $k$ 个这种答案的矩形，那么它们至少占据 $1/k$ 的空间。

再凸性一下，如果最小化那个 $1/k$ 空间下界的和，那么最优解是所有 $i$ 数量相同，此时可以发现每个占据不超过 $1/n$，所以至少需要 $n^2$ 个矩形。

### XIV Circuit Lowerbound

历史上，一种尝试证明 $P\neq NP$ 的方式是证明问题的 Circuit Lowerbound。这一方向的终极目标是证明 $NP\not\in P/poly$，根据 ch6 的 Karp-Lipton 这也是被广泛相信的。

但这实在是太困难了：现在 NP 的最好 Circuit Lowerbound 甚至是 $(\mathbf 5-\epsilon) n$(todo)。

由此，人们考虑从一些更简单的问题入手。从而有两个方向：

1. 证明比 NP 更强的复杂度类有好的 Circuit Lowerbound。
2. 证明比 P/poly 更弱的 Circuit 类不能做一些简单的问题。

第一个实际上在 Ch6 已经见过一次，这里我们先从第二点开始。

从 Circuit 强度从下往上看，最最弱的是 $TC_0$，但这显然没有思考的必要：输出只和常数个 bit 有关。

那接下来是 $AC_0$，再往上通常是 $AC_0$ 加一些特殊门的版本：例如，

1. $ACC_0[m]$ 是加入一个模 $m$ 的 Gate，输出 $0$ 当且仅当输入是 $m$ 的倍数。$ACC_0$ 是可以加任意取模。
2. $TC_0$ 是加入一个 Majority Gate。

一些偏题的小练习：证明 $ACC_0\in TC_0$。

Proof: 考虑一个 $n$ 个输入的门，往这里加 $n$ 个 $0$ 和 $2n$ 个 $1$，然后原输入和 $n$ 个 $0$ 以及 $k$ 个 $1$ 做 Majority，每个 $k$ 跑一次。这样搞完找到答案对于 $k$ 的跳变点（$v_i \land\lnot v_{i-1}$）就是原来有几个 $1$，然后任何只和个数有关的函数都可以做了。

结合下一个结论可以证明 $AC_0\subsetneq TC_0$（计算理论 midterm）：如果可以做，那抄一下上面的东西就有 Parity in AC0。

怎么证一个东西不能被一类 Circuit 表示？这还是极其难。下面的成果也可以说明这一点。

#### Parity not in AC0

Idea: 能不能一层一层地把 AC0 拆掉？

Recap: DNF 是一堆 AND 再 OR 起来，CNF 是一堆 OR 再 AND 起来。k-C/D NF表示每个内层 Clause 大小不超过 $k$。

##### Hastad's Switching Lemma

结果：给一个 $k$-DNF，只要随机足够多（$n-o(n)$）个变量进行赋值，那结果就很可能能表示为一个 CNF。更进一步，可以证明对于 $s$，如果随机了 $t$ 个变量赋值，则剩余部分不能表示为一个 $s$-CNF 的概率不超过

$$
(\frac{(n-t)k^c}n)^{s/2}
$$

其中 $k$ 为常数。

考虑如何证明这种结果。首先一个关键的问题是，什么是“不能表示为一个 s-CNF”?这好像不好思考，那再考虑一个简单的情况：函数是单调的，换言之不存在 $\lnot$，此时怎么写 CNF？此时函数可以看成超立方体上右上到左下中间有一个分界面，每一个 Clause 限制如果它全 $0$ 了那就不合法。（从低维情况看）可以发现，每个分界面上的“顶点”都需要一个 Clause，换言之：

对于每一个集合，满足全部限制 $0$ 后函数就是 $0$，但少限制一点就可以不是 $0$，则其需要一个正好为其大小的 Clause 来处理。

Proof: 考虑把这些填进去，那一定是堆满了某个 Clause 使得函数变成 $0$，但如果这个 Clause 更小，那少限制一个也是必定 $0$。

可以发现这对原问题也成立：只需要把限制 $0$ 变成可以任意限制即可。那这就得到了一个通过极小的能让函数变为全 $0$（或者对于 DNF，全 $1$）的限制来判定的方式。

因此“不能表示为 s-CNF”可以变成一个正向的限制(ex3)：存在 $>s$ 个变量和它们的一组赋值，使得赋值后函数全 $0$，但少赋值一个都不行。

考虑把这些变量也赋值了，这样在 $t$ 很大的情况下，可能的情况数是变小的：每多一个差不多相当于除以 $\frac n{2(n-t)}$。如果我们能通过总的赋值情况还原初始方案，那我们就能直接说明则这样的方案数不超过原方案的那么多倍。问题是显然不能直接还原，但如果我们可以用少于 $(\frac n{2(n-t)})^s$ 的信息解决问题，那仍然能说明一个比例。

考虑怎么用很少的信息把新填的变量标记出来。首先考虑什么是填变量，一个 DNF 变为全 $0$ 当且仅当每个 Clause 里面都有一个不满足的 Literal，那么填变量填到函数全 $0$ 也可以看作如下过程：每次找一个 Clause，选一个 Literal 填了，然后继续找。此时就可以用到 k-DNF 的性质了：如果每次填第一个不满足的 Clause 里面涉及的变量，那就只需要 $\log k$ 个 bit 来定位这个变量，这就可以比 $n$ 小很多。

但这样的一个问题是，填过去之后就不知道之前哪些 Clause 还可以是 $1$ 了，这样只能从初始状态出发，不能倒着推。

此时有一个绝妙的想法：考虑先假装这样填把定位搞出来，然后全部反着填发过去。这样倒推时能看到第一个不满足的 Clause，然后定位、翻过来继续定位下一个。（我们可以处理一下假设不存在 $a\lor\lnot a$ 这种东西）这就对了。

换言之，本来有 $\binom nt2^t$ 种方式，现在可以搞到 $\binom n{t+s}2^{t+s}$ 种之一，还需要 $k^{O(s)}$ 的方案来编码额外信息。在 $t \to n$ 的时候，这差不多是少了 $(n/2)^s$，所以随便说明比例很小。

我们也可以精细分析(ex4): 先算一下 $\frac{\binom n{t+s}}{\binom nt}=\frac{(n-t-1)^{\underline k}}{ {t+s}^{\underline k}}$，这差不多小于 $(\frac{n-t}t)^s$。那带回去就差不多有原来那个概率，但我不知道为啥有个 $/2$。

##### Use Switching Lemma to prove the Theorem

直观地想，每层一开始是个 1-DNF，那随机限制 $n-n^c$ 个变量后，每个点都高概率变成一个 $c$-CNF，然后就可以和上一层合并，但合并完还是 $c$-CNF，然后继续做就行了。

一个问题是 Circuit 比较复杂，所以我们先用同时算 $a/\lnot a$ 的方式把 $\lnot$ 删掉(ex1)$，然后强行展开所有出度大于 $1$ 的节点（常数深度，只会多常数次方）得到一棵树(ex2)。对树考虑一层一层删就很好了。

具体来说，每层限制 $n-\sqrt n$ 个变量，那第 $i$ 层是 $n^{1/2^{i-1}}\to n^{1/2^i}$，所以界里面是 $n^{1/2^i}$ 的东西。为了用 Union Bound，我们需要 $k=O(2^i)$（再乘上 log circuit 大小），但这还是常数，可以接受，所以就对了。

全部删完以后，只需要限制 $n-n^{2^{-d}}$ 就可以完全固定 Circuit 的取值，但 Parity 显然不满足该条件，因此 $Parity\not\in AC_0$。

#### Parity not in ACC0(3)

另一种方式是一个多项式方法。与之前类似，我们希望说明 Circuit 的计算必定满足一些特性，但 Parity 不满足。


1. 用一个度数不高的多项式计算 Circuit。注意到精确计算是不可能低度数的(ex7)：AND 的一个表示需要度数 $n$，而我们可以归纳证明在 $F_p$ 下除了使用高次的东西（例如 $x^p=x$）不存在别的表示：一次的情况可以用范德蒙德矩阵可逆证明，高次只需要证明低次非零多项式能够给第一个变量赋值使得剩余多项式非零。因此我们考虑**近似**：要求 $P(x)$ 和 $f(x)$ 在大多数输入上一致。
2. 证明 Parity 不满足这个条件。

但首先，什么域下 Parity 不满足这个条件？首先 $F_2$ 必然不对，因为此时函数就是一次的全部加起来。但考虑任意一个别的 $F_p$，我们总能找到一个阶为 $2$ 的元素 $-1$，那考虑映射 $0\to 1,1\to -1$，因为这是线性换元所以可以在 $F_p$ 上直接做。那么此时的 Parity 是所有元素乘起来，这就是高次的。所以我们需要一个不是 $F_2$ 的有限域。

##### Low-Degree Approximation of AC0

在 $F_3$ 下考虑问题。NOT 可以显然地解决，但对于一个 fan-in $n$ 的 AND，直接做只能乘起来，这就不行了。考虑怎么用低度数的东西近似 AND 和 OR。

可以发现，对于 OR，写一个随机线性函数是一个很好的思路：如果全 $0$ 则结果是 $0$，否则有 $2/3$ 概率结果非零。此时结果可能是 $1,2$，但可以发现 $F_3$ 下平方一下 $2$ 就变成 $1$ 了，所以还是一个二次 $1/3$ 单侧错误的结果。

但这显然不够用。不过注意到这是个单侧错误，那有很直接的解决方案：搞 $O(\log n)$ 个随机函数，然后用直接的 OR 方法乘起来。这样次数是 $O(\log n)$，正确率是 $1-n^{-c}$，这样就可以 Union Bound。

这里有多层，如果每层搞一次，总的次数就是 polylog。

##### No Approximation for Parity

如果有，那我们就有一个 $d$ 次多项式和那个 $n$ 次的 parity=$\prod x_i$ 只在很少(0.1%) 的输入上不一样。那考虑任何一个函数，我们都可以通过写一堆 AND Term 把它写成 $n$ 次，不出现任何 $x_i^2$ 的多项式。然后考虑乘上 Parity，注意到对于给定输入 $x^2=1$，那么大于一半的 $x_i$ 相乘（在绝大多数输入上）等价于剩下的 $x_i$ 相乘，再乘上 Parity 的近似。因此任何一个函数都可以这样变成次数不超过 $(n+d)/2$ 的多项式，且它在 parity 正确近似的输入上结果都对。

但这样的函数有多少？数次数的结果是 $3^{\binom n0+\cdots+\binom{n}{(n+d)/2}}$，而实际上需要至少 $3^{|S|}$，其中 $S$ 是正确的输入个数。后者之前近似到了 $0.995*2^n$，但前者在$d=o(\sqrt n)$ 时都显然差了一个大常数（放缩方差即可得到），因此这必然是错的。

##### Extension to ACC0(p)

考虑上面的做法，注意到如果加一个模 $3$ 的 Gate，那似乎没有影响：直接把多项式加起来再平方，就是只有 $0$ 到 $0$、其它到 $1$。那上述结果可以直接扩展到 $ACC_0(3)$。

再考虑换域，考虑上面哪些步骤和 $F_3$ 有关。首先 $x^2=1$ 部分只需要 $F_p$ 上继续找 $-1$ 就可以了，但还有一步是把任意非零变成 $1$，$0$ 不变。那这只需要把平方变成 $p-1$ 次方。

但这对合数就很难成立(ex6)了：无论是 $ACC_0(6)$ 还是 $ACC_0(p^k)$ 现在好像都是 Open 的。

#### Monotone Circuits

之前已经提到过，一个单调的 Circuit 指完全没有 $\lnot$ 的，一个单调的函数指把 $0$ 翻成 $1$ 不减小函数值。显然前者计算的函数满足后者条件，另一方面也容易发现后者能被前者计算：实在不行可以大力写出 CNF 形式。

一个经典的单调函数（也是 NP-C 问题）是 k-clique：问图中是否有大小为 $k$ 的团。此时有如下结论：

> 对于 $k<n^{1/4}$ 和足够大的 $n$，计算 k-clique 需要大小为 $2^{\Theta(\sqrt k)}$ 的 circuit。

和之前的证明类似，我们希望找到一个简单的计算形式，说明单调 Circuit 可以被这个形式**近似**，最后说明这个形式不能在正确的大小内算 Clique。

首先，什么是一个算 Clique 的形式？一个做法是用 Clique Indicator：一个这样的东西可以用一个点集 $S$ 表示，它检查 $S$ 是否构成一个团，然后把所有东西的结果 OR 起来。好消息是，这东西看起来就不能很快地做 Clique：精确算必定需要 $\binom nk$ 的暴力，近似也可以分析。

但问题是，怎么能用这个近似任意 Circuit？考虑现在就有两个 Indicator 需要 AND 起来，那结果是一个不是团的边集需要同时为 $1$，但这太难用 Indicator 的 OR 来表示了。

##### Restriction of Input

这种情况下，我们可以只考虑一部分的输入：如果它能在一部分输入上近似 Circuit，但同时不能在这一部分输入上正确的算 Clique，那就寄了。具体而言，我们考虑如下两种输入：

1. 答案为 Yes 的部分，我们随机 $k$ 个点，构造一个这些点的团，其余不连边。
2. 答案为 No 的部分，我们随机给点 $k-1$ 染色，然后不同色之间连边。由鸽笼原理不存在大小为 $k$ 的团。

首先我们直接回来考虑上面的问题。对于 AND 两个 Indicator $S,T$ 的操作，这次我们直接得到 $S\cap T$。可以发现对于答案是 Yes 的部分，如果本来是两个 $1$，那么随机的点包含 $S,T$，所以 AND 起来还是 $1$；对于 No 的部分，我们期望本来就高概率输出 $0$，那合并后加限制显然不会变出 $1$。对于 OR 显然可以直接加起来。

现在只需要再限制搞出来的 Indicator 的数量：注意到如果两组 OR 再 AND 起来，那么我们会搞出平方个东西：$$(\lor A_i)\land (\lor B_i)\equiv \lor(A_i\land B_j)$$

所以我们肯定不能直接做，而需要进一步限制 Indicator 的数量。这里有两点需要考虑：Indicator 的大小和数量。

##### Sunflower Lemma and Count Reduction

如果有太多的 Indicator，能不能合并一些？一个直接的想法是拿出一堆 Indicator，换成它们的交集：如果有非常多的东西有一个很大的交集，那看起来很对。但实际上不能这样分析，而是需要考虑答案为 No 的部分有多少概率变成 Yes。回到 No 的染色构造，可以发现概率相当于有多少概率这个交集内颜色互不相同，但每一个原先的集合内都有相同颜色。但这时可以发现一些奇怪的例子：如果有一半集合多一个元素，一半集合多另一个元素（然后再随机加点元素使其两两不同），那上述情况出现的概率甚至是与 $k$ 有关的常数，这必然不对。

问题出在哪里？我们显然希望一些独立的事件来降低概率，而不是一个额外元素解决全部问题。此时有如下直接的结论：

###### Sunflower Lemma

任给一些大小不超过 $l$ 的不同集合，只要有 $(p-1)^ll!$ 个这样的集合，则可以找到 $p$ 个集合 $Z_1,\cdots,Z_p$，使得任意两个集合的交集相同 $Z_i\cap Z_j=Z$。

证明：归纳，$l=1$ 显然。对于其余情况，如果能找到不交集合组则直接成立，否则考虑极大不交集合组，其存在不超过 $(p-1)l$ 个元素，且任一集合都和这些元素有交。那找出交的最多的元素，其至少交了 $(p-1)^{l-1}(l-1)!$ 个集合，那么删去这个元素，对包含它的集合做归纳即可。

回到原问题，假设我们已经限制了 Indicator 的大小 $l$，那只需要 $(p-1)^ll!$ 个集合就可以找到一个 Sunflower，然后我们需要进一步限制概率，由独立性概率是每一个集合的额外部分加入后存在同色对的概率乘起来。根据随机性，我们只需要限制到 $l=c\sqrt k$ 就可以保证每一个概率是常数，然后取足够大的 $p$ 就可以解决。注意到这里 Circuit 可能非常大（有 $\exp(\sqrt k)$ 个点，每个点上可能需要做很多次合并），所以我们取 $p=O(\sqrt k\log n)$。集合数量上界 $m=(p-1)^ll!$ 可以放缩到 $n^{\sqrt k/100}$，每一步我们合并两个后会乘起来，然后每步消一些，所以最多 $m^2*size$ 步。只要 $2^{-p}$ 能够压住这个就可以了。这样错误概率是很小的。

##### Size Reduction

另一个问题是我们需要控制集合大小，每次 AND 的时候 Indicator 的大小也会加倍，但上面需要控制 $l$ 到 $O(\sqrt k)$。

考虑一个大小为 $l$ 的 Indicator 的影响。一个随机的 k-clique 在它里面的概率差不多是 $(k/n)^l$，因为 $k<n^c$ 这差不多就是 $n^{-\Omega(\sqrt k)}$。所以这还是可以压住操作次数。那么可以直接丢掉大的 Indicator 而错误率很小。

那这样从下往上做，我们得到了 $O(n^{\sqrt k/100})$ 个 Indicator，它们可以在两类输入上高概率近似原来的 Circuit。

##### Approximation by Clique Indicator

考虑一个 Indicator 实际上能干啥。首先，如果它的大小小于 $O(\sqrt k)$，那一个随机的 No 数据就很可能被判对，这可以生日悖论分析。

但另一方面，如果它的大小大于 $O(\sqrt k)$，那之前的分析说明它成功处理一个 Yes 数据的概率也只是 $n^{-\Omega(\sqrt k)}$。所以我们确实需要这么多个 Indicator，从而 $s$ 至少需要有这里的 $m$ 级别，就是 $n^{O(\sqrt k)}$。

#### Random Open Problems

##### Hardness for Stronger Classes

另一个方向是证明更强的复杂度类有很高的 Circuit Complexity。在 ch6 我们证明过了求 Hard Function 的问题可以被 $\Sigma_2 E$ 算，甚至还可以更好。Scale Down 的结果是 PH 包含任意 $SIZE(\Omega(n^k))$ 的函数，但这不一定说明它和 $P/poly$ 的关系。

还有一个更短，但是不那么构造的结论：

Thm. $MA_{EXP}\not\in P/poly$

证明：如果属于，那么 $PSPACE\in P/poly$，由 ch6 的某个证明 $PSPACE=MA$（发过去 Prover 的策略），从而直接 $MA_{EXP}=EXPSPACE$，这显然矛盾。

但下一步仍然是 Open 的：证明或证伪 $NEXP\not\in P/poly$。

##### ACC0 and Communication Games

Open Problem 1: 证明什么东西不在 $ACC_0(6)$ 里面。

###### Symmetric Representation of ACC0 Circuits

Thm(Yao 90, Beigel-Tarui 91). ACC0 Circuit 可以表示为如下的 2 层 Circuit：第一层全部为 AND 节点，入度为 polylog，数量为 quasipoly(exp(polylog))，然后输出只和这一层中 $1$ 的数量有关（symmetric）。

一个用法是，考虑 polylog-party communication。此时每个 AND 都能被至少一个人计算，且每个人都知道谁能算哪个 AND，那么排序一下就能每个 AND 算一次，然后每个人输出总和即可。

这样是一个 polylog-party，使用 polylog 个 bit 的方式。那如果有 Communication 的下界就可以有这边 ACC0 做不了的结论。但很遗憾的是现在的界都是 $n/exp(k)$ 的，如果能把指数压下去，就能解决这个 Open Problem。

##### Linear-size NC1

如果考虑限制入度的情况，那么至少需要 $O(\log n)$ 深度来考虑每个输入位，那么一个最简单的情况是

Open Problem: 找到一个 $O(n)$ 大小，$O(\log n)$ 深度的 Circuit 不能计算的函数。

Thm. 给一个 DAG，保证深度（最长路径）不超过 $d$，则可以删掉 $k/\log d$ 的边将最长路径长度除以 $2^k$。

Proof(ex10)(1.1*): 先按照深度分层，可以分成 $d$ 层，每一层向后面连边。那这可以看成一个完全竞赛图。

显然切两半直接删掉前面到后面的边可以让直径减半。

显然删掉 1->2 3->4 5->6 ... 可以让直径减半：每一块 $(2k-1,2k)$ 最多经过一层

能不能继续做？来一个线段树，然后考虑第 $i$ 层所有左儿子区间到对应右儿子的区间。刚才的东西就是第一层和最后一层。如果我们去掉一些层的边，那在树上向后的时候，不能在这些层转弯，那可以发现只能跳 $2^{\text{剩余层数}}$ 次：就在剩余层上按照一般跳法跳。如果大于这个次数，就考虑最高层跳的位置，找到更大的一侧向下讨论，总能矛盾。

那每删一层都是除以 $2$，选择边数最少的那些层删即可。

这是什么意思呢？原来的 Circuit 深度是 $O(\log n)$，考虑变成 $\epsilon \log n$，这样需要删掉 $O(n/\log\log n)$ 的边（因为除以常数），但删完之后输出就只和 $n^{\epsilon}$ 的输入（还有删掉的边）有关。那显然不是所有函数都能这样干，但和一万个例子一样，这里还是很难找到构造。

另一个想法是把这个看成通信。考虑输出 $n$ 位的情况。我们把输入分层两部分 $(x,i)$，其中 $x$ 有 $n$ 位，$i$ 有 $\log n$ 位，然后查询第 $j$ 位。然后考虑 3-communication：

1. 对于知道全部输入 $(x,i)$ 的人，他可以把上述过程中删掉的边的权值全部发送。
2. 对于剩下两个人，他只需要拿到 $j$ 后把这个 bit 用到的 $n^{\epsilon}$ 个输出 bit 分别发出来。

那么这样的通信复杂度是 $O(n/\log\log n)$，我们希望证明一些函数不满足这个条件，例如，考虑 $f(x,i,j)=x_{i\oplus j}$；但这还是很难。

##### Branching Programs

一个 Branching Program 是一个状态 DAG，每个点有一个标号 $x_i$。当到达这个点时，其读取输入的这一位，然后根据这个值有对应出边。

也可以是非确定的：有多条出边然后随便选一条。

Open Problem: 找到一个 P/NP 中的语言，其需要 $n^{1+c}$ 的 BP 来实现。

另一个定义是 BP 的 Width: 将 DAG 分层，使得每一层只连向这一层和下一层，最小化最大层的大小。

那显然常数 Width 的 BP 都可以用 NC1 表示(Ex9)：分治，每个区间记录进入第一层的某个点会到达最后一层的哪个点，这是常数信息量。

###### Barrington's Theorem: NC1 = Const-Width BP

首先后者属于前者就直接对 BP 做分治。

然后考虑另一个方向。我们使用如下构造：每个 gate 用一个序列表示，每个位置是一个群里面的元素，它依赖于输入的一个 bit；保证乘起来要么是 $\epsilon$ 要么是一个固定的元素 $a$。

从上往下确定 $a$，考虑怎么 AND，钦定两个输入给出 $a,b$，那考虑换位子 $aba^{-1}b^{-1}$（逆元部分完全倒过来构造即可）：如果有一个是 $\epsilon$ 也就是 $0$，那输出也是 $0$。否则，我们可以安排 $a,b$ 使得输出是我们想要的……吗？合法条件是换位子子群等于原群，或者至少换位子下去不会得到空，那么至少需要群不可解。一个最好的选择是 $A_5$。注意到每一层会大小加倍，所以对于 NC1 我们得到的还是 poly 大小的序列。

然后考虑表示 $A_5$ 的元素，那么可以写成一堆排列矩阵的乘法，每个排列矩阵由某个输入决定。然后排列矩阵的乘法很容易写成 BP 的形式，且 Width 正好是 $5$。

##### Karchmer-Wigderson communication games

已经在上一章证明过了。我们的目标是 NC1 之上的 lowerbound

Open Problem：在 NEXP 内找 $\Omega(\log n\log\log n)$ 的 KW-game Complexity。

一个 candidate 是，输入前半段是一个 Language 的 Truth Table(很可能需要 $O(\log n)$ 的深度)，然后把后半段重复作用 $\log/\log\log$ 次，每次重新拼接并划分。但我们很难证明重复作用深度必定叠加。

Ex8a: 用 KW Game 证明 Parity in NC1。

~~首先 Circuit 是非常简单的：直接分治 XOR 起来~~

考虑继续分治：双方说自己前半段的奇偶性，相同就递归另一侧否则递归这一侧，然后就一样做。

Ex8b(1.0*): 用 KW Game 证明 Majority in NC1。

Circuit 不那么简单：可以用如下 Trick 分治加起来，然后提取最高位：如果要把三个数加起来，可以先每一位求和 $0,1,2,3$，然后拆成 $1+2$，进而变成两个数加起来。做 $O(\log n)$ 轮后暴力加 $O(1)$ 个数即可。

所以 Game 更不简单。一个想法是直接上述 Circuit 抄过来，但这太难看了。

问题可以看成，一方的 $1$ 比另一方多，然后找不同位。

考虑继续分治，双方分别考虑左侧，但此时需要把和全部说出来才能判断往哪边走，这太难了。

考虑双方先交流一下总和。如果总和差的是奇数，那直接跑 Parity 就完了。但总和差 $2$ 怎么办？能不能不每次发两位而是一位一位考虑？

我们现在已知两边的差不是 $4$ 的倍数，考虑双方先问左侧/右侧的和模 $2$ 最高位是否相同。

1. 如果有一个不相同，那对着这边继续做。此时我们只考虑了一位。
2. 如果都同余，继续做下一位找不同。但这样的好处是，下一位我们就知道差不是 $2$ 的倍数，然后就可以调 Parity 了。

那更一般的情况也是一样的：假设现在已知差不是 $2^k$ 的倍数，然后从 $2^{k-1}$ 位开始向下比较两侧的和，直到找到不相同的。这样接下来可以降低 $k$。总的过程中 $k$ 减小 $O(\log n)$ 次，每一层额外 $O(1)$ 次，所以只用了 $O(\log n)$ 个 bit。

### XV Proof Complexity

Recall: CNF 是 OR 的 AND，DNF 是 AND 的 OR。找一组 DNF 的合法解或者一组 CNF 的非法解是平凡的，所以我们考虑的都是另一个方向。

判断 CNF 是否有解是 NP-c 的，这很难。但另一方面，如果 CNF 有解，那证明它是非常简短的：只需要给出这组解（不考虑怎么注意到它）；这正是 NP 的另一个定义：存在非常短的“证明”。

而另一方面，考虑证明一个 CNF 无解（或者类似的，一个 DNF 必定为真），这是 coNP-c 的。它能否被简短地证明呢？如果 $coNP\not\subset NP$，那对于任意一个证明模型，一定有一些无解的 CNF 不存在多项式大小的证明。因此，从这一角度出发，一种证明复杂度下界的方式是考虑不同“模型”下的证明长度下界。

和上述所有例子一样，常见的证明方式（ZFC，$\cdots$）是人们不会的，事实上更简单的东西也是困难的；因此我们会从非常简单的情况开始。

#### CNF and Resolution

回到刚才的例子：给一个 CNF，证明它无解。考虑一些简单但有效的证明方式（显然枚举是不需要考虑的）。这里给出如下方式：

1. 将 CNF 的所有 Clause 写下来，依次得到 $C_1,\cdots,C_k$。我们需要证明，不存在一种取值满足所有 Clause。我们尝试反证：假设存在取值满足所有的，尝试推出矛盾。
2. 每一步，选择两个存在的 Clause $A,B$，满足存在变量 $x_i$，使得 $A=x_i\lor\cdots_A,B=(\lnot x_i)\lor \cdots_B$，然后把两个 Clause 除去 $x_i$ 之外的东西拼（$\lor$）起来注意到对于任意取值，如果 $A,B$ 都被满足，那考虑 $x_i$ 的取值，可知 $\cdots_A,\cdots_B$ 里面至少有一个为真，所以 $\lor$ 出来必然是真的。
3. 如果有一步得到了空的 Clause（对 $A=x_i,B=\lnot x_i$ 进行操作），那显然矛盾（注意满足 Clause 的定义是满足其中一个 Literal）。此时即可结束。

上述讨论证明了这个做法的正确性。我们还希望证明它的完备性：任何一个无解的 CNF 都能被这样证明出来(Ex1)。

Proof: 考虑最暴力的证明方式：顺序考虑每个变量 $x_i$。对于每个 $x_i$，拿出所有包含 $x_i,\lnot x_i$ 的 Clause，然后把所有组合加进去，接下来扔掉所有包含 $x_i,\lnot x_i$ 的 Clause。我们需要证明，如果原来无解，则这样一步之后无解；然后就可以归纳证明最后必定推出矛盾。

不妨设有 $n$ 个包含 $x_i$ 的 Clause: $x_i\lor A_1,\cdots$；类似的有 $m$ 个包含 $\lnot x_i$ 的 Clause $(\lnot x_i)\lor B_1$。如果有解，则这一步之后，每个 $A_i\lor B_j$ 都被满足，从而每一对 $A_i,B_j$ 都至少有一个是真的。如果 $A_i$ 不全真，$B_j$ 也不全真，则这显然不可能；因此要么所有 $A_i$ 都是真的，要么所有 $B_i$ 都是真的。如果是第一种情况，我们令 $x_i=false$ 就可以满足所有 $(\lnot x_i)\lor B_1$，另一侧同理。

考虑这东西的复杂度，每一次 Clause 数量可能会平方，这看起来是 $2^{2^n}$ 的，但注意到本质不同的 Clause 只有 $3^n$ 个（如果出现了 $x_i\lor (\lnot x_i)$ 那么它可以被删掉），那去重之后复杂度就是 $2^{O(n)}$。

但这个暴力做法不比平凡做法快。事实上我们可以直接证明这种方式对某些问题需要指数级的步数。

##### Bottleneck Method

###### Pigeonhole Principle

考虑如下问题：

> 将 $n$ 个球放进 $n-1$ 个盒子，要求一个盒子只能放一个球。
>
> 具体地，记 $n^2$ 个变量 $p_{i,j}$ 表示第 $i$ 个球是否放进了第 $j$ 个盒子。则限制有两种：
>
> 1. 每个球至少需要放进一个盒子，这是 $n$ 条长 OR。
> 2. 每个盒子最多放一个球，那么可以枚举每一对球，它们不能同时放进这个盒子，这是 $O(n^3)$ 条短 AND。

小学数学经历告诉我们这东西必定不可能，所以它可以被 Resolution 推出矛盾。接下来我们考虑如何说明 Resolution 非常慢。

这里的证明分三步：

1. 限制到某类输入上，并以此对过程做一些变换。
2. 证明变换后的过程必定存在一个大 Clause。
3. 证明如果一定存在一个大 Clause，则一定存在指数多个。

但思考的过程很可能是反过来的。

###### Introduction

考虑把输入带入一个 Resolution 的过程。这个过程可以看成一个 DAG，每个点（Clause）入度为 $2$ 或 $0$。一开始，每个输入至少在一个入度 $0$ 的点上为 False，然后在结束节点上所有输入都是 False。考虑每一个中间节点，合并两个 Clause 的过程

$$
(x_i\lor A),((\lnot x_i)\lor B)\to (A\lor B)
$$

如果一组输入在结果节点上是 False，那它至少在一个入度节点上是 False。但反过来是不一定的：显然两个输入（因为 $x_i$）不会全部 False，但 False+True 的情况输出是不确定的，也可能是 True。因此这可以看成，每个 Clause 证伪了一部分输入，每次合并时可以合并两边证伪的集合，但又会以神奇的方式丢掉一些。目标是合并到全集。

但此时我们还啥都看不出来。

###### Hard Distribution and Monotone Replacement

和之前的一万个例子一样，我们只考虑一类特殊的输入，使得在这类输入下我们可以做一些变换。

考虑 $n$ 组输入，第 $i$ 组输入中，第 $i$ 个球不放，剩下的球任意排列放进盒子。或者说，将 $p$ 看成 $n\times(n-1)$ 的矩阵，则第 $i$ 行为空，剩余部分构成一个匹配。

回到上面的过程，这个过程只关心每个输入在每个 Clause 上的结果。注意到每个盒子都是放了球的，我们可以做如下变换：

$$
\lnot p_{i,j}\to \vee_{k\neq i} p_{k,j}
$$

这不改变所有赋值后的结果，且操作后 Literal 只存在 $p$，而不存在 $\lnot p$。

###### Large Clauses

回到上面的思路。每个 Clause 证伪的东西是两个输入的合并起来，再丢掉一些东西。初始时，每个限制可以证伪一类输入，最后合并到证伪了所有 $n$ 类输入。那可以发现，存在一个 Clause 证伪了 $[1/3,2/3]$ 的输入：在合并到 $1/3$ 之前，两个合并起来不可能超过 $2/3$。

也可以按类考虑：类似可得存在一个 Clause，它证伪了 $[n/3,2n/3]$ 类输入（每类至少一个），而剩下的全是真的。

然后考虑两类 $i,j$，满足第 $i$ 类存在一个被证伪的输入，但第 $j$ 类都没有被这个 Clause 证伪。考虑第 $i$ 类的那个输入，如果我们把第 $j$ 个球所在的盒子换给第 $i$ 个球，它就变成了一个第 $j$ 类的输入，而我们只是把一个 $p_{j,c}$ 换成了 $p_{i,c}$。又注意到上一步我们已经变成了单调的 Clause，所以这个 Clause 必定存在 $p_{i,c}$，其中 $c$ 是第 $j$ 个球原先所在的盒子。那对于每对 $(i,j)$ 做一次，所有 $p_{i,c}$ 两两不同（首先 $i$ 决定第一维，然后一种情况内第二维不同。这里单调保证了不用 $p_{j,c}$，后者可能只有 $n$ 个。），从而至少有 $2/9n^2$ 个 $p_{a,b}$。

###### Many Large Clauses

现在我们证明：如果每个证明方式在上述操作后都至少存在一个大小为 $2/9n^2$ 的 Clause，则一定存在很多个大小为 $n^2/10$ 的 Clause。

想法是，每个大 Clause 覆盖了 $1/10$ 的变量，所以可以填一个变量满足 $1/10$ 的大 Clause，然后删掉同行同列其它变量（赋值 $0$）（类似之前的 random restriction）。注意到这样填完之后，问题变成了一个小一点的鸽笼原理：还剩 $n-1$ 个球和 $n-2$ 个盒子。

考虑继续删（如果一个 Clause 因为移除变量而变得小于 $n^2/10$ 了，则不考虑它），这样 $\log |Large Clauses|$ 轮之后删完。如果这个数小于某个 $cn$，那搞完之后不存在 $2/9(n-cn)^2$ 大小的 Clause。

考虑给变量赋值对变量造成的影响。首先考虑删掉过程中被取值满足的 Clause，然后删掉剩下不满足的 Literal。考虑 Resolution 的一步，如果三个都没被删或者结果被删了，那毫无影响。那关键情况是两个输入有一个被删了，但输出没被删。那有效赋值变量就只有使用的 $x_i$，此时另一个一定完整保留。考虑就用那一个，这样会导致一个 Clause 变成它的子集。我们只需要再证明把 Clause 变成子集不影响证明。这就和之前一样，如果一步用 $x_i$ 的时候它在一侧被删了，那就用这一侧剩下的。然后归纳就完事了。

这说明，搞完赋值操作后，我们得到了一个对小的鸽笼原理有效的证明，且它不存在大的 Clause。但这就矛盾了。所以 $\log |Large Clauses|$ 是 $\Omega(n)$ 的，这就是指数级步数。

##### Interpolation Theorem

###### Basic Interpolation

Thm. $\phi(x,z)\lor \psi(y,z)$ 恒真当且仅当存在函数 $I$，使得 $(\phi(x,z)\lor I(z))\land(\psi(y,z)\lor \lnot I(z))$ 恒真。

Proof. 先考虑没有 $x,y$ 的情况。枚举 $z$ 并决定 $I(z)$。如果 $\phi,\psi$ 有一个是真的，那用 $I$ 盖住另一侧即可；另一方面，如果后面是真的，那没被盖住的一侧是真的。有 $x,y$ 的情况把“是真的”换成“一定是真的”即可。

这怎么用？

###### Circuit Interpolation

Thm. 在上述情况下，如果 $\lnot (\phi(x,z)\lor \psi(y,z))$ 可以被 Resolution $S$ 步证明无解，则存在 $O(S^2)$ 的 Circuit 计算一个满足条件的 $I$。

Note. 我们可以认为步数包含初始 Circuit，因此 $\phi,\psi$ 需要写成 DNF 的形式且 Clause 很少，这样才能把整个式子写成很短的 CNF。

Proof. 考虑给一个 $z$ 怎么做。类似之前的想法，把 $z$ 的值带入整个 Resolution 的过程。一开始，每个 Clause 只包含 $(x,z)$ 或者只包含 $(y,z)$。如果合并的变量是 $x$ 或 $y$，则我们不作改变。如果合并的是 $z$，那赋值后我们知道有一侧已经真了，所以赋值后实际上假设变为另一侧需要能被满足（而不再需要是两侧并起来，因为 $z$ 提前固定了）

可以发现这样每步操作后，得到的 Clause 还是完全属于某一侧的，所以可以继续做。最后我们推出矛盾，也因此是只属于某一侧的。从而，我们只需要记录每个 Clause 处理后属于哪一侧，然后从前往后做即可。

然后就可以直接写成 Circuit。（也可以不维护新的 Clause：如果一侧被删了但是按照没删做，也不影响结果。）

###### Monotone Circuit Interpolation

我们还有进一步的结论：如果 $\psi$ 里面 $z$ 的出现是完全单调的（不出现 $\lnot z_i$），则存在单调计算 $I$ 的 Circuit。（注意如果 $\phi,\psi$ 互斥，那么 $I$ 完全计算的是 $\psi$，所以它是合理的）。类似的，如果 $\phi$ 里面出现的都是 $\lnot z_i$，那么结论仍然成立。

Proof.(ex2) 考虑上面的部分我们在做什么。如果判断出来两个输入值（所在的方向）相同，那我们直接用输入的结果。如果不同，那我们读 $z$ 的值，选择相反的那一边作为输入。选择器是很难单调的，但考虑使用上面的性质：$I=0$ 表示 $\phi$ 那一侧，$I=1$ 表示 $\psi$ 那一侧。如果出现了最后的情况，那根据假设，到这里一定是 $\phi$ 一侧有 $z_i$，$\psi$ 一侧有 $\lnot z_i$。为什么反过来了？注意到我们扔给 Resolution 的是 $(\lnot \phi)\land (\lnot \psi)$。所以如果 $z_i=1$ 我们选 $\psi$，$z_i=0$ 选 $\phi$，此时读 $z$ 即可。

如果我们不维护真的 Clause，可能出现形式上操作反过来的情况，这表示实际上两个 $z_i,\lnot z_i$ 都被删掉了，那任意选一个都是合理的，所以应该也不用考虑。

###### Resolution Lowerbound from Clique

然后我们考虑如下问题：

1. $\phi(x,z)$ 表示 $x$ 是否是图 $z$ 中 $n^{1/4}$ 大小的团。
2. $\psi(y,z)$ 表示 $y$ 是否是图 $z$ 中 $n^{1/4}-1$ 染色。

那显然 $\phi\land \psi$ 不可能是真的，所以可以 Resolution 它。

考虑表示 $\phi,\psi$，那只要编码常规（比如图直接给邻接矩阵），两者都容易写成 CNF(ex3)（注意到这里和上面实际上反了过来，所以 CNF 是对的）：团是验证每条边是否存在（可以发现这是单调的），$\psi$ 是验证每条边是否不存在。

如果这东西能被很快的证明，那我们就有一个很快计算的 $I$。但我们回到上一章的证明：任何一个在 $k-1$ 染色图和 $k$-团上正确计算 $Clique_k$ 的单调 Circuit 都有指数级下界。这里在这两种图上，显然两者正好有一个是真的，从而 $I(z)$ 正好表示 $\lnot\psi=\phi$（还是注意这里反过来了），那 $I$ 就在这些输入上计算了 Circuit。这说明 Resolution 证明这东西的长度也是指数级的。

#### Other Proof Models

##### Integer Programming and Cutting planes

整数规划的定义这里就不说了。

众所周知，如果是一个线性规划问题 $Ax\leq b,x\geq 0$，那无解当且仅当可以直接线性组合行以求出矛盾。换言之。存在一个非负线性组合，得到 $(sth positive)\leq -1$。或者也可以全部写成 $\leq$ 的形式，然后限制变为得到 $0\leq -1$（上一种情况中，正的部分可以被减掉）

但整数规划就没有这么容易了：合法的 Polytope 可能存在，但其中不一定有整点。此时的一种证明方法如下：

> 类似之前的记号，我们从给定的限制不断推出新限制，得到 $0\leq -1$ 时不合法。
>
> 首先我们每一步可以做一个整系数线性组合。而关键是我们还可以进行如下操作：
>
> 如果当前有一个线性组合，满足 $x_i$ 的所有系数有一个 $gcd$，那我们可以整体除以这个 $gcd$，然后对常数部分 **取整**。

最后的取整步骤是关键的。我们可以证明它的正确性和完备性：一方面，如果有解，那么每一步之后那个解仍然满足新的方程（注意到左侧组合出来都是整数，取整不影响结果）

然后我们证明完备性(ex4)。考虑如果存在一个没有整点的 Polytope，我们希望说明能够继续削这个 polytope。考虑它的一个顶点，根据某经典结论一定存在一个切这个顶点的超平面，其和 polytope 只在这里相交。进一步我们可以找到一个有理系数的超平面。更近一步，我们不希望找到的超平面在整系数后右边也是整数，但这可以微调系数解决(?) 因为顶点是一堆线性无关平面的交，我们总可以用这些平面整系数组合出任何平面（系数可能乘很多倍），然后除下来，然后取整就可以削掉顶点。

一个可能更好的方式是直接一维从高到低一个一个删，每一步微调一下系数。

这里也有非常有趣的 lowerbound(Pudlák 97)，但是咕了。

##### Polynomial Equations and Hilbert’s Nullstellensatz

问题：给一堆 poly 等式：$P_i(x_1,\cdots,x_n)=0$，证明无解。

结论：有解当且仅当存在一个多项式系数组合，得到 $0=1$。

因此一个证明就是构造这些多项式系数。那构造的方式，Polynomial Calculus 和之前的想法类似：有一堆多项式，每一步我们可以操作得到新的多项式。

##### Frege and Extended Frege

Bounded-depth Frege: 类似之前的 Resolution，但我们允许用多层（常数层数）的 Clause。（可以认为 Resolution 就是一层）

Frege: 我们允许任意深度的 Formula，以及一车需要的转换法则。

Extended Frege: 我们额外允许换元：将一个变量换成一个 Formula。

第一个人们好像还会做(todo: Ajtai88)，后面的现在还 Open。

#### Is P vs NP independent?

显然我们并不知道这件事。

一个趣事是，我们可以考虑这里的问题。例如，SAT 不存在 $O(n^{100})$ 的 Circuit 可以写成，对于任意 $n^{100}$ 的 Circuit，总存在一组输入让它算不对。那这相当于一个 $2^n$ 大小的 Formula，但暴力验证是 $2^{n^{100}}$ 的，因此一个问题是这东西有没有一个证明复杂度下界。

事实上确实有一些结论：这东西要么是错的，要么它在一些简单的系统里面很难证。但在例如 Extended Frege 上，人们还不会做。

另一个结论是，如果这种问题在 Extended Frege 上有 lowerbound，那更弱的 proof system 就不能证明它。但我懒得学 PV 或者 bounded arithmetic 了。

### XVI Algebraic Models

一般的计算模型都是只考虑 $\{0,1\}$ 上的操作。如果算法中需要维护一些数，那常见操作是维护二进制表示。在所有数都是 poly 长度/poly 精度的时候，处理这件事通常都是被忽略的。另一方面，一种直接的操作是往计算模型里面加入在某个域下计算的能力：直接把每个元素从 $0/1$ 变成域里面的元素。

显然，如果域是有限域，那么这件事和原来的 $0/1$ 模型非常等(ex1)价：随便表示一下有限域上的元素即可。因此更有趣的情况是无限域，例如 $\Z$，$\R$ 和 $\mathbb C$ 下的计算。可以想象，如果一个位置能存任意一个无限域的元素，那这个事情会变得非常强。例如，我们有：

1. 如果这个模型支持接入任意常数，比较一个数是否 $>0$，那我们可以判定任何 $P/poly$ 里面的问题(ex12)：例如，考虑 unary HALT，我们可以把每个长度的答案直接编码到一个实数里面，然后不断 $*2,-1$，判断大小取出前面的位。但这显然是难以接受的。
2. 即使我们不接入常数，甚至只考虑整数问题，这个模型还是非常强。例如，如果我们考虑 $\Z$ 上的模型，然后支持取模（和 $==$ 的 branch），那我们就能直接做质因数分解(ex10)，而这被相信是困难的。

Proof(1.2*): 考虑算阶乘，如果能 poly 算，那我们套个二分判 gcd 是否是 $1$ 就能分出最小因子。

然后考虑怎么算阶乘。根据 oi 经典操作考虑倍增：记 $f_n(x)=(x+1)(x+2)\cdots(x+n)$，那么 $f_{2n}(x)=f_n(x)f_n(x+n)$，答案是 $f_n(0)$。这里只需要支持多项式相乘，或者复合一次函数。

考虑怎么存多项式。那一个想法是选一个 $B>n!$（为了好算我们可以取 $B=n^n$），然后把多项式表示为 $f(B)$。这样只要系数不爆（这个做法显然没有负系数），乘法就可以直接乘。

然后考虑怎么带入。显然 $f_n(0)$ 只需要对 $B$ 取模。类似地想一想，$f_n(1)$ 只需要对 $B-1$ 取模，这样 $B^i$ 就会取模到 $1$，类似地 $f_n(c)$ 可以对 $B-c$ 取模。但如果要带入 $x+n$，那看起来得对 $B-(B+n)$ 取模，这看起来没有道理……但我们没有规定过每一步需要用相同的 B。考虑第 $i$ 层用 $B_i=B^{n^{\log n-i}}$，这样相邻两层之间差 $B^n$ 倍，所以一层到下一层不会爆，取模 $B_i-(B_{i+1}+n)$ 即可。同时指数是 $\exp(\log^2 n)$，所以还是能快速幂出来。

这有两点启示。其一，设计相关模型的时候需要小心地考虑能加进去的操作，而不是像做 $F_{998244353}$ 的情况一样所有操作直接加进去。其二，这个模型确实强于普通模型，因此它的下界显然是更有用的，但它的上界困难也是更好的。

#### Straight-Line Programs and Circuits

定义一个代数电路为一个类似 Circuit 的东西，但：

1. 输入为每一个 $x_1,\cdots,x_n$，或者 poly 个常数变量。
2. 每个节点的运算为 $+$ 或者 $\times$。

定义一个 Straight-Line Program 为 poly 条顺序语句，第 $t$ 条语句形如 $y_t=(sth) op (sth)$，其中每个操作数是常数或之前的结果或输入变量，操作为 $+,\times$。

显然这两个是等价的：拓扑序一下。

然后有一些简单的例子：

(Ex2): Fast DFT

(Ex3): 多项式乘法

(Ex4): 分治矩阵乘法，$O(n^{\log_2 7})$。分治的思想是容易的：如果 $k\times k$ 能用 $k^c$ 步做，那就是 $O(n^c)$。

(Ex6): 行列式 in Alg-NC2。高明的 Cycle Cover 容斥。我记得好像是说，每个点可以考虑一个从它出发，只经过更大的点的 Walk，总长度为 $n$。然后 $k$ 个 Walk 系数 $(-1)^k$。这样如果有交，那合并的和不合并的可以抵消掉。然后容易分治+DP。

##### AlgP/poly, AlgNP/poly

定义：

1. AlgP/poly 是任何一个 poly 大小的上述东西能算的，且次数**不超过** poly 的函数。
2. AlgNP/poly 是在上一个的基础上，可以再任意做几次 $\sum x_i\in\{0,1\}$。

Note:

1. 限制次数主要为了避免 $n$ 步算 $x^{2^n}$ 这种东西。
2. 这里 NP 的定义实际上更类似于 #P，因为有计数。事实上：如果我们套一个排列求和，这东西就可以算 Perm；类似的可以数哈密顿路径等东西（因为 Perm 已经 #P-c 了）

这里可以定义 reduction 为简单换元（只能换到 $0,1,x_1,\cdots,x_n$），但这样也能构造出：

1. Perm 是 AlgNP/poly-complete 的。

#### Algebraic Computation Trees

上面的模型里面没有任何的 Branch，还是比较阳间的。接下来我们考虑一些包含 Branch 的操作。

定义 Algebraic Computation Tree 是一个类似 Branching Program 的东西：有一棵树，每个点是一个状态。除此之外还有一堆额外变量。每个点的状态形如：

1. 对变量进行操作（类似 Straight-Line Program），然后跳到唯一的儿子。
2. 根据某个变量与 $0$ 的大小关系，跳转到多个儿子中的一个。
3. 输出 $0/1/...$

它的代价定义为最大深度，其中 $+,-$ 不计算代价，$*,/$ 和分支都计算代价。

那么可以定义这个模型下的复杂度，称为 AC(f)。这个模型也被称为 Linear Search Algorithm。

Note. 这也是 Non-uniform 的，甚至 poly 代价的时候它能有指数级的 Non-uniformness。事实上我们甚至有：

[A Polynomial Linear Search Algorithm for the n-Dimensional Knapsack Problem]：Subset Sum 可以在这里做到 poly(n)，好像是 $O(n^5)$ 的深度。

做法简述：我们考虑如下问题：给**任意**个整系数，系数有界的超平面，问一个实数点是否在至少一个超平面上，保证点的范围有界。则这个问题可以做到 $poly(dim)*f(v)$。

首先需要如下定理：对于系数有界的超平面，它们在一个有界区域内围出来的闭合区域大小有一个下界，大概是 $exp(-poly(dim))$ 乘一些常数相关量的。

然后可以说明，在有界区域内，总存在一个参数 $r$，使得一个半径为 $r$ 的球内，任意超平面如果有交，则交必定相同。（如果有几组不同的交集，则它们投影后围出了一个闭合区域，然后我编不下去了）

现在考虑一个子问题：所有超平面的交两两相同。考虑三维的情况，此时交是一条线。很容易发现我们取一个与交线不平行的平面，然后全部沿着交线投影过来，就变成了二维的问题。（注意到平面包含交线，那么投影不会造成问题）

这在更高维下还是成立的，但 $2\to 1$ 有一点小问题：点线相交的维数 $0+1<2$，所以不太直观。但 $2$ 维已经可以二分了。

因此考虑如下算法：每次按照 $r$ 划分区域，定位区域后选两个和区域相交的超平面算交，然后构造投影平面并投影到低维问题（我们需要把询问点也投影，而不是投影到询问平面。目的是让构造和输入无关）。好处是我们只需要在构造树的时候维护当前区域究竟有哪些超平面，但之后就不需要了。除去维护超平面的集合，剩余部分都是 poly(dim) 的。

然后看 Subset Sum 的问题，这相当于 $2^n$ 个超平面：$\sum_{i\in S}x_i=1$（可以归一化）的并，那就可以用上述做法。

这说明我们对于简单的问题很难有超过 poly 的下界。但我们还可以考虑一些简单的下界。一种方法基于类似 Tilling 的分析思路，考虑每个叶子处的输入集合：

数学结论：$n$ 维空间，$h$ 个 $d$ 次不等式限制，得到交集的连通块大小不超过 $d(2d-1)^{n+h-1}$，即 $exp(n+h)$。

一个问题是，树上可能引入新的变量。但注意到投影回输入空间显然是减少连通块数量，所以这也不需要考虑。

显然连通块并一下只会变少，那么有如下结论：

记 $C$ 为答案为 $0/1$ 的连通块数量的较大者，则 $AC(f)\geq O(\log(C)-n)$。

Proof: 有 $2^d$ 个叶子，深度 $d$，那么 $2^d*\exp(n+d)\geq C$。

例如，考虑如下问题：给 $n$ 个数，判断是否存在相等的数。考虑答案为 $0$ 的集合。我们声称任何一组不同的大小顺序对应一个连通块：如果不同大小顺序连通，那么变换过去的过程中必然相对顺序改变，这就跨过了答案为 $1$ 的面。因此 $C\geq n!$，从而下界是 $O(n\log n)$。一种方式是，先排序然后顺序比较。

#### BSS Model: Algebraic TMs

考虑一个图灵机模型，但是每个格子上是一个域里面的元素。然后和普通图灵机一样，有常数个 state，每一步

1. 如果当前 state 等于 $a$ 且格子值**等于** $b$，则跳转到某个 state，对当前格子的值进行某个函数，head 往某个方向移动。
2. 否则，做另一套这样的操作。

显然，如果域是 $F_2$，那这就是一般图灵机。

一个关键问题是函数可以怎么取。最直接的，我们不希望一个不能 poly 描述的东西，比如一个停机问题 Oracle 的编码。

更近一步，我们还不希望一些奇怪的东西出现。比如如果能取整，就能取模，然后就能分解质因数(ex10)。所以一个良好的定义是，我们只允许简单分式作为函数。简单的含义是常数度数。

当然这并不能避免函数里面出现停机问题的常数，因此我们 branch 条件限制为等于，不然就能读出来了。

然后我们可以在这个模型下定义类似 P,NP 的东西：

1. 定义 $P_{\F}$ 是某个域下上述模型 poly 能算的东西。
2. 对于 $NP_{\F}$，使用 Certificate 的定义。

同时，我们定义 $0-1-$ 上述模型，表示限制输入只能是 $\{0,1\}^*$。

##### 0-1-NP_C complete problems

问题：给一堆多项式等式，问是否存在一组解。

Proof: 一个方向显然。对于另一个方向，考虑抄写 Cook-Levin Theorem，只是变化部分变成了各种多项式，$x$ 和 $(1-x)$。但我们还需要把输入系数变为 $0/1$。注意到原输入是 $0/1$，可以做点取整操作。

##### Undecidable Problems

显然一个 $T$ 步结束的 BSS TM 可以写成一个这样深度的 AC Tree(ex11)：直接展开所有 Branch。

回忆 AC Tree 部分，这里问题是一整个图灵机判定的东西改成了随着 $n$ 增长的树。

但无论如何，一棵树有可数个节点，每个节点对应常数个连通块。因此它计算的函数是可数个闭集的并。但这显然不表示所有函数，随便拿一个过来即可证明不能被计算。

### XVII Complexity of counting

> 统计方案数，~~模 998244353~~

#### Function problems, #P

我们来定义“计数”对应的复杂度类。很遗憾的是，计数并不是一个判定性问题，因此我们首先考虑如何构造非判定性的问题，那么：

FP(Function P)：所有被 poly-time TM 计算，但不一定是判定性问题（输出任意）的函数。

然后就有：

#P: 所有如下语言构成的集合：给一个 poly-time $M(x,y)$，对于每个 $x$ 输出为使 $M$ 接受的 $y$ 数量。

计数显然是比判定难的：如果能计数，就至少能判定有没有解。

#### PP

很多时候我们还是希望研究判定性问题，因此我们想要找到一个和 #P 对应的判定性版本。而这确实是存在的：考虑最高位。

PP：所有如下语言构成的集合：给一个 poly-time $M(x,y)$，对于每个 $x$ 输出是否有至少一半的 $y$ 使得 $M$ 接受。

首先由如下结论：$#P\in P^{PP}$，因为我们可以加一些接受/拒绝的 $y$，然后二分。另一个方向是显然的，这差不多说明它们是某种意义上等价的。

Note. 我们一般不拿 mapping reduction 来搞 FP 上的规约，否则需要大战输出格式。一种类似 mapping reduction 的方式是同时映射输出，但我们也有完美映射的情况。

#### #P-completeness

这里仍然使用 Oracle，或者 Turing reduction 来定义：

1. $L\in \# P$
2. $\# P\in FP^L$

Thm. #SAT is #P-c.

Proof. 注意到在远古时期，我们证明 NP-c 的时候发现了到 SAT 的规约是方案一一对应的，所以方案数也是保留的。

##### Per is #P-complete

Permenant: 给一个方阵 $M$，求 $\sum_{\sigma\in S_n}\prod M_{i,\sigma(i)}$。如果我们把方阵看作邻接矩阵，那这就相当于图上 cycle cover 的计数。

现在我们给出一个 #SAT 到这里的规约。和之前一样，我们一定是一个高明的 gadget 构造。

构造 Variable：考虑一个 $a_i\to b_i$，然后从 $b_i$ 连回来两条路。这样不走的那条路就需要自行寻找匹配，这一边就可以对应一个变量取值。为了更好的独立性，我们可以隔着加自环，这样就是很多个近似独立的 $\to t_i\to$ 和 $\to f_i\to $。

构造 Clause: 有三个 $\to x_{1,2,3}\to $，要求构造使得取值 $1$ 当且仅当有一个是 True，否则 $0$。一种构造如下：假设三个全部连到环上得到 $a\to x_1\to b\to x_2\to c\to x_3\to a$，然后加边 $a\leftrightarrow d,b\leftrightarrow d,c\leftrightarrow d,b\leftrightarrow c$。可以发现如果三条边任意出现 $0,1,2$ 条时，都存在唯一的 Cycle Cover。如果全部出现，则 $d$ 没法匹配。

但这要求把一个 $\to t_i\to$ 的状态平移过去，因此我们有：

Clone Gadget：给两个 $\to a\to,\to b\to$，构造 Gadget 满足方案非零当且仅当两个正好选一个。

我懒了，总是能造的。直接的构造需要带权边，因此我们需要：

处理负权：模一个大于 $n!$ 的数(考虑 0-1-per)。

处理整数权值：首先构造 $2^k$，然后构造加法。具体来说我们需要构造一种 $a\to b$，使得走过去 $2^k$ 种，不走过去里面有一种。构造大概就一个完全竞赛图加上每个点一个自环，然后选点是 $2^k$ 方案数。

#### Approx of #P

考虑计数的近似问题。我们希望得到这样的一些东西：

APX: 存在常数近似比 poly 算法。

PTAS: 对于任意近似比，存在 poly 算法。

FPTAS：对于任意近似比 $1+\eps$，存在 $poly(n,\eps^{-1})$ 算法。

额外的，可以把 T 换成 R 代表随机算法。

##### Easy Approximation

一些 #P-c 的问题是可以被近似的：它们至少存在一个 FPRAS 的算法。

这些近似大多基于如下方式：均匀采样+子问题 self reduction。

例如我们考虑 01perm 的问题，假设我们能随机采样，那考虑如下方式：每次随机采样，然后找权值最小的边删掉。这样经过 $n^2$ 步，我们可以（高概率）得到连续的 $n^2$ 个 perm 问题，每一个比前一个删了一条边，且后一个问题答案至少是前一个的 $1/3$。然后对每一对问题我们在大的里面随机采样，看是不是下一个问题里面的，这样可以得到两个答案比值的精确近似（Chernoff）。然后乘起来就可以了。

而 Perm 的均匀（低误差）采样是真的能做的：这种东西一般是构造一个高明的 MCMC，然后证明收敛。但是我懒了(todo)。

##### Hard Approximation

但也有些问题是困难的。例如，考虑简单环计数的问题。它第一眼还比较正常，但如果我们把每条边换成 $n\log n$ 层两个点交替，从而把边权变成 $n^n$。那可以发现一个哈密顿路可以贡献 $n^{n^2}$，但小环加起来都不能贡献到 $n^{n(n-1)}n!<n^{n^2}$。因此这个是 NP-Hard 的，甚至任意 poly(n) 的近似都是 NP-Hard 的。

事实上，我们可以说明：如果存在一个 poly 的近似，那很多情况下就存在 FPRAS。我们考虑可以 Direct Product 的问题：对于问题 A,B，我们容易构造方案数是两个问题方案数乘积的新问题。例如，独立集计数和 #SAT 都满足这个条件。那考虑 pow 很多次，我们得到了 $V^{n^100}$ 的 poly 近似，那就是非常好的 $V$ 近似。

#### Toda's Theorem

Thm. $PH\in P^{\# P}$，也可以是 $P^{PP}$。

##### From NP to class UP

我们再定义一些与"合法解 $y$ 的数量"相关的类。沿用 PP 的定义，但是：

1. Parity P: 把由最高位决定换为由最低位 $\pmod 2$ 决定。
2. UP: 问方案数是不是 $1$。有两种定义。严格定义是说保证 $M(x,y)=1$ 对于任意 $y$ 至多有一组解，然后需要判定有没有解。一个更弱的版本是带 Promise 的：如果正好一组解则 YES，无解则 NO，否则任意。

Thm.(Valiant-Vazirani) 可以把 NP 问题(SAT)以 RP 的方式随机规约到 Promise-UP，即：

1. 如果 $x$ 是 YES，那么有一定概率可以得到 UP 中正好有一组解的情况。
2. 如果 $x$ 是 NO，则一定规约到无解情况。

Proof. 我们需要区分有 $0$ 组解，和有 $>0$ 组解的情况。回忆之前的 Set Lowerbound Protocol，如果我们用一个 2-wise independent hash function(简称 $Ax+b$) 做一个到值域 $p$ 的随机映射，则 $s$ 个元素映射到某个位置的概率至少是 $s/p-(s/p)^2$，这是用 $\binom n1-2\binom n2\leq 1$ 算出来的。但进一步可以注意到，这个值只在 $n=1$ 的时候取到 $1$，所以这也是正好有一组解概率的下界。那么如果取一个 $p$，我们就可以对 $s/p\in[c_1,c_2]$ 中的一段满足条件。因此可以倍增取 $O(\log 2^n)=O(n)$ 个 $p$，总有一个能对非零的解数做到常数正确概率（显然无解不可能找到解）。但我们显然不知道有多少组解，因此可以随机一个，即如下规约：

> 随机一个值域 $2^i$，随机一个 $Ax+b$，问是否正好有一组解满足 SAT 和 $Ax=b$.

##### Parity P, probability amplification

上述规约的概率是 $O(1/n)$ 的。一个 Open Problem 是能不能把 UP 的规约做的更好。这里的问题是 UP 不能直接通过重复做来放大概率或者做一个 OR：如果一边有一组解，一边可能有任意组解，那很难合并出一个只有一组解的 YES。所以我们只能随一个输出。

因此我们考虑 Parity P，这相当于输出方案数模 $2$，而在 $F_2$ 下我们有很多方式做这件事：例如，$F_2$ 下做 OR 就是 $x+y-xy$，而 SAT 方案数相乘就是 Direct Sum，因此我们可以直接把那 $n$ 个情况全部 OR 起来，就得到了 $n$ 倍大小，常数概率正确的东西。然后再自己 OR $n$ 层就是指数小的错误率。

##### From NP to PH

显然我们能 $exp(-n)$ 错误率的做 NP，我们就能做 coNP。

然后考虑 $\Sigma_2$，那相当于 $2^n$ 个 coNP 再 OR 起来。那我们先对 coNP 跑上面的规约，但把正确率再调高点，然后把 SAT 换成上面规约的结果，再做一次 OR 即可。然后就能做 PH。

进行一些简单的 Check。每一层会给大小乘以 $n$，但只有常数层，所以可以接受。最后我们还是能随手做到指数小错误率。

至此我们证明了 $PH\in BP\dot \oplus P$。（如果忘了这个记号是啥，可以回去参考随机章节的随机规约）

##### Derandomization Step

怎么把随机去掉？现在的问题是，有一堆方案数，我们保证绝大多数是奇数或者绝大多数是偶数，需要用计数来区分这两个 Case。

直接数数还是不行的，因为一个变化就可以改变奇偶性。但如果把奇数/偶数换成 $0/1$，那直接数高位就完事。因此注意到 $4x^3+3x^4$ 满足：

1. 如果 $x\equiv 0\pmod {2^k}$，则显然 $4x^3+3x^4\equiv 0\pmod {2^{2k}}$
2. 如果 $x\equiv -1\pmod {2^k}$，则 $4x^3+3x^4\equiv -1\pmod {2^{2k}}$。这里的关键是 $4(1-x)^3+3(1-x)^4$ 的一阶项被消掉了。

因此做嵌套 $O(\log n)$ 次，我们就可以把奇偶变成 $\pmod {2^{O(n)}}$ 下的东西，此时大小也只增加了 $2^{O(\log n)}$ 倍。这样再求和模一下就能看出来了。

#### Exercises

Ex5: 证明如果 $P=NP$，则存在 #P 问题的 APX / PRAS / PTAS。

Prf(0.6*): 首先注意到我们可以直接跑 Set Lowerbound，这个是 $BP\dot NP$ 的：随一个 Hash Function，然后找一组解，这就是随机的 APX。

然后考虑怎么 PRAS，那么类似之前的方式，对于 $\eps$ 倍的差距，我们可以多 Direct Sum 几次把它变成常数倍差距，然后再跑 Set Lowerbound。

最后考虑怎么确定性，那我们可以拿出之前 Perfect Completeness，或者 $BPP\in \Sigma_2$ 的步骤：先把 gap 放到 $O(n)$ 倍，然后拿 $O(n)$ 个 $Ax+b$ 覆盖所有值域。单点被覆盖的概率是 $1-2^{-O(n)}$，所以大的情况存在一个覆盖，小的情况一定覆盖不了，然后写成 $\Sigma_2$ 就行了

Ex6: 对于任何一个 AC0 circuit，我们可以用如下 Circuit 以 $1/poly(n)$ 的错误率近似它：前两层是 $\land,\lor$，度数不超过 $polylog$，最后一次一个大的 $\oplus$ 连接之前所有，总大小（显然可以不超过）$exp(polylog)$。

Proof. (0.7*) 我们需要知道之前在干啥。从下往上归纳，每一步可以写成一堆 AND 的 XOR。考虑一个 OR Gate，如果直接乘我们会得到 $n$ 倍大小，但注意到之前做 NP 的时候我们用 Set lowerbound 解决了 $2^n$ 个 OR 的问题，那么这里可以类似操作：随机一些确定大小的 $Ax+b$ 然后对满足条件的求和，这样得到 $O(\log n)$ 个随机子集，使得高概率有一个里面有奇数个 $1$。然后再 OR 起来就是 $log$ 倍了。（AND 类似 $+1$ 解决）。这样最后是一堆 $polylog$ 个东西的 AND，再 XOR 起来。

Ex7: 证明 $BQP \in P^{\# P}$。

Prf(1.3*): 我们可以直接证明 $BQP\in PP$。以下部分抄写自某次 qcs 作业。

首先可以把实部和虚部拆开得到只有实数的版本，然后可以取整得到只有有理数的版本。此时考虑 BQP 的暴力描述：记 $v_{i,S}$ 表示 $i$ 步后 $S$ 状态的系数，每步转移是一个简单的线性变换。但现在我们希望直接计数，因此考虑枚举一条转移路径 $S_1,S_2,\cdots,S_t$，其系数为每一步转移系数（不存在转移就是 $0$）乘起来，然后求和就给出某个位置的最终系数。但我们实际上需要平方求和，这可以由组合意义拆开为枚举两条路径，最终位置相同，然后乘起来。最后的问题是系数有负的但在 $[-1,1]$ 之间，那考虑枚举完后，计算系数 $s$ 并以 $(1+s)/2$ 概率接受，这样就精确算了 BQP 接受的概率。加入 $1/2$ 会使得之前的 Gap 只剩下指数小（每步转移系数经常不是 $1$），但这对于 PP 是可以区分的。

### XVIII Average Case Complexity

> 保证数据随机。

很多时候，一个问题是非常难的，但如果数据随机，那它是简单的，例如

1. 一般图三染色是 NP-c 的，但如果图完全随机（每条边 $1/2$ 出现），那我们可以判完 $K_4$ 暴力做(ex1)：注意到我们能在 $4n$ 个点的图里面找到 $n^2/2$ 组不交的 $K_4$（分四组然后画等差数列），由此可以得到图不包含 $K_4$ 的概率是 $exp(-O(n^2))$ 的，然后暴力是 $exp(n)$ 的，所以期望用时还是 poly。
2. 最大团是 NP-c 的，但如果图随机，考虑如下分析(ex2)：选 $k$ 个点有 $n^k=exp(k\log n)$ 种方式，构成团有 $exp(-k^2/2)$ 的概率，由此可以看出只要 $k>2\log n$，形成这么大的团的概率就可以忽略不计，那么从小到大搜即可得到 quasi-poly 的复杂度。

#### Distributional Problems

基于上面的讨论，我们来定义什么是“数据随机”下的问题：有一个问题 $L$，然后有一个输入上的分布 $D$。这样的一对 $(L,D)$ 被称为一个 Distributional Problem。如果 $D$ 取均匀随机，那就是常见的数据随机。

因为我们要考虑不同输入长度，$D$ 通常对于每个输入定义一个，因此实际上 $D$ 是一串分布 $D_1,D_2,\cdots$，其中 $D_i$ 是 $\{0,1\}^n$ 上的分布。

然后我们希望定义这样意义下的高效运算，即在这个分布下，它期望很快。那我们需要解决一个问题：如何定义期望很快。

##### Time Constraint

对于期望很快的部分，一个直接的想法就是“期望时间是 poly 的”。这看起来非常对，但有一个问题：我们希望我们的定义是模型无关的，在之前的所有例子中，换一个图灵机最多带来平方级的减速，这一般不成问题，但是期望意义下不是：平方的期望不等于期望的平方。更特别的，如果有 $2^{-n}$ 概率跑 $2^n$ 时间，那期望是 $1$，但平方一下时间期望就爆了。

我们希望的定义是，给时间做一个任意 poly 变换后还满足“期望很快”的性质，那有一个直接的定义：

distP: 存在 $c$，使得 $time^c$ 的期望是 $O(n)$ 的。

这里 $O(n)$ 可以是任意选的(ex6)：根据柯西不等式，时间开根自然导致期望至少开根。

Note. 对于 distP，我们不限制分布是啥，因此可能是它 average case 很好并且 $D$ 合适，也可能是它 worse case 就好然后 $D$ 是随便什么东西，因此 $P\in distP$。

##### Reduction for distP

现在考虑这上面的规约。根据之前的经验，规约是一个 poly-time 的函数 $f$，满足

1. $x\in L_1\leftrightarrow f(x)\in L_2$

注意到 $D_i$ 是定义在同一个长度上的，因此为了简便我们定义：

2. $|f(x)|$ 只和 $|x|$ 相关，且是一个 poly 的东西。

但这还有一些问题。我们的一个目标是，如果 $(L_2,D_2)\in distP$，且 $(L_1,D_1)$ 可以规约到它，那前者也可以通过规约属于 distP。但这样就有一个特例：

$L_2$ 在 $0^n$ 上很慢，别的都很快。但规约全部映射到 $0^n$。这样上面的分析就无效了。因此我们需要避免很多概率放到一起，更进一步

3. (Domination) 存在多项式 $q$，使得 $Pr_{D_1}[y=f(x)]\leq q(n)Pr_{D_2}[y=x]$。

在这个条件后，我们可以自然地证明之前的目标：每个位置概率最多放大了 poly 倍，所以“期望”还是对的。

同时这两个事情显然(ex7)还是传递性的（两个多项式乘起来）。那接下来我们就希望考虑 NP-completeness 在这里的扩展。

#### Distributions, distNP

现在考虑定义 NP 的版本。我们不希望看到 NDTM 的 expected worse-case time，因此这里定义为：一个 worse-case poly 的 NP algorithm，和一个分布。

##### Distribution Constraint

直接的问题是，我们不可能取一个任意的分布。不然的话，分布里面只包含一组特定数据就可以把这个定义卡回 $NP$，但这是不好的。

另一方面，如果直接只取均匀随机，则可能漏掉一些同样有趣的问题：一个常见的类型是，问能不能把满足某个性质的图和随机图区分出来。例如，输入有一半概率是随机图，有一半概率随机包含一个大小为 $k$ 的团，现在要就行区分。虽然有一些代数技巧，但这个问题在 $k<n^{1/2-c}$ 的时候还是 Open 的。

我们需要一些更强的分布，但还要避免最开始提到的那个问题。解决问题的方式是，注意到如果 $P\neq NP$，那多数情况下一个 P 的人没法把最坏数据找出来。因此考虑定义成一个 ~~P~~ BPP 的人能够生成的分布，即

P-sampleable：存在一个 p.p.t. 输出的东西是给定的分布。

这看起来已经非常正确了，但在后面做规约的时候，我们可能遇到一点小问题：考虑把 $D_1$ 规约到 $D_2$，此时为了避免 $D_1$ 里面经常出现的东西在 $D_2$ 里面很少出现，我们至少需要做一点处理。但如果是 P-sampleable，那我们不能直接知道哪个东西出现的多，这会带来不小的问题。因此我们有另一个定义：

P-computable: 存在一个 P 的算法，输出分布的 CDF：$\sum_{y\leq x}Pr[y]$。（我们只输出乘以 $2^k$ 后为整数的东西）

那么有如下几点事实：

1. 能算这个就能采样(ex4)：先随一个 CDF 范围内的东西，然后二分（逐位确定）
2. 反过来是不一定的：如果 $P\neq P^{\# P}$，则存在一个 P-sampleable 的东西不能被算 CDF。

Prf(0.6*)：考虑一个趣味构造：把输入分三段：中间当成一个 SAT，最后 $n$ 位当成变量取值然后求值 SAT，然后这东西出现当且仅当结果和第一位相同。最后一步保证了出现的东西总数是 $2^{n-1}$，且采样也非常简单：随机一个后面多少位，然后算 SAT 再决定第一位。但另一方面，考虑这个东西的前缀和，如果我们固定 $1+SAT$ 部分，那后面每个位置有概率当且仅当它是 SAT 的解，那算前缀和不弱于 $\# P$，如果能算那 $\# P=P$ 了。

为了更容易的证明，我们通常考虑 P-computable 的东西。由这两种不同的定义，我们得到：

1. sampNP：NP 加上 P-sampleable 的分布
2. distNP：NP 加上 P-computable 的分布

##### distNP-complete languages

考虑造一个问题，把所有 distNP 规约到它。那一个问题是我们需要把一堆不同的分布 $D$ 规约到同一个分布上，且最多差 poly 倍。如果分布是 uniform 的，那非常困难：我们可能需要算出一些值，把小的东西合并起来。这显然是常见规约不能干的事，我们还是需要每个输入映射到一个单独的 $x$。

由此，我们需要在目标分布里面搞出很多差距很大的概率，以适配 $2^{-n}\sim 1$ 的概率。那么有一个很好的方式：随一个长度 $n$，再随机 $n$ 位，然后补 $0$。这样我们就得到了 $1/n*(1/2,1/4,\cdots)$ 的各种概率，前面少掉的 $1/n$ 倍可以看成 poly 的误差。接下来我们就可以考虑把不同概率映射到 $1/2^i$ 上面去。

回到造 complete 问题上面，一个常见的问题还是 TMSAT：给 $M,x,1^t$，问 $M$ 在输入 $x$ 时，$t$ 步后是否停机。如果写成分布，那 $x$ 部分我们需要之前的技巧（长度可以补到 $1^t$ 上），但 $M$ 还会带来 $2^{-|M|}$ 的概率，因此我们需要再钦定这个是 $1/poly(n)$，即 $M$ 只占用了 $log$ 位输入。

总的来说，输入前 $log$ 位是 $M$，然后随一个 $t$ 之内的长度 $n$，前面作为输入后面作为 $1^t$。枚举 $n$ 数数可知这东西是 P-computable 的。(ex8)

然后考虑规约 $(L,D)$。首先考虑后半段怎么处理。对于一个概率为 $p$ 的输入，我们将其下取整到 $2^{-i}$，然后用某个前半段长度 $i$ 的东西代表它。我们需要这个东西能够快速算，同时 $M$ 还能通过代表的东西把输入反推出来。这是可以做的(ex9)：在 CDF 上看这件事，我们在 $[0,1]$ 上均匀撒 $2^i$ 个点，每个概率是 CDF 上一段大小不小于 $2^{-i}$ 的区间，那么可以找到它包含的第一个点作为对应，这样不会重复。这样计算只需要求出 CDF 区间（P-computable!）然后找，反推还是二分。

然后把反推的东西作为新的 $M'$，后面接一个 NDTM 作为 $M$ 放到前面。因为这东西描述是常数所以问题不大。

Thm. 上面这个问题是 distNP-complete 的。

##### sampNP-complete languages

Thm. (Impagliazzo, Levin) distNP-complete 的问题也是 sampNP-complete 的。

会去读的(todo)。



### XIX Derandomization 1: Hard-on-Average, Amplification, and Error Correcting Code

#### Average-case Hardness, Hard-on-Average

在上一章的部分中，我们考虑的都是 Average Case 下的 Las Vegas 算法：它保证正确，但时间复杂度不定。这里我们回到正确性的角度考虑。同时，这里只考虑 Decision，Circuit Model。

对于一个固定的正确率 $\rho$，定义 $\rho$-Avg Hardness 表示让正确率至少是 $\rho$ 所需要的最小 Circuit Size。记作 $H_{avg}^\rho$。

取 $\rho=1$ 就得到 Worse-Case 的 Circuit Complexity。然后我们再考虑最简单的情况：注意到 $\rho=1/2$ 及以下是显然的：输出 $0/1$ 总有一个对。因此最极端的情况通常考虑 $1/2+\epsilon$。因此，这里定义：

一个（固定位数）的函数的 Avg Hardness 为最大的正整数 $c$，使得 $c$ 大小的 Circuit 都不能算到 $1/2+1/c$ 以上的正确率。这可以看作是一个简化记号。

常用记号：我们说一个东西是 Mildly Hard-on-Average 的，如果存在一个 $H^{1-\delta}$ 很大。如果进一步 $H^{1/2+\epsilon}$ 很大，它就是 Strongly Hard-on-Average 的。

和之前一样，这些记号的起因之一是对 Worse-Case Hardness 及随机情况的考虑：如果一个问题只是 Worse-Case Hard，那可能一个算法随机情况下根本碰不到错的情况。那么如果一个问题进一步是 Hard-on-Average 的，那它就更好。

因此一个直接的目标是：给一个 Worse-Case Hard 的问题，我们能不能得到一个 Average-Case Hard 的问题？

#### Error-Correcting Codes

上一个目标是什么意思？有两个问题，如果我们能解决第一个的一大部分（Average-Case），我们就能完全解决第二个（Worse-Case）。如果把问题看成真值表，那就相当于这样一件事：

记 $\Delta(x,y)$ 表示两个长度相同的串，其中不同的位置的占比。一个 $f:\{0,1\}^n\mapsto \{0,1\}^m$ 是 $\delta$-ECC，如果

1. 对于任意两个不同输入对应的输出，$\Delta\geq \delta$，或者等价的
2. 在一个输出上修改不超过 $\delta/2$ 比例的位置时，我们都能还原输入。

##### Existence

首先考虑它的存在性。 

Thm(Bilbert-Varshamov). 记 $H(\delta)=-\delta\log\delta-(1-\delta)\log(1-\delta)$。对于 $\delta<1/2$，存在 $m=n/(1-H(\delta))$ 的 ECC。

Proof(ex9). 考虑顺序构造每一个 $f(i)$。每次构造的时候，它不能和之前的放的太近。但可以注意到，$\binom m{\delta m}$ 差不多就是 $2^{mH(\delta)}$（会小一点），而前者差不多是距离一个串不超过 $\delta m$ 的串数量。那么每个之前的结果会 ban 掉差不多 $2^{m(H(\delta)-1)}=2^{-n}$ 比例的位置，从而此时无论怎么不交都存在一个放下去的位置。 

其实还有一个非常直接而且快的构造： $f(x)=Ax$。简单做差可知 Distance 就是 $f(non-zero)$ 里面 $1$ 的最少数量，然后就只需要 bound 一次个。

那另一方面，如果 $\delta$ 更大呢？

ex10b: 如果 $\delta>1/2$，则可行的输入数量 $2^n=O(1)$。

Proof: 直接数数。记 $N=2^n$，每一位最多贡献 $N^2/2$ 个不同的对，但也贡献了 $N(N-1)/2$ 个相同的对。那这个比例就很难超过 $1/2$（当 $N$ 足够大的时候）

ex10a: 如果 $\delta=1/2$，则我们需要指数大小的 Encoding，即 $m=\Omega(2^n)$。 

Proof(0.6*): 仔细数数，每一位最多贡献 $N^2/2$ 个不同的对，但也贡献了 $N(N-1)/2$ 个相同的对……但这比 $1/2$ 还少 $N$ 对，还有空余。

但注意到这个对一个子集还是成立的！考虑第一位操作后全部选 $0$ 的那一边，不妨假设这边至少有 $N/2$ 个元素。那么它们已经比 $1/2$ 加起来多了 $O(N^2)$ 的量，接下来就需要 $O(N)$ 步调整回来。

其实有更简洁的数数方法，且听下回分解。

接下来我们可以看到达到这个界的构造。这样来看，在 $\delta<1/2$ 的时候，我们都有一个线性长度的 ECC。随着 $\delta\to 1/2$，这个界逐渐增大。在 $1/2-o(1)$ 时超过了线性，最后变为指数级。

##### Construction

但拿个指数级构造（比如上面那个证明）出来显然是不好的，因此我们再看一些具体的例子。

###### Walsh-Hadamard

$\delta=1/2$

$m=2^n$，构造非常简单：$f(x)$ 的第 $y$ 位表示把两者看做二进制数，然后做内积。

正确性显然。

###### Reed-Solomon

上面都是在 $\{0,1\}$ 上定义的 ECC。我们也可以换到在任意字符集 $\Sigma$ 上去定义 ECC。此时比较的是不同字符的个数。

因此我们考虑如下构造：$F^n\mapsto F^m$，其中 $m\leq |F|$。将输入看做 $n-1$ 次多项式的系数，然后直接求值。

根据代数学基本定理，最多有 $n-1$ 个重复，所以可以做到 $\delta=1-n/m$。

为什么这里又可以 $\delta>1/2$ 了呢？实际上 $\{0,1\}$ 和 $\Sigma$ 的转换会带来一些改变(ex12)。显然的转换是直接 pack 起来，可以发现前者到后者不会降低 $\delta$（但也不能增高，有最坏情况），而后者到前者会使得 $\delta$ 降低 $\log\Sigma$ 倍：一个大字符的不同换到二进制表示上可能只有一位不同。

###### Reed-Muller

把上面的构造换成多元多项式。记最大次数为 $d$，变量数为 $l$。

根据 Schwartz-Zippel，$\delta=1-n/|F|$。

为什么要考虑这个？后面会发现，这样解码更快。

##### Composition of Codes

> 密码学期中考试：给两个 Private Key Enctyption，保证有一个是安全的，构造一个确定安全的版本。

复合两个 Encoding 的方法很直接：先做第一个，然后把输出分段，每段分别喂给第二个。 

简单结论：两个 ECC 这样复合，$\delta$ 相乘。

证明：如果第二个只从一位输入那显然。一般情况注意到 packing 不损失 $\delta$。

那这东西有什么优势呢？注意到，我们不要求复合前后字符集相同。

##### WH o RS

一个常见技巧是，之前我们直接把 $\Sigma$ 拉到 $\{0,1\}$ 会使 $\delta$ 变成 $1/\log \Sigma$ 倍。那如果 $\Sigma$ 甚至不是常数，这就不可接受了。

现在考虑这样：先 RS 完，然后对每个字符做一个 WH。这样可以只用一个 $1/2$ 的代价。

当然 $F$ 还是影响整个过程：根据 WH 的情况，现在它影响编码的长度。所以说还是不能乱来。

##### Decoding

但只有构造都是不够的。回想我们最开始的目标：如果我们能近似的算（真值表）一个 ECC，那对着它 Decode 就可以算之前的值。那我们至少要会 Decode。

###### Decode Reed-Solomon

根据一般结论，现在距离是 $m-n$，所以错 $m/2-n/2$ 个以下都是可以接受的。换言之，

Thm. 在存在的情况下，我们可以唯一确定一个 $n$ 次多项式，使其在给定 $m$ 个点值上至少有 $m/2+n/2+1$ 个正确。

如果没有错的点值，那只需要解一个 $P(x)=y$ 构成的方程组就行。但一般情况下，找到满足最多方程的解还是 NP-c 的。

如何绕过错误的点值？考虑将方程变为，解 $F(x)=yG(x)$，其中 $G$ 的次数为错误点值的数量（$m/2-n/2-1$）,$f$ 的次数为这个值加上 $n$。

直观上看，取 $G=\prod_{wrong}(x-x_i),F=PG$，那这就是一组解。但我们还需要考虑，如果我们找到任意一组解，那它是不是好的。

把 $y$ 换成正确的答案 $P(x)$，那么 $F=PG$ 两边次数都是 $m/2+n/2$，同时在 $m/2+n/2+1$ 个位置正确，从而它们是同一个多项式。因此一定有 $F=PG$。
  
##### Efficient/Local Decoder

但能 poly 的解码还不够。回顾我们的做法：把函数写成真值表，对真值表跑 ECC。那 ECC 的长度是指数级的。因此，我们只希望读 polylog 位来进行还原，但同时我们也只要其中一位的值（因为是唯一还原，所以这是良定义的）。

一个问题是，我们只读 polylog 个位置，而一个 ECC 可以错线性个位置。所以一个确定性算法显然不可能对。因此，我们考虑的是 **随机** 的 Decoder：它输入一个下标，然后有 polylog 的时间输出这一位，要求正确率至少 $2/3$。 

###### Walsh-Hadamard

注意到我们只需要恢复 $1/4$ 以内的错误。然后根据 GoldReich-Levin 的第一步，我们随机一些 $x$，问 $f(x)\oplus f(x+e_i)$ 就行。

###### Reed-Muller

可以发现 RS 肯定不大能 polylog，但多元情况下一个 $O(d)$ 的代价就没那么大。

看看这个问题：给一个多元多项式的点值，修改一部分，然后还原某一项的系数……好像二元都特别难。

因此，我们可以改一下它的编码方式：输入改成某些数量的点值，使得可以通过点值唯一还原低次多项式。然后输出不变。

变成求值的好处是，我们可以随便限制到某个变量，而不用管其它系数的问题。

那么问题变成，有一大堆点值，其中有一部分不对，然后需要恢复一个点值出来。

直观的看，如果错误点值随机出现，那我们直接只看第一个变量做一元问题，这条线上只要错的不多就行。一般情况下，我们就随机选一条线。

###### Composition, Decode WH o RM

复合解码的做法很直接：跑第一个解码，每个询问再单独跑第二个解码。

现在我们来考虑整个过程的参数。RM 需要 $N=2^n$ 级别的输入，但我们还希望解码时间是 $polylog(N)$ 的。注意到输入长度是 $\binom{l+d}l\log F$，那么让域大小 F=polylog，次数 d=log^2, 元数 l=log/loglog。此时输入就是 poly 长度的，输出长度是 $F^l\log F$，这也是 poly(N)$ 的。

然后再对每个字符用一个 WH，这使得输出长度乘上 F 倍。 

#### Hardness Amplification: Yao's XOR Lemma

直到上一步为止，我们的 ECC 都是能支持一个不超过 $\delta/2$ 的错误率的还原，所以新的函数上算到大于 $1-\delta/2$ 的正确率是困难的。

但结合 $\delta$ 的限制，这样就很难做到 Strongly HoA。因此这里需要单独来一步：给一个 Mildly HoA($1-\delta$)，我们希望做到 Strongly HoA($1/2+\epsilon$)。

显然，把很多个相同的函数拼起来，那它应该会变得非常 Hard（$(1-\delta)^k$）（参见：OWF Amplification）。但这里问题是，我们还是只能输出一个 bit，这就不好。

此时 Yao's XOR Lemma 说，把每个输出 bit 异或起来，它还是很难。

那显然（？），这东西的证明是不显然的。我们需要解决两步，首先从 $(1-\delta)$-HoA 到真的存在一个困难的部分，然后从这个到 XOR Lemma。

##### Impagliazzo’s Hardcore Lemma

Thm. 如果一个函数对于大小 $S$ 的 Circuit 是 $1-\delta$-HoA 的，那么我们能找到一个分布，其中每个位置的权值不超过 $2^{-n}$ 的 $\delta^{-1}$ 倍，使得这个分布上，对于大小小于 $S\epsilon^2/100n$ 的 Circuit 它是 $1/2+\epsilon/2$-HoA 的。

简单理解：如果它是 $1-\delta$-HoA 的，那我们可以提取一个 $\delta$ 部分，使得它是 Strong-HoA 的。

实际上也可以从这个分布提取 $O(\delta)$ 的几乎困难部分(ex2)：注意到每个正确率不会小于 $1/2$，那么根据简单数数，大于 $1/2+2\epsilon$ 的占比不超过一半，那么小的那些对应了很多个输入。

但这为什么可以？如果对于每个分布错的都很平均会发生啥？答案是：如果每个错的都很平均，那我们随机选小 Circuit 出来取众数，根据 Chernoff 这样正确率很高，从而我们可以做到非常好的正确率。

###### Proof

现在我们给一个更严谨的证明。考虑这样一个问题：

第一个人选一个满足条件的分布，第二个人选一个 Circuit，然后得分为 Circuit 在分布上的正确率。

显然，第二个人换成选 Circuit Distribution 不影响结果。

然后可以注意到这是一个零和博弈，根据博弈论经典结论，两个人任意顺序行动不影响最优结果，游戏有一个完美的纳什均衡。

注意到满足条件的分布做一个非负线性组合还满足条件，所以第一个人随机策略也没有影响。

事实上这个分布的 polytope 的所有顶点就是所有选 $\delta 2^n$ 个元素的子集(ex7)：换言之，给一个这样的分布，它可以被拆成若干个这样子集的非负线性组合。构造就随便贪心一下，每次把当前系数最大的全部拿出来搞搞。

证明可以抄一手 LP Dual，或者用 Separating Hyperplane。(ex5-6)

书上抄的 Separating Hyperplane 证明：考虑 $\min_{x\in A,y\in B} |x-y|$，考虑取到这里的点。我们声称，这个向量的切平面就是我们想要的东西。为什么呢？如果切过去不行，那对面的点连到 $x$ 来，可以在这条线上找到一个距离 $y$ 更近的位置。

注意到按照上述顺序，第一个人可以让分数不超过 $1/2+eps$ 就说明能找到分布。反过来，则第二个人可以找到一个 Circuit 的分布，使得在这个分布下，每个输入分布的正确率都至少是 $1/2+\epsilon$。

现在考虑有哪些位置的正确率至少是这么多。如果有 $\delta$ 部分的不是，那那些构成一个分布，矛盾。因此对于至少 $1-\delta$ 的输入，这个分布的正确率至少是 $1/2+\epsilon$。

然后随机，Chernoff。可以搞到指数正确率，然后 Union Bound，从而存在一个全对的解，它就是取了一个众数。

##### Prove of Yao's XOR Lemma

把随机输入的分布分成两份，一部分 $\delta$ 的是之前说困难的，另外的是剩下的。

把输入的 $U^k$ 分成 $(F+G)^k$，其中 $F$ 表示困难的那部分。那如果我们的正确率大于了 $1/2+O((1-\delta)^k)$ 级别，我们就在某一个形如 $...F...$ 的部分上得到了很好的结果。然后我们想说明我们能解决 $F$。

直接的想法是拿到一个输入，随机别的东西，然后放进去算出异或，再反推。但我们一不能采样奇怪分布，而且我们算不出别的答案。

但这里是 Circuit，所以是 /poly。那我们可以固定一个其它位置放的值，显然存在一个达到 $1/2+\epsilon$，然后就对了。

#### Worse-case -> Mildly HoA -> Strongly HoA

如题。

但还有个问题：如果我们想要 $2^{O(n)}$ 级别的 Hardness，那我们需要 XOR $O(n)$ 个东西来压正确性。，这样输入变成了 $n^2$ 位，从而新的问题上我们的 Hardness 只有 $2^{O(\sqrt n)}$。


为了做到更好，我们需要考虑不用 XOR Lemma。

#### List Decoding

如果我们想一步到位，直接解码 $1/2-\eps$ 误差的东西，那显然这不可能解码出唯一的东西。

那解码后的东西会很多吗？如果误差 $1/2$，那这覆盖了一半的东西，所以显然不行。但如果再小一点，那 Goldreich-Levin 啥的似乎说明这东西应该不多。

这怎么用？我们跑完 ECC 之后，把正确的编号编码到 Circuit 里面去，就还原了输入。

事实上我们可以证明这确实不多（Johnson Bound）：考虑继续数数。有一种非常简便的方式：将 $0,1$ 换成 $-1,1$，那么两个数的内积就是 $(1-2\Delta)m$。

那么此时有 $k$ 个向量，每个本来模长平方是 $m$，然后考虑 $\langle \sum w,\sum w\rangle$，这等于 $k$ 个模长加上所有交叉项，因为 ECC 是 $1/2-\epsilon$，那么这部分不超过 $\epsilon k^2m$。

因此这个不超过 $km+\epsilon k^2m$。但另一方面，我们如果只考虑距离一个点不超过 $1/2-\delta$ 的，那它们的和模长本来应该很大。具体来说，它们的 L1 norm 至少是 $2\delta m*k$，那么 L2 至少是 $4k^2\delta^2m$。那么我们得到

$$
4k^2\delta^2m\leq km+\epsilon k^2m
$$
 
那这看起来就给出了一个 $k$ 的上界！只要 $\delta^2\geq \epsilon$，那么 $k\leq O(\delta^{-2})$。

所以看起来这样搞是可行的。但是这个 bound 还是太弱，比如不能直接做 $0.75$ 到 $0.51$。接下来我们会给出一些更具体的分析。 

##### Reed-Solomon

考虑一下，如果合法点值更少，那可能的解有多少。和之前一样，假设每个合法解对应 $C$ 个正确点值（$C=(1-\delta)m$），那么两个不同合法解的交小于 $d$，否则可以插值使其相同。之前的分析是，只要 $2C-d>m$，就不会有两个合法解。

那一般情况呢？(ex15)考虑最坏情况，第一个解占了 $C$ 个，第二个解再占 $C-d$ 个，第三个解 $C-2d$ 个，这样最后得到 $C^2/2d$。也就是说，只要 $C\geq c\sqrt{dm}$，那这样解的数量都不超过 $\sqrt{m/d}$ 级别。

但这样分析不会给一个构造的方法。用之前的方式也不行：我们不能保证解方程把每种解都找到。

[Sudan 96]：考虑解二元多项式 $Q$，满足 $Q(x_i,y_i)=0$，且 $x$ 的次数不超过 $\sqrt {dm}$，$y$ 的次数不超过 $\sqrt{m/d}$。

根据上面的想法，如果所有解覆盖所有点值，那么 $\prod(f(x)-y)$ 就是好的答案。但一般情况呢？(ex16)考虑一个 $f(x)-y$，如果在 $Q$ 里面考虑 $Q(x,f(x))$，那容易发现 $Q$ 的零点数就是这组解满足的点值数。而另一方面，它的次数是 $d(\sqrt{m/d})+\sqrt {dm}$。因此只要有 $2\sqrt{dm}$ 个点值，那么 $Q(x,f(x))=0$，从而 $f(x)-y|Q$。

因此只需要随便解一个 $Q$，然后二元多项式分解。

#### Local List Decoding

和之前一样，我们也希望跑一个 Local Decode。但现在我们就需要重新规定正确性：有很多合法的输出，但我们一次输出一个 bit，随便搞可能输出不匹配。

因此定义 Local List Decoder：输入下标 $i$ 和编号 $c$，输出第 $c$ 个可能的串的第 $i$ 位。这里我们不要求按照顺序/不重复/不多输出，只要求：有一个编号范围，然后有一个编号输出正确。

##### Walsh-Hadamard

这回就是完整的 Goldreich-Levin：编号就是我们枚举的线性基里面的值。

##### Reed-Muller

考虑套之前的做法。但问题就在于，我们很难把不同位置的输出正确地串起来。一个直观的想法是，如果我们能给每个解一个标记，使得相同的多项式有相同的标记，同时接出来的东西标记不同，我们就能正确地串起来。

对于多项式，最自然地标记是点值：那么我们可以标记 $(x,y)$ 表示 $f(x)=y$。

那撞车了怎么办？此时我们好像没法搞到正确的东西。但因为次数不大，所以撞车的情况相对不多，也就是说我们能对大部分位置求出答案。那可以外面再套一层。

还有个问题是我们每次选一条线，然后求出线上的点值。但如果 $x$ 不在线上，那标记就失效了。为了保证随机性，我们可以把二次改成三次曲线：经过两个点，和第三个自由度。

##### Composition

和之前一样。

#### All together: Worse Case to Strongly HoA without losing expnonent

和之前差不多。懒得算了。

最后结果是，如果 $H_{wrs}\geq S(n)$，那我们能找到另一个函数，使得 $H_{avg}\geq S(n/c)^{1/c}$。 



### XX Derandomization 2: Pseudorandom Generators in Complexity, NW Generators

#### PRG for Derandomization

Derandomization: 有一个随机算法，我们想问能不能把随机去掉。例如，BPP 是否直接等于 P？

（密码学中的）PRG：我们可以生成一个串，它看起来和真的随机串一样：任何多项式算法都没法分辨它。

那一个自然的想法：我们把 PRG 的输出喂给随机算法。但事情远没有结束：PRG 只是减少了随机的量级。在密码学里面，我们一般是输入 $n$ 个随机 bit，然后输出 $poly(n)$ 个。那这样的话，搞完我们还是需要 $n^c$ 个随机 bit。这不是确定性的。

因此，在复杂度里面，我们希望用更极端的方式解决问题：如果我们输出 $n$ 个 随机 bit，然后输出 $exp(n)$ 个，那这样搞完就只需要 $poly\log n$ 个随机 bit。然后就可以暴力：枚举所有情况计算概率，如果任何算法都不能区分两种输出，那应该概率变化不大（否则就区分）了，然后就可以判断和 $1/2$ 的大小解决问题。这是最关键的区别：我们的输出可以比 poly(n) 大非常多，然后运行时间也可以更宽松：外面枚举已经 $2^n$ 了，那么再来个 $exp(n)$ 是不影响事情的。

后者也是非常有趣的一点：Generator 比 Distinguisher 跑的时间可以多很多，所以 Generator 可以暴力做一些事情。

因此，我们定义：

> 给一个阳间的函数 $S$，一个 $G$ 是 $S(l)$-PRG，如果：
>
> 1. 它输入 $n$ 位时，输出 $S(n)$ 位。且运行时间不超过 $exp(n)$。
> 2. 任何一个 $S(n)^3$ 大小的 Circuit 区分它和随机输出的差距不超过 $0.1129141$。

这里可以设成常数是因为我们只用一次，而不是拿去封装好到处反复用。

然后直接套上面的讨论，得到：

如果存在一个 $S(n)$-PRG，那么 $BPTIME(S(n))\in DTIME(2^{O(n)})$。还可以把 $n$ 换成任何一个函数。

证明：直接套上面的东西。如果结果不对，那么这个算法在输出真随机和我们给的随机的时候表现差距至少是 $1/3$（在某一个 $x$ 上）。然后固定这个 $x$（你是一个 Circuit），我们就得到了一个 Distinguisher。

然后有一些简单的推论：

1. 如果存在 $2^{O(n)}$-PRG，那么 $P=BPP$。
2. 如果存在 $2^{n^c}$-PRG，那么 $BPP\in TIME(2^{poly\log n})=QuasiP$。
3. 如果 $\forall c$，存在 $n^c$-PRG，那么 $BPP\in\cap TIME(2^{n^\eps})=SUBEXP$。

首先，肯定存在一个这样的函数使得它是 $2^{cn}$，同时 Hard to distinguish 的(ex2)：直接随每个输出，根据 Hoeffding 这是对的。但我们没法快速构造，同时加一个 $/poly$ 就没意思了。

#### PRG from Average-Case Hardness: The Nisan-Wigderson Generator

如何从一个困难的函数得到一个 PRG？密码学中的经验说，如果有一个 OWF，我们可以造一个 Hardcore Bit：给定 $x$，很难算出这个 Hardcore Bit，然后把它和 $x$ 拼起来就可以。

这里可以发现一个困难函数的输出就是一个 Hardcore Bit，那我们自然可以这样干，然后套之前的传统分析（转到 unpredictability）说明它不可被区分。

显然还可以拆很多段，每段贡献一个 Bit，但这样也不能做到很多个输出的 bit。为了输出很多个 bit，它们之间显然不会是独立的。但可以说明，这样是没问题的：

NW Generator: 给定 $d<n<l$，记输入长度为 $l$。我们找一堆大小为 $n$ 的下标子集，满足每两个子集的交不超过 $d$。然后每个子集输出一位，表示把这个下标上的输入喂进去的结果。不妨设我们有 $2^{d/10}$ 个这样的子集。

这为什么能对？考虑如果有一个 Distinguisher，那它至少能够 Predict 后面的某一位。此时它可以根据之前的一堆子集的输出得到下一个子集的输出。

那子集外的东西和这里无关。我们可以固定一个子集外的取值，使得此时的成功率不低。然后就只看子集内的情况。

那些之前的输出怎么办？两个子集的交不超过 $d$，所以一个 bit 可以被 $2^d$ 级别的 Circuit 求出。那我们造一个东西，先对每个子集只通过交集计算输出，然后用上面的 Distinguisher 算出新的子集的答案。这样的大小不超过 $2^{2d}$，所以：

只要 $f$ 的 Avg Hardness 至少是 $2^{2d}$，那上面构造的就是一个 PRG。

在很久之前，我们说过根据基础数数，存在很多 Worse-Case 难度 $2^n/n$ 级别的 $f$。

这也可以类似地对 Avg Case 做。考虑 $H_{avg}\leq 2^{n/10}$ 的函数(ex3)，每个这么大的 Circuit 可以接受 $(1/2-2^{-n/10})2^n$ 个错误，算一下这个组合数至少是 $2^n$ 的 $2^{-0.8n}$ 倍（$(1-2^{-n/10})^{2^{9n/10}}）$），所以没有那么多小 Circuit 覆盖所有函数。

##### Combinatorial Designs

现在我们考虑这堆子集的构造。

如果随机呢？$l$ 个数里面随机两个 $n$-subset，那期望的交集是 $n^2/l$。那确实有这样的结论：

Thm. 只要 $l\geq 10n^2/d$，即 $d\geq 10n^2/l$，那么存在这样的构造，且可以 $2^{O(l)}$ 计算。

首先就考虑随机，那么有 Chernoff 保证每两个的交超过上界的概率都是 $2^{-O(d)}$ 级别的。那期望就是正确的。

但我们不能随机，所以考虑一个一个选，每一步暴力找一个满足条件的，因为期望存在所以一定能找到。

然后我们回来搞 NW Generator 的参数。记输出数量为 $S(n)$。显然需要 $d=O(\log S)$，那么 $l=O(n^2/\log S)$。这样的话，输入 $n^2/\log S$ 个 bit，输出 $S^c$ 个 bit。根据之前的分析，只要 $f\in E=DTIME(2^{O(n)})$，且它的 Avg Hardness 至少是 $S^c$ 就行。

但这个 $n^2/\log S$ 也不太影响事情：

1. 如果 $S=2^{cn}$，那 $n^2/\log S=O(n)$，所以直接得到 $P=BPP$。
2. 如果 $S=2^{n^c}$，那换元 $n^{1/(2-c)}$ 只是影响一下指数，还是 QuasiP。
3. 如果 $S=n^{\omega(1)}$（对应第三种情况），那和上一个类似。

#### Putting Altogether: Ch19 + Ch20

根据上一章的结论，如果有一个 Worse-Case Hard $S(n)$ 的东西，那我们可以得到一个 Avg-Case Hard $S(cn)^c$ 的东西。

可以发现这个形式不会对上面的三种东西带来影响。（但如果是上一章前半段的做法，得到 $S(\sqrt n)$，那这里第一个就不行了）。

还有个问题，后面那个东西复杂度是多少？容易发现两个 Encode 可以是 Poly 的。那如果一个问题属于 $E$，那它的真值表也是单指数级，所以后者也是属于 $E$ 的。

因此，如果存在 $f\in E$ 需要 $S(n)$ 级别的 Worse-Case Complexity，那就存在 $S(cn)^{1/c}$ 级别的 Avg-Case Hardness。

实际上 NW Generator 也可以加强，把 $n^2/\log S$ 处理掉。但这里略过。

有趣的是，反方向也成立：

ex4: 如果存在 $S$-PRG，那么存在 $s\in E$ 需要 $S(n)$ 级别的 Worse-Case Complexity。

Proof: 考虑一个问题叫做：给一个输出，判断它是否是 PRG 可能的输出。这显然属于 $E$（暴力做），但能做它就能 Distinguish，所以不可能完全准确的判断它（甚至正确率 $0.9$ 以上）。

那么我们最终得到：

1. 如果 $f\in E$ 需要 $2^{cn}$ 的 Circuit Complexity，那么 $P=BPP$。（[IW97]!）
2. 剩下的和上一个形式类似。

ex6: 如果 $f\in E$ 需要 $2^{cn}$ 的 Circuit Complexity，那么 $NP=MA$。

注意到 MA 就是 NP 之后跑一个随机算法。如果 NW Generator 存在，那么那个随机算法换成确定性算法也不会在任何情况下出错，这样就变成 NP 了。

#### Derandomization in Complexity

首先可以注意到 NW Generator 显然是 relativize 的，那我们可以定义 $^O$ 下的 Circuit Complexity：放一个 Oracle Gate。然后整个事情不变，结果是这样生成的东西给 $Circuit^O$ 也没法 Distinguish。

然后是一些接近 Win-Win 的东西：

ex7a：如果 $E\in (P/poly)^{NP}$，那么 $PH$ 倒塌。

Proof(0.8*)：注意到之前的 Meyer's Theorem 也是 relativize 的：简单回顾证明，如果 $E\in P/poly$，那输出某一步时的运行状态也 $\in E$，所以可以被一个 Circuit 计算，然后就可以 $\exists$ Circuit，$\forall$ 可能的计算步骤，使得输出通过验证。但整个过程加上 Oracle 显然还是对的。

因此这种情况下，$E\in \Sigma_2^{SAT}\in \Sigma_3$。那 $PH$ 显然……等等这不对。但显然 Padding 一下就知道 $E$ 如果有多项式的 Circuit，那 $EXP$ 也有，所以 $PH\in EXP\in \Sigma_3$。

ex7b：另一方面，如果在 $^{NP}$ 下，有一个 $f\in E$ 的 Avg Complexity 是 $2^{cn}$，那么 $AM=NP$。

Proof：根据 NW Generator，我们可以构造一个 $2^n$ 时间，带有 SAT Oracle 的 $2^{c'n}$-PRG。它的输出对应小的 $2^{cn}$ Circuit With SAT Oracle 是不能从随机里面区分出来的。

但尽然我们已经 $2^n$ 了，那把 SAT Oracle 暴力算出来还是 $E$ 的，从而可以接受。这里的关键是 distinguisher 时限比较紧，不能干这件事。

但显然 AM 就是随机一下，然后跑一个 SAT Oracle。那么把随机替换成这个 PRG 也行。从而我们只需要验证 $poly(n)$ 个 SAT 里面是否有一半以上被满足，然后数数。数 poly 个东西显然可以写成 SAT。

##### Theorem 20.16

Thm. 如果 $BPP\neq EXP$，那么 $\forall L\in BPP$，我们总能找到一个 $\exp(n^{o(1)})$ 的确定性算法，其和 $L$ 的正确率至少是 $1-1/n$。

idea：如果你有 NW Generator 那就搞定了。另一方面，我们有 ex4，所以可以想象，如果 NW Generator 不存在，那我们可以反过来用 Distinguisher 去把问题解决，然后说不定就 BPP=EXP 了。

那么首先，如果 $EXP\not\in P/poly$，那么我们用 NW Generator，直接 Derandomize。否则，$EXP\in P/poly$，那么 $EXP=\Sum_2$。

现在考虑还是拿一个 $f$，造一个 NW Generator。考虑取 f=PERM。那么应该有一个 Distinguisher 上，换掉随机会使得一小部分输出不对。 

但怎么找到这个 Distinguisher？这里的问题是，我们希望 Uniform 地搞这一套东西，这样等会才能真的解决问题。(ex9)好消息是，我们只是要 Derandomize BPP，而不是啥 BPP/poly。那我们至少知道，如果 Derandomize 失败，那么存在一个常数表述的 Randomized TM，也就是说我们能够直接生成这个 Circuit。

然后需要把它变成真的 Distinguisher。和上一步一样的原因，我们不能直接 Average Argument。所以这就是为什么这里是 $1-1/n$-Correct，不是 $1$：如果是 $1-1/n$，那我们多随几个总能随到一个不对的。然后还需要判断它对不对，那就先把 BPP 多跑几遍得到一个 $0.99999$ 正确概率的东西，然后再把输入拿进来分辨，就很容易解决 $2/3$ 对 $1/2$ 的问题。

现在我们有一个 uniform 的 Distinguisher。然后根据经典的 unpredictability，这里就变成，我们可以 Uniform 地构造一个 Circuit，它需要算一些小的 $f$，然后可以解决大的 $f$ 的某一位。这里注意到：

1. 本来我们是说存在一个，但显然随机一个也大概率正确。
2. 因为 $S=n^{\omega(1)}$，所以 $d$ 实际上很小，那每个小的 $f$ 我们只需要算固定的 perm 搞出系数，然后就能得到 Circuit。
3. 从某一位到所有的步骤差不多就是抄一遍 Goldreich-Levin。

然后就可以得到：我们有一个算法，它算几个 perm 就可以得到一个算 perm 的 Circuit。

然后就可以这样：先算 $n=1$，然后拿 $n=1$ 的 Circuit 去构造 $n=2$ 的 Circuit，以此类推。每一步成功率足够即可。

这样的话 $Perm\in BPP$，但同时 Perm 是 #P-C，所以它是 PH-C 或者 EXP-C，这样就会有 $BPP=EXP$。因此我们完成了证明。

##### Theorem 20.17

Thm. 以下三件事不可能同时发生：

1. Polynomial Identity Testing 可以被 Derandomize 到 $P$。
2. $NEXP\in P/poly$
3. $perm\in AlgP/poly$

这说明了啥？如果 $P=BPP$，那么至少有一些 Circuit Lowerbound。~~这和现在啥都没有不冲突~~

首先是一些简单的结果：

###### Lemma 20.18

如果 $EXP\in P/poly$，那么 $EXP=MA$。

实际上 PSPACE 开始就行：注意到这种情况下 $EXP\in \Sigma_2$，那么 $EXP=PSPACE=IP$。根据经典结论，对于 IP 来说，Prover 的策略只需要是一个 PSPACE。那么又因为 PSPACE\in P/poly$，所以 Merlin 可以把自己的策略对应的 Circuit 发过去，然后 Arthur 自己模拟这个过程。

###### Lemma 20.19

如果 Polynomial Identity Testing 属于 $P$，且 $perm\in AlgP/poly$，那么 $P^{perm}\in NP$。


和之前一样，考虑对每个 $i$ 找 Circuit，同时用 Down Reduction。这里 NP 地找 Circuit，然后判断 $i$ 和 $i-1$ 是否一致。判断就拆一项求和然后用 Polynomial Identity Testing。

然后是一个比较困难的结果：

###### Lemma 20.20

如果 $NEXP\in P/poly$，那么 $NEXP=EXP=MA$。

用 $NEXP=MIP$？但 $MIP$ 的 Prover 没那么好构造。

Proof. 首先，如果 $NEXP\not\in EXP$，那考虑其中的一个语言 $L$。我们能找到很多 $x$，使得任何 EXP 算法没法正确的计算它们。

那考虑这样一个 EXP 算法：用小（poly(n)）的 Circuit 生成一堆 Certificate（具体来说，对一个 Circuit，枚举 $2^l$ 种输出，拼接输出），然后暴力试一下。注意到如果它不行，那么 $L(x)$ 上所有可行的 Certificate 都很难被生成，换言之它们有很大的 Circuit Complexity！也就是说我们现在得到：

> 我们能找到无限多个 $x$，使得 $M(x,y)=1$ 的所有 $y$ 看作真值表，都具有 $n^{\omega(1)}$ 的 Circuit Complexity。

这一步被称为 Easy Witness。



然后就可以 NW Generator。只要我们找到一个 $y$，然后就可以得到 SUBEXP 的 Derandomization。

然后看一下用之前方法可以推出来的 $EXP=MA$，此时我们再对 MA 跑 Derandomization。复杂度是 $subexp$ 乘上 NW Generator。我们不能找到 $y$，但换成 NTIME 就可以了。

但 $y$ 是指数长度的，所以我们看起来把 $EXP$ 放到了 $NEXP$，甚至还不如不 Derand……？有一个不易察觉的区别：NW Generator 的运行时间和 EXP 的问题无关。不妨设 EXP 得到的 MA 要跑 $n^k$ 时间，那直接搞是 $DTIME(2^{n^k})$，但如果用 NW Generator，那是 $SUBEXP(n^k)*2^{n^c}$，其中 $2^{n^c}$ 是 $y$ 的长度，但那是一个固定的语言。

因此我们得到的不是 $EXP\in NEXP$，而是一个固定的 $EXP\in NTIME(2^{n^c})$（实际上右边还需要 $/n$，因为需要 advice 把 $x$ 放进去。）……这看起来好像也没啥大问题，毕竟如果 $NP=EXP$……？

注意到我们还有一句话：$NEXP\in P/poly$，所以 $EXP\in TIME(n^c)/poly$。数数就不对，矛盾。（也可以直接类似说明此时不可能 $NP=EXP$）

###### Theorem 20.17

现在开始炒菜环节。

如果三个都满足，那么 20.20 说明 $NEXP\in MA\in PH\in P^{perm}\in NEXP$，所以全部相等。然后 20.19 说明它们又全部等于 $NP$。最后，我们使用 Time Hierarchy 解决问题。


ex10：证明如果 $NEXP=MA$，那么 $NEXP\in P/poly$。

Proof(0.4*)：回顾之前的证明，如果 $EXP\not\in P/poly$，那我们有 SUBEXP 的 Derand，然后根据 ex6 就有 $MA\in NSUBEXP$，但这显然和假设矛盾（Time Hierarchy）。因此 $EXP\in P/poly$，那么 $NEXP=MA=EXP\in P/poly$。



### XXI Derandomization 3: Other Constructions: Expanders, Extractors

除了一般的 Derandomization，我们还可以考虑一些特殊的情况：如果只考虑一种情况或者模型，那此时有没有能替代随机的确定性构造？

#### Expanders

考虑无向图。

很多时候，随机图有着很好的性质，比如最小割一边一定很小，随机游走很均匀……等等。

在图论算法那边，有这样（和随机图差不多的）性质的图都叫做 Expander，然后我们通过一些算法把图拆成 Expander，对 Expander 容易解决问题，然后用大量技巧合并。（参见另外一篇 blog）在另一些算法中，我们直接随一个图，然后用 Expander 的性质。

但在 Derandomization 这里，我们更想去掉随机。好消息是，确实存在确定性的构造。然后我们就可以用它来替代一些随机图能干的事。

为了简便（比如，我们不关心啥 conductance / expansion），我们考虑的图里面每个点度数相等，这称为 $d$-regular。

##### Random Walk and Eigenvalues

考虑一个随机游走。分布可以用向量表示，然后随机走一步相当于左乘一个矩阵，记这个图对应的矩阵是 $A$。那么随机游走很多步相当于 $A^kv$。

因为考虑无向图，所以可以给它直接对角化。显然特征值在 $[-1,1]$ 之间（不可能走着走着变多），注意到 $d$-regular 情况下，有一个特征向量是 $1/n(1,1,\cdots,1)$。

特征值分解完考虑随机游走，那么本来 $u=\sum c_iv_i$，之后就变成 $c_i\lambda_i^tv_i$。因为正交，$1/n(1,1,\cdots,1)$ 前面的系数必然是 $1$。那么除了极端情况（图有非平凡循环周期，无向的时候就是二分图(ex3)），剩下的特征值模长都小于 $1$，然后就可以发现 $A^kv\to 1/n(1,1,\cdots,1)$，所以随机游走会收敛到均匀情况。

当然，为了避免二分图这种极端情况，一种常用解决方式是 Lazy Random Walk：每步有一半概率不动，一半概率随机走。也可以每个点加一个自环。  

但我们还关心它啥时候能收敛的比较好。可以发现这就和剩下这些特征值的大小有关。因此我们定义 $\lambda(G)$ 表示第二大特征值的模长。那跑完 $t$ 步之后，差距大概是 $\lambda^t$ 级别的。所以我们希望 $\lambda$ 不大。

实际上，我们可以证明，除去极端情况外，无权无向图的随机游走 $\lambda$ 确实很小：

直观上看，每一步是把相邻的权值混合起来，但因为我们考虑一个和 $(1,1,\cdots,1)$ 正交的东西，它必定有正有负，所以总会存在一个地方混合两侧一正一负，所以会减小。

但实际分析比想象中的复杂。记 $u$ 为当前系数，$v=Au$。注意到（？？？）可以通过如下方式搞交叉项：

$$
\sum A_{i,j}(u_i-v_j)^2=\sum A_{i,j}u_i^2-2u_iv_j+v_i^2\\
=|u|^2+|v|^2-2v^TAu\\
=|u|^2+|v|^2-2v^Tv\\
=|u|^2-|v|^2
$$

因此我们假设 $|u|=1$，然后我们就用一个非负的东西刻画了模长减少的量，也就是 $\lambda$ 的上界。

那么直观考虑，如果有一个很大的 $u_i$，一个很小的 $u_j$，然后找一条路径过去，依次用 $u_i-v_{i+1}$ 和 $v_{i+1}-u_{i+1}$ 串起来。然后用 Cauchy。

注意到因为模长 $=1$ 所以至少有一个 $1/\sqrt n$ 大小，注意到和 $1$ 正交所以两种符号都有，所以端点差距至少是 $1/\sqrt n$，结合起来总的量至少是 $1/d*1/n*(1/\sqrt n)^2=1/dn^2$。那我们就至少有 $\lambda=1-\Omega(1/n^3)$。

但对于 $d$-regular graph，我们还能做到更好：可以发现图里面任意两点最短路不超过 $O(n/d)$(ex4)：按照最短路分层，每个点只会连向相邻三层，然后数数。所以某个 $n$ 可以换成 $n/d$，然后就变成了 $\lambda=1-\Omega(1/n^2)$。

那么两者分别对应 $\tilde O(n^3)$ 和 $\tilde O(n^2)$ 的收敛时间。

实际上前面的分析对于任意非二分图也对：注意到此时最终分布正比于度数，度数分布拿过来仍然满足上面的分析，然后选路径的时候去奇环绕一下。

注意到这两个界都几乎是紧的：

1. 对于 $d$-regular Graph，考虑一条链，两边分别一个自环，也可以考虑一个环。解方程容易发现是期望 $O(n^2)$ 步走到对面。
2. 对于一般图，考虑一个团接一条链，然后期望 $n^2$ 步才能走上链一次，需要走上去 $n$ 次，得到 $O(n^3)$。

##### Expander Definition

如果是一个随机图，那我们期望它 mix 地很好。换言之，我们希望 $\lambda$ 尽量小：

所以定义它是 $(n,d,\lambda)$ 的 Algebraic Expander，如果 $\lambda(G)\leq \lambda$。

一个对推导非常有用的东西：记 $J$ 表示全 $1$ 矩阵，考虑 $A-cJ$，此时从特征值看，注意到 $A,J$ 都有 $(1,1,\cdots,1)$ 的特征值，然后在外面 $J$ 都是 $0$ 没有影响。所以这样相当于只是把 $A$ 最大的那个特征值减小 $c$。那考虑 $c=1-\lambda$，得到：

$$
A=(1-\lambda)J+\lambda C,\|C\|\leq 1
$$

但代数太复杂了，因此还有一个更简单的定义：

定义它是 $(n,d,\rho)$ 的 Combintorial Expander，如果对于任意一个割 $V=S+T$，$E(S,T)\geq \rho*d*\min(|S|,|T|)$。（在这种图里面 edge expansion 和 vertex expansion 几乎没有差距）

简单的性质：

ex9：对于任意一个图，$\lambda\geq 1/\sqrt d+o(1)$。

证明：考虑 $u=(1,0,\cdots,0)$。那么 $|Au|^2\geq 1/d$（Cauchy，只有 $d$ 个非零），但在这个图上 $u=1/\sqrt n\mathbf 1+...$，那么特征值分解一手，$|Au|^2\leq 1/n+(1-1/n)\lambda^2$，直接得到 $\lambda\geq \sqrt{1/d-1/n}$。那么一般情况下都可以看成 $1/\sqrt d$。

ex10：还可以继续代数分析。根据经典结论 $\sum \lambda_i=tr(A)$。$tr(A^k)$ 相当于随机游走返回自己的概率。在这里，考虑用每个点到起点的距离标记它，那么归纳可知最坏情况是每个点连到一个 $l-1$ 和 $d-1$ 个 $l+1$。此时如果走 $2c$ 步，那返回概率可以先考虑每一步的 $d$，然后乘上系数。但在只需要一个下界的情况下，可以把 $0\to 1$ 的概率从 $1$ 放到 $(d-1)/d$，这样 $2t$ 步概率就是 $C_{2t}((d-1)/d^2)^t$，其中 $C$ 是卡特兰数。那这差不多就是 $2^{2t-t\log d}$（$C_{2n}=\binom{2n}n/(n+1)$）。

那么另一边 $tr(A^k)\leq 1+(n-1)\lambda^k$，所以

$$
1+(n-1)\lambda^{2t}\geq n2^{2t-t\log d}
$$

现在假设 $\lambda^{2t}>1/n$，然后差不多就有

$$
\lambda^{2t}\geq 2^{2t-t\log d}
$$

这样就会得到 $\lambda\geq 2/\sqrt d$。为了满足条件，可以取 $t=\log n/\log d$。这可以是足够大的。

实际上搞这么复杂的原因主要是这个界差不多是可以达到的。（Ramanujan Graphs）

对于另一边，我们很容易做到 $\rho=\Omega(1)$(ex11)（注意 $\lambda$ 越小越好，$\rho$ 越大越好）：随机几个排列连边，然后用心算期望和 Chernoff。

另一方面，显然 $\rho\leq O(1)$(ex13)：考虑随机一个大小 $n/2$ 的子集，期望割边数量是 $d|S|/2$。那么显然 $\rho\leq 1/2$。

##### Equivalence

Expander 非常有趣的一点是，有一车不同用途的定义：Expansion，Conductance(Vertex Expansion), Random Walk($\lambda$), Cut Equivalence 等等，然后它们都可以是等价的，这样所有性质都能用。（另一个趣味例子是拟阵）

###### Algebraic to Combinatorial

考虑我们要算一组 $V=S+T$ 的割的边数有多少。那考虑如下向量：$S$ 处取 $+|T|$，$T$ 处取 $-|S|$。记这个向量为 $x$，那么 $|x|^2=(|S|+|T|)|S||T|$。

和之前一样，考虑如下处理：

$$
\sum A_{i,j}(x_i-x_j)^2=2\|x\|^2-2x^TAx\geq 2(1-\lambda)\|x\|^2
$$

注意到左边只数了割边，那么 $2|Cut|*(|S|+|T|)^2/d\geq 2(1-\lambda)(|S|+|T|)|S||T|$，所以割边数量至少是 $(1-\lambda)d|S||T|/n$。

然后显然有如下结论：

1. 如果它是 $\lambda$-expander，那它也是 $\rho=(1-\lambda)/2$ 的 Expander。

实际上也可以分析更一般的情况，比如 $S,T$ 并起来不是全集(ex14)。

但分析非常的代数：记 $1_S$ 表示只在这些下标是 $1$ 的向量，那我们要分析 $1_S^TA1_T$ 的值。这里考虑没有 $/d$ 的情况。

此时 $A$ 的最大特征值是 $d$，次大特征值 $d\lambda$。我们想把 $d$ 给分出来。注意到这是可行的：记 $J$ 表示全 $1$ 矩阵，考虑 $A-(d/n)J$。可以发现本来两个矩阵都在 $1$ 上面有一个特征值，然后在别的空间上有一组正交特征向量。但 $J$ 别的地方都是 $0$，那么可以共用 $A$ 的特征向量。这样 $A-(d/n)J$ 的特征值就是把最大的那个删掉，其它不变。那么出来这部分贡献一个 $d|S||T|/n$。剩下的部分根据 Cauchy，不超过 $\lambda\sqrt{|S||T|}$。（相当于把最大的一项单独处理）。那么得到：

$$
E(S,T)\in \frac dn|S||T|\pm \lambda\sqrt{|S||T|}
$$

更直接的，我们可以给一个 Vertex Expansion(ex15)：考虑 $A1_S$，可以特征值算它的模长大概是多少。然后注意到如果模长是 $k$，那么至少需要 $1/k$ 个位置才能做到(Cauchy)。

###### Combinatorial to Algebraic

为了简便，我们认为特征向量都是实系数的。

之前搞了一些差的二次项的东西，但这个很难分解。注意到：

$$
(\sum A_{i,j}(v_i-v_j)^2)(\sum A_{i,j}(v_i+v_j)^2)\geq (\sum A_{i,j}|v_i^2-v_j^2|)^2
$$

这是一步 Cauchy。然后第显然

$$
\sum A_{i,j}(v_i+v_j)^2=2\|v\|^2+2\langle Av,v\rangle\\
\sum A_{i,j}(v_i-v_j)^2=2\|v\|^2-2\langle Av,v\rangle
$$

那如果我们考虑任意一个特征向量 $v$，这一堆就是确定的，此时

$$
(\sum A_{i,j}|v_i^2-v_j^2|)^2\leq 4(1-\lambda^2)\|v\|^4\\
\sum A_{i,j}|v_i^2-v_j^2|\leq 2\sqrt{1-\lambda^2}\|v\|^2
$$

然后解决左边。一次项的好处是可以线性性。那么不妨设 $v_1^2\geq v_2^2\geq\cdots v_n^2$，然后

$$
\sum A_{i,j}|v_i^2-v_j^2|=2\sum_{i=1}^n|v_i^2-v_{i+1}^2|cut([1,i],[i+1,n])
$$

然后就可以用 Edge Expansion 了！

$$
\sum A_{i,j}|v_i^2-v_j^2|=2\sum_{i=1}^n|v_i^2-v_{i+1}^2|cut([1,i],[i+1,n])\\
\leq 2\sum_{i=1}^n|v_i^2-v_{i+1}^2|\rho\min(i,n-i)
$$

那如果没有那个 $\min$，再拆回去就是 $2\rho(\sum v_i)^2=2\rho\|v\|^2$。如果是这样的话，我们就能直接得到：

$$
2\rho\leq 2\sqrt{1-\lambda^2}\\
1-\lambda^2\geq\rho^2\\
\lambda\geq \rho^2/2
$$

那怎么解决 $\min$？考虑只取 $v$ 的一部分项。这样的问题出在计算 $\langle Av,v\rangle$ 的时候，它并不一定是 $\lambda|v|^2$。但是我们可以放缩：记 $w=v-v'$，只要 $w^TAv'<0$，那这个东西必定大于 $\lambda|v|^2$。这样 $2\|v\|^2+2\langle Av,v\rangle$ 会变大，但它不是关键项，放到 $4\|v\|^2$ 甚至也不影响分析。

摆了，如果是实数那直接正负分开就行，如果有复数那不会算了。

#### Construction of Expanders

因为我们想做 Derandomization，那我们必须要一个确定性的构造算法。

做法是，考虑几种把图组合起来的方法：

##### Multiplication

考虑两个点数相同的 $d$-regular Graph，直接把它们的矩阵乘起来，显然这还是个图。

容易发现点数不变，度数 $d\to d^2$。但好处是，这样的 $\lambda$ 减小了：变成两个乘起来。证明是容易的：注意到 $(1,1,\cdots,1)$ 的正交空间上特征值都不超过 $\lambda$（并且也不会映射出去），那乘起来倍数不超过两个 $\lambda$ 的乘积。

##### Tensor Product

根据经典定义，点现在记作 $(u_1,u_2)$，然后 $(u_1,u_2),(v_1,v_2)$ 有边当且仅当 $(u_1,v_1),(u_2,v_2)$ 在各自的图里面有边。

那点数 $n\to n^2$，度数 $d\to d^2$。注意到特征值也是 Tensor Product 起来，所以 $\lambda$ 变成两个 $\lambda$ 的最大值。

那我们又可以增加 $n$，又可以降低 $\lambda$。但还差一步：如何减少 $d$。

##### Replacement Product

首先考虑这样一个操作：把每个点换成一个大小为 $d$ 的团（带自环），然后每个点连一个出边。

直观上看，如果我们能一步外面一步里面的走，那里面的部分模拟了随机选点，所以这就和最初的随机游走完全一样。

实际上我们必须混在一起走。但这说明，我们保留了一部分随机游走：

考虑构造一张图，每步有一半概率走团一半概率走外面，那考虑 $G^3$，则 $8$ 个部分中有一个等价于原先的随机游走。因此可以知道，如果原来是 $\lambda=1-c$，那现在至少是 $\lambda=1-c/8$。

但换个团等于没换。不过注意到，根据之前 random walk 的想法，一个 Expander 在此时和团很接近。具体来说，从特征值的角度，一个 Expander 等价于一个团的邻接矩阵（全 $1$）加上 $\lambda$ 的小量（$\|C\|\leq 1$）。那么这里把这个带进去，得到 $\lambda\leq 1-c(1-\lambda)^2$。

这样的话，如果我们有一个 $(n,d,1-c)$ 的 Expander。我们就可以点数 $\times n$，度数 $n\to d$，然后 $\lambda\to 1-c(1-\lambda)^2/8$

也可以组合证明。

##### All together

那很容易想到怎么拼起来：先增加点数，然后降低 $\lambda$。接下来一步把度数降回去。

那考虑每次先 $A\times A$，然后矩阵乘 $A^{10}$。接下来我们需要度数 $d^{20}\to d$，然后就是 $\lambda\leftarrow 1-c(1-\lambda^{20})^2/8$。让 $c$ 取一个常数。因为 $20$ 可以随便大，所以一定可以找到一个范围，使得 $\lambda\leq 1-t$ 时，变化一步后还小于这个值。

还有两件小事：

1. 我们只得到了每个 $d^k$ 大小的 Expander。但这是容易变成其它大小的 Expander 的：考虑就定一个 $n$，然后缩到 $n$ 个点。

这凭啥对(ex16)？虽然拿 Algebraic 非常难说，但考虑 Edge Expansion，可以发现缩点不影响 Edge Expansion 的任何性质，所以就秒了。这再次说明多个角度的重要性。

2. 在用 Expander 的时候，把图建出来实在是太慢了。事实上很多时候我们只需要随机采样一个出边。那可以发现这里容易 $O(\log_d n)$ 采样：直接逆向整个过程。


#### Using Expanders

##### Random Walk on Expander

考虑如下过程：在一个 Expander 上，先随机一个点，然后随机开始游走。可以证明：

1. 对于一个大小为 $kn$ 的集合，走 $t$ 步还一直停在里面的概率不超过 $((1-\lambda)\sqrt k+\lambda)^t$

证明：考虑停在里面的概率。每一步，我们把 $x$ 变成 $Ax$，然后只保留其中 $kn$ 个位置。注意到 $A=(1-\lambda)J+\lambda C$ 后面部分 $\|C\|=1$，前面部分注意到操作完都是 $(1,1,\cdots,1)$，但这样去过一个保留位置就直接 $*\sqrt k$。所以每一步范数减少这么多。

那么如果 $\beta$ 是个常数，我们都可以找一个合适的 $\lambda$，使得概率是 $exp(-t)$。

那这说明了啥？考虑一个直接的翻译：每个点表示一个随机串 $y$。考虑一个 RP 算法，那么只要有常数概率能看出来，我们都可以换成用这个方式走，它也不差。

那这有什么意义？本来我们是要 $n*t$ 的随机次数，现在变成了 $n+t$。

可以发现这个对 BPP 也能搞(ex12)：显然结论可以扩展到，对于任意选 $t$ 步，它们都在里面的概率是指数小的。然后对着 BPP 错的概率数数，注意到这个等价于随机变量之和大于某个值的概率，然后 Chernoff。

##### Expander Algorithms

众所周知，很多问题在 Expander 上是简单的：

1. 如果问最小割，那可以确认我们只用考虑一侧很小的割。
2. 类似的，如果要 Flow Sparsifier，那可以直接一个菊花。
3. 还是类似的，如果要最短路，那注意到随机游走 Mixing Time 是 $O(\log n)$，也就是说存在长度 $O(\log n)$ 的路径。

我们考虑最后一个。如果图是 Expander，那我们只要很短的随机游走就能判定连通性。那如果图不是 Expander 呢？此时我们可以尝试提取出一些 Expander。例如，我们有 Expander Decomposition：把图分成若干块，每一块里面都是 Expander。我们有 Repeated Version，能保证分掉每条边。而对于连通性，有更直接的做法：注意到之前的那堆复合操作都不怎么影响连通性（除非你叉积一个二分图）

考虑拿到一张图 $G$，我们每步先自己 Matrix Product 很多次，然后 Replacement Product: $d^k\to d$。然后循环往复。那个分析不仅保证了 $\lambda\leq 1-c$ 的时候它不会变大，也很容易分析到说如果 $\lambda$ 比某个值大，那每一步都会减小足够多倍。

注意到任何一个连通块一开始都至多是 $1-O(1/n^2)$，那么做 $O(\log n)$ 次就可以保证每个连通块都是 Expander。

那么在这个图上随机游走期望 $O(\log n)$ 步就够了。

那点数呢？每步乘 $d$，$O(\log n)$ 次，所以还是 poly n。

如果初始不是 regular graph? 随便拆一下点。注意到现在就可以暴力枚举 $O(\log n)$ 步，然后每一步存一下走的方向。整个回溯过程也随便做，那么我们得到如下震撼结论：

Thm. Connectivity $\in L$。

注意到我们相当于直接搞了 $G^{n}$，但通过高明的 Expander 技术把边数降了下去。从 Random Walk 的角度， Expander 确实是拿来做这种作用的。

#### Randomness Extractors

给一个不那么随机的东西，我们能不能提取一个很随机的东西？

##### Random Sources

首先考虑定义一个东西的随机程度。显然熵是一个好的定义，但有个小问题：如果我有一半概率是 $0$，一半概率随机，那它的熵还是很高。但另一方面，从一半的 $0$ 里面显然啥都提取不出来。

因此考虑 Min-Entropy: $H_{\infty}=-\log\max \Pr[x]$。

然后目标是什么？显然我们不能从三个 $1/3$ 里面完美地提取随机串。因此我们考虑 Statistically Close。

那么一个定义的想法就是，输入一个 $H_{\infty}$ 是 $k$ 的东西，我们输出 $m$ 位，满足输出和随机分布的统计距离不超过 $\epsilon$。在此基础上，我们希望 $m$ 比较接近 $k$。

但有个问题：给定一个程序作为 Extractor，那我们可以构造一个输入(ex17)，只把让它第一位输出 $0$（或者 $1$）的东西放进去，那 Min-Entropy 差不多是 $n-1$，但你显然提取不出来。

所以说 Extractor 也是随机的：它输入 $x$，再输入 $d$ 位随机串。也可以看成它对一个 $x$ 的输出是 $2^d$ 种可能情况之一。为什么这样可能行？如果来安排这个，那可以随手堆到 $2^{-d}$。但堆到这个不影响：$d$ 里面加一项 $O(\log(1/\epsilon))$ 就可以。

实际上确实是：

##### Existence

根据传统艺能直接随机。怎么分析 Statistical Distance？一种方式是考虑 $2^k$ 个值域的所有子集，取差的最大值。

现在考虑 $X$ 是随机 $2^k$ 个位置，那我们相当于 $2^{k+d}$ 个东西随机撒下去，然后问 Statistical Distance。

根据上一句的分析，我们考虑每一个子集，那么是这堆东西随机撒到 $0,1$，然后问偏差了 $2^{k+d}\cdot\epsilon$ 的概率。那来一个 Hoeffding，得到概率大概是 $exp(-2^{k+d}/\epsilon^2)$。

然后 Union Bound。我们有 $exp(2^k)$ 个函数，有 $exp(n2^k)$ 个取值。那很容易发现我们只需要
$$
d=\log n+2\log(1/\epsilon)+O(1)
$$
就可以了。

现在只考虑了随机 $2^k$ 个位置的情况，但根据上次的结论，每个 $H_{\min}$ 很大的分布都是这样很多组（随机 $2^k$ 个位置）的线性组合。

##### Leftover Hash Lemma

密码学经典结论：随机 $A\in \{0,1\}^{m\times n},x\in \{0,1\}^n,H_{\infty}(x)=k$，则 $(A,Ax)$ 和随机 Statistically Close。

证明：固定一个 A 看距离。记分布为 $p$，则

$$
\|p-1\|_2^2=\langle p,p\rangle-\langle1,1\rangle=2^{-2k}[\sum_{x,y}[Ax=Ay]-2^k]-2^{-m}=2^{-k}
$$

考虑不同 $A$ 相当于平摊，好像不改变这个事。那是不是随便啥 $m$ 都行？一个问题是，L1 和 L2 是不一样的。$L_2=2^{-m}$ 的分布可能 $L_1=1$：考虑均匀随机。但根据 Cauchy 这个就是最坏情况。所以 $k=m+O(\log 1/\epsilon)$ 就是可行的。因此我们需要 $m=k-O(\log 1/\epsilon)$。 



当然可以把 $Ax$ 换成任意一个 Pairwise Independent（显然上面只用了二次）。最优的构造长度是 $O(n+m)$。

当然这个和上面的 Extractor 还有一点点区别：这里可以把随机部分也输出出去。所以这个用上面的描述是不那么优的。

##### Random Walks

注意到 Expander 上随机走 $O(\log_{\lambda}\epsilon)$ 就是很随机的，所以考虑把输入看成 Expander 上的点，随机输入看成游走的参数，然后直接走。

初始 $L_2=2^{-k}$，但还是有之前一样的问题，需要做到 $L_2=\epsilon 2^{-n}$。所以需要 $d=n-k+O(1/\epsilon)$。

##### NW Generators

我们知道，如果拿一个 Avg Hard 的 $f$，那我们就可以造一个 Computationally indistinguishable 的 NW Generator。原因是，如果我们能分辨后面那个，那我们就可以很好的去算一个 $f$。

但这里要求比 CI 高一档，还能用 NW Generator 吗？在要求 Statistically Close 时，Distinguisher 可以是任意函数，所以不一定能直接搞。

但注意到 Extractor 和之前的 PRG 不一样：我们的输出位数又回到了 poly 级别（也不可能比 $n$ 大）。考虑输出 $k^{1/4}$ 位，那此时就只有 $2^{k^{1/4}}$ 个 Distinguisher。然后继续数数：有这么多 Distinguisher，每一个这样的东西，我们还需要把其它位构造出来，那部分可能性也不超过 $2^{k^{1/4}}$。因此随便拿 $2^k$ 个函数过来，总有一些是困难的，不能被这些东西处理。

因此考虑如下构造：把输入看成一个 $\{0,1\}^{\log n}\to\{0,1\}$ 的函数，然后就用 NW Generator 造一个 $\{0,1\}^{c\log n}\to\{0,1\}^k$ 的东西，然后输出。分析就和之前一样：能 Distinguish 的函数数量是有限的，所以大多数情况都不行。

可以发现这个几乎就是最优的。

##### Random Sources and black-box simulation of BPP

ex18a：如果输入一个 $H_{\infty}\geq n^{10}$ 的东西，那我们可以用一个 Extractor 生成很多随机 bit，满足所有情况下平均起来和均匀随机很接近，然后在当前这个部分里面计数即可。注意到 Extractor 可以用很小的参数（上面那个构造），所以可以枚举那部分随机做到确定性。

然后显然不给随机是不行的(ex18b)：我们构造一个，你输入的位置全放 $0$，别的地方全放 $1$。

类似的，如果只有一个很小的 Random Source（满足对于任意一个 $H_{\infty}\geq n/2$ 的东西，它们的距离都是常数），那也是不行的(ex18c)：容易发现这个 Source 必然满足很多东西都聚集在 $2^{n/2}$ 个位置上，然后对这些位置安排即可。

更深层次的，直接 Black-Box 搞 Derandomization 是不可行的，我们都得更具体的考虑 BPP 的算法，比如 NW Generator 就用到了算法作为 Distinguisher。

#### Using Extractors: Nisan's Generator, Derandomizing L

注意和 NW Generator 区分。

##### Recycling Lemma

现在有一个本来很好的随机 $X$，但我们拿它搞了个 $f(x):\{0,1\}^n\to \{0,1\}^s$，所以现在它不是那么随机了（给定 $f(x)$）。那我们能把随机提取出来吗？考虑跑一个 Extractor：$\{0,1\}^n+\{0,1\}^{s+O(\log 1\epsilon)}\to \{0,1\}^n$。

现在固定一个 $f(x)$。如果原像数量是正常的 $\epsilon/2$ 倍以上，那 Extractor 都可以跑得足够好。剩余部分加起来误差也不超过 $\epsilon/2$。

这有什么用？考虑 $L$（带随机的那些）都相当于一个函数，输入前若干位随机后输出走到的状态。那如果我们在某个地方停下来，然后就可以把之前用过的随机几乎回收过来，然后就可以替代后面的随机。

那考虑直接搞，每次我们加 $\log S+\log 1/\epsilon$ 位，就可以把之前的随机全收回来。注意到每次加的东西也会放到 Entropy 里面去，所以每次能提取的东西会越来越多。但这样还是需要 $\sqrt n$ 级别的随机。

那怎么更好？每次提取出来是完全随机的东西，但我们只需要对 $L$ 来说很随机。那这里可以再套一个自己的 Generator。具体来说，我们分层定义 $G_i$：

$$
G_i(S,z)=G_{i-1}(S)\circ G_{i-1}(Ext(S,z))
$$

证明考虑 Hybrid Argument：先把右侧换成随机，这里用 Statistically Close。然后分别下两个 $G_{i-1}$，每一步归纳。因此总误差差不多是 $2^k\epsilon$。同时输出也差不多是 $2^k$，所以我们需要 $\epsilon=O(1/poly(n))$，但这是可以的。这样 Seed 长度是 $k\log(1/\epsilon)=O(\log^2 n)$。所以

$$
BPL\in SPACE(\log^2 n)=L^2
$$


### XXII PCP Theorems

#### Basic PCP Theorem

首先我们回顾什么是 PCP。用原始的定义相当于，任意一个 NP Language 都可以被这样 Check：Prover 准备一个可以非常长的串，然后 Verifier 随机 $p(n)$ 个 bit，然后决定问 $q(n)$ 个位置，然后看是否接受。要求是如果是对的，那么可以让接受率为 $1$；反之任何情况下接受率都不超过某个常数。

有一个等价的表述：考虑一个 $CSP(q,2)$ 的问题：有一堆 $0,1$ 变量，然后有一堆限制，每个限制只和 $q$ 个变量有关。我们需要给变量赋值，满足尽量多的限制。这里每个限制就相当于 Verifier 某种随机后进行的操作。

那么 $PCP(\log n,1)$ 就相当于如下情况的 CSP：限制数量 $2^{O(\log n)}=poly(n)$，那么变量数量也是 $poly(n)$。那么完整的 PCP Theorem（$NP\in PCP(\log n,1)$）就相当于说，在 CSP 里面判定如下两种情况是 NP-Hard 的：

1. 可以满足所有限制。
2. 不能满足常数比例的限制。

显然区分全部满足和不能全部满足是困难的。为了证明上面的东西，我们希望把这个 Gap 放大：找到一个变换，使得本来能完全满足的之后也能完全满足，但不能完全满足的现在有很多不能满足。

在接下来的过程中，我们还会用到非 $01$ 变量的 CSP。这里记变量的取值（字符集）为 $W$，问题记作 $CSP(q,W)$。

我们还一直在尝试放缩 Gap。那么我们记 $1-\epsilon$ 表示我们构造到现在的 Instance 满足：

1. 如果原来有解，那么现在还是有解。（这一条一般是显然的）
2. 否则，现在最多满足 $1-\epsilon$ 比例的限制。

因此我们总共有三个参数：限制变量数 $q$，字符集 $W$ 和近似比 $\epsilon$。初始 $q=O(1),W=2,\epsilon=1/n$。

在 $q=2$ 的时候，我们可以把变量看成点，限制看成边，然后这就是一张图。我们希望引入图论的技术，所以这里还有：

1. 每个变量所在限制数量的最大值 $d$。
2. 图的 $\lambda$。

我们现在开始操作。目标是 $\epsilon=\Omega(1)$。

最后一个注意事项：为了规约合法性，显然最后的大小得是多项式的。

##### OPENING: Preparation of Instances

###### Reducing q

考虑每个限制建一个变量，记录它包含的变量的取值。这样限制就变成了一元限制。然后加一些和原先变量的限制，表示两个取值要一致。

考虑如果有一个和变量不一致的限制，那么调成一致不会变差（那边至少 $-1$，这边最多 $+1$）。从而不能满足的限制数量不会减小，显然也不会增多。但限制数变多了，所以 Gap 还是变小了。

所以 $q\to 2,W\to W^q,\epsilon\to \epsilon/q$，然后大小变成 $q$ 倍。

###### Reducing Degree

显然我们想拆点：把一个变量拆成很多个，然后连一些限制保证它们得相等。

但在考虑 Gap 的时候，直接连可能不太好：考虑连成一条链，那这样我可以前一半一个取值，后一半另一个取值，这样就用 $1$ 的代价变了一半的取值。这是完全不行的。

那么直观上看，我们需要找一种连的方式，使得随便你怎么分两半，一半一种取值（多种的情况和两种类似），那这样违反的限制数都至少和两边较小的一侧相关（这样的话，偏离这么多取值的代价差不多就是偏离取值的数量）。换言之，我们希望有一个和完全图或者随机图一样的性质。

那这就是一个 Edge Expansion。所以我们考虑拿 Expander 过来。为了简便，我们还是用 Algebraic Expansion，同时我们只用一个形式非常简单的推论（更精确的分析参考上一章）：

1. 考虑一个大小不到一半的集合 $S$，$S$ 内连出去的边回到自己的概率不超过 $1/2+\lambda/2$，换言之连出去的概率至少是 $1/2(1-\lambda)$。
2. 对于合理的 $d$ 和足够大的 $n$，我们都能构造 $\lambda=1-\Omega(1)$ 的 Expander（见上一章）
3. 还有一个非常常用的东西是 $G^k$，它表示把邻接矩阵乘起来，或者每条边对应一条长度确定的路径。注意到 $G^k$ 是把特征值也 pow 的。所以第一条的直接推论是，走一条长度为 $S$ 的路径，最后回到自己的概率不超过 $1/2+\lambda^k/2$。

Proof(1)(ex1)：根据经验，我们拿出 $A=(1-\lambda)J+\lambda C$，然后前半贡献不超过 $(1-\lambda)\cdot |S|/|V|\leq 1/2-\lambda\2$，后半贡献不超过 $\lambda$。

现在我们认为我们有 $0.1$ 的 Edge Expansion。然后我们对每个变量造一个 Expander，然后一个点连向一个原来的限制。

现在考虑新图的一个最优方案，如果一个变量的 Expander 上取值不同，那我们全部取出现次数最多的那种，这样改变量取值可能增加 $c$ 个错误，但 Expander 内减少了 $c/10$ 个错误。

那我们至少可以说明，存在一个 $10$ 倍错误的方案和原来的方案对应。那么现在的错误最少是之前的 $1/10$。我们限制数又乘了 $d$ 倍，所以最多是 $1/10d$。

那么 $\epsilon\to \epsilon/10d$。同时图变成了 $(d+1)$-regular。

ex16: 已知 MAX-3SAT 的近似是困难的（看下面），证明如果只考虑每个变量出现常数次的问题，那近似还是难的。

Proof：和上面一样拆点，上 Expander。

###### Making Expander(Reducing Lambda)

其实非常简单：找一个 $0.5$-expander，把这张图加上去（放一些 Trivial 的限制）。

注意到显然 $\lambda(A+B)\leq \lambda(A)+\lambda(B)$（把共同最大的扔掉也对），然后随机游走又 $/2$ 了，所以就会从 $1$ 变到 $1-\Omega(1)$。

##### MIDDLE: Reducing Alphabets using Exponential PCP

上面有一步，减少了 $q$ 但是增大了 $W$。我们再考虑反过来的问题：能不能把 $W$ 变回 $2$？

那我们显然可以又把变量写成二进制表示，然后把限制摊开……但这显然是在搞笑，因为 $q\to q\log W,W\to 2$ 相当于把之前的一步做的事情给倒回去了。

换句话说，我们希望验证两个 $\log W$ 位变量之间的关系，但我们不希望一次读 $O(\log W)$ 位，而是 $O(1)$ 位更好。那这显然又是一个 PCP。

但我们不能用 PCP 来证明 PCP。不过这里（我们相信）$W$ 和 $n$ 无关，所以复杂度搞大点也行。那注意到在很久之前（Chapter11），我们证明了一个弱化版的 PCP：$NP\in PCP(poly(n),1)$。

回顾那个证明：我们搞来一个 WH Code：把 $n$ 位映射到 $2^n$ 位，每位是它和某个向量内积的结果。这样如果我们想求某个 $\langle a,x\rangle$，那~~我们可以直接读~~为了保证正确性，我们可以读两个然后相减。

然后我们注意到判二次方程组模 $2$ 的解是 NP-Complete 的，而这个很好用 WH Code 表示：我们要求 Prover 提供 $A,A\times A$ 的 WH Code，为了验证这两个的合法性和二次方程组的合法性，我们随机向量内积上去判定。

那这里类似：每个关系都可以写成 Circuit，然后可以规约成二次方程是否有解。然后我们对这个写一个 PCP。现在新的变量就是 PCP 的这堆 Code，然后新的限制是我们每个随机种子搞出来的验证过程。

再来考虑正确性。注意到 PCP 保证，如果这个限制是错的（无论是它给了一个错误的 Code 还是 Code 对应的原来东西不满足），那正确率都不超过 $1/2$。（这个实际上和 PCP 的定义略有不同，但是容易验证这是对的）。因此现在如果某个变量上正确率大于 $1/2$，那么它们就满足了原来的一组方程。因此错误率至少是 $\epsilon/2$。

那么 $q\to O(1),W\to 2,\epsilon\to \epsilon/2$。然后大小乘上 $2^{poly(W)}$ 倍。

##### FINALE: Gap Amplification using Powering and Expander

我们已经解决了 $q,W$，但还缺少最关键的一步：如何把 $\epsilon$ 增大。我们先来看一个例子：

###### Warmup: Approximating Independent Set

我们曾经说过，近似独立集的计数是非常难的，因为你把图复制 $k$ 遍，计数就变成了 $k$ 次方。那么如果我们能近似复制后的图，那原来的图的近似比就被压缩了。

但直接复制显然对最大独立集没有用：这样复制只是把最大独立集乘以 $k$，而不是 $k$ 次方。

不过，真的有把最大独立集变成 $k$ 次方的方式：考虑 $n^k$ 个点，每个点由 $k$ 个下标 $c_1,\cdots,c_k$ 构成。两个点之间有边，当且仅当它们对应的所有下标（去重后）没有边相连。可以发现如果原来独立集为 $c$，现在的 $c^k$ 还是独立集。另一方面，如果现在有一个独立集，那它们包含的点并起来显然是原来的独立集。

但这样点数太多了！我们只能让 $k$ 是常数。但好像 $(c-1)^k$ 和 $c^k$ 差别不大。

不过可以先把图复制 $n$ 遍，这样差距就是新的点数的根号，然后就可以说明 $1+n^{-\epsilon}$ 倍近似是困难的。虽然这个还是打不过之前的结果。

那怎么更好呢？我们干的事情是把所有的 $c_1,\cdots,c_k$ 选出来，而 Expander Walk 可以接近随机地选出来这些东西。

考虑一个 $d$-regular Expander。我们在上面考虑所有长度 $O(\log n)$ 的游走，把经过的点一次写下来得到长度 $O(\log n)$ 的序列。这显然只有 poly 大小。然后我们想说明，它们和均匀选出的差不多，在独立集的情况里面就是对于每个集合 $|S|=cn$，在集合里面的路径数量占比差不多就是 $c^{O(\log n)}$。具体来说，我们的结果是 $(c\pm 2\lambda)^{O(\log n)}$。

Proof.(ex2) 仍然考虑 $A=(1-\lambda)J+\lambda C$，然后算概率是显然的。

然后考虑，在很久之前我们证明了某个常数倍近似独立集大小是 NP-Hard 的，那这里区分 $c,2c$ 是困难的。我们先给图里面加一堆孤立点避免 $c$ 小的情况，然后就可以使得 $c+2\lambda$ 比 $2c-2\lambda$ 小很多，这样最后如果我们能分辨 $(c+2\lambda)^{O(\log n)}$ 和 $(2c-2\lambda)^{O(\log n)}$，我们就能区分原来的 $c,2c$，但这就困难了。因此在新的图上，近似比不能超过某个常数的 $O(\log n)$ 次方。

显然不用 Expander 也能做这事，但此时点数为 $n^{O(\log n)}$，所以这个近似比还是太小。但用 Expander 之后，点数是 $d^{O(\log n)}$，那近似比是点数的 poly。换言之，我们可以得到如下结论：

在新的图上，$n^{-\epsilon}$ 倍近似最大独立集是困难的（对于某个 $\epsilon$）。

ex15：证明 $n^{-\epsilon}$ 倍近似如下问题是困难的：给一堆线性方程，求最多能满足多少。（这里不是有限域，因为有限域随一个就是 $1/p$。）

可以发现这就和上面的想法差不多：考虑直接枚举 $n^k$ 次 $k$ 个下标，然后随机线性组合起来，这样就把 $\epsilon\to \epsilon^k$。然后把这件事换成 Expander，$k$ 取 $O(\log n)$，复刻上面的最后几步即可。

###### Powering for CSP

考虑 $q=2$ 的情况，那么限制可以看成一张图。然后我们用之前的技巧保证，图里面每个点度数都是常数 $d$，同时图是 Expander。

显然，现在对应一个 walk 的应该是一个限制，因为我们要数满足限制的数量。那么一个新的限制就对应了很多条边，也就是很多个之前的限制。按照想法，我们应该让所以限制都被满足才满足这个大限制。

那变量是啥？Naive 的想法就是拿出原来的变量，然后现在 $q$ 就变成 $O(t)$，其中 $t$ 是游走的步数。但这样不够：这个正确率相当于 $(1-\epsilon)^t\geq 1-t\epsilon$，但等会把 $q$ 变回去还要 $t\epsilon\to \epsilon$，所以又相当于啥都没做。

那我们希望 $q$ 不变大，那每个点必然记录更多信息。因此，每个点上现在同时记录距离它不超过 $t+\sqrt t$ 的所有点的取值。然后对于每一个长度 $2t+1$ 的路径，以下为不合法情况：

1. 路径上存在相邻两个点，左边距离起点不超过 $t+\sqrt t$，右边距离终点不超过 $t+\sqrt t$，然后它们两个在两侧分别的值放在一起不合法。

那如果全部按照真的方式填值，这就是好的。但填一点不一致的东西看起来可以更优，这怎么考虑？

和之前一样，我们尝试从新的一组解里面还原一个原先 $n$ 个变量的取值，然后说明新的东西违反的限制数不比原来在原图上违反的限制数少太多。

之前我们找了出现次数最多的取值，这里差不多：考虑从一个点开始随机走 $t$ 步，然后取走到概率最大的取值作为我们的值。

这有啥用呢？考虑 $2t+1$ 路径的中点，固定中间这条边后可以看成两边分别随机走 $t$ 步，所以左侧走到一个给这个点赋值等于上面取值的点的概率至少是 $1/W$。类似的，所有以这条边为中点的路径中，期望有 $1/W^2$ 的路径满足，中间两个点的众数取值和两端点给的取值一样。

但这样还只是 $/W^2$。那我们多考虑几条边：考虑中点两侧 $\delta\sqrt t$ 的点。它们出发的路径是 $t\pm \sqrt t$ 范围的随机游走。

这好像和之前长度为 $t$ 的随机游走有很大差距。但我们可以让它没啥差距！考虑往图里面每个点加一半自环，这使得 $\epsilon$ 除以 $2$。但加了自环以后，可以这样考虑：随机游走是先枚举实际走几步，然后再随机游走。第一个是一个二项式分布 $B_n,\Pr[B_n=c]=2^{-n}\binom nc$。那么有如下结论：

$B_n,B_{n+\delta\sqrt n}$ 的 Statistical Distance 不超过 $O(\delta)$。

Proof.(ex3) 考虑 $B_n,B_{n+1}$，那么有一半概率相同，另一半概率往右移动一位。因为 $B_n$ 是先单增再单减，所以这样移动后是前一半变小，后一半变大，然后就可以把 $\sum |u_i-v_i|$ 两边合并起来，得到这个差距只和 $B_n$ 中最大的概率有关。那个就是 $2^{-n}\binom n{n/2}$，根据经典近似 $n!\approx \sqrt{2\pi n}(n/e)^n$ 这就是 $O(1/\sqrt n)$ 的。所以动 $\delta \sqrt n$ 次都还是好的。

那么我们取周围 $\delta\sqrt t$ 条边，它们满足条件的概率都至少是 $1/2W^2$。这样就能说明，随机取一条路径，上面期望有 $\epsilon\sqrt t/W^2$ 条边对应了原先不满足的限制（因为不合法的限制有 $\epsilon$）。但现在还不行：可能有些路径上有很多，别的路径上没有，然后又把 $\sqrt t$ 干掉了。

但直到此时，我们还没用到 Expander 的性质。注意到如果是个 Expander，那么所有路径的表现应该近似于随机选点。而随机选点时，因为不满足的限制本来只占 $\epsilon$，所以一条路径里面应该不会出现很多这样的限制。具体来说，我们可以算 $E[x^2]$。经过边是比较麻烦的，可以放松为经过对应的 $\epsilon d$ 比例的端点。这样经过两个端点的概率几乎就是 $(\epsilon d)^2$，但还会多 $\epsilon d(\lambda)^{j-i}$（经过的两个位置）。但这个求和就是 $O(\epsilon d)$。显然我们假设 $\epsilon d<1$，那么整个期望就是 $O(\epsilon d\cdot \delta\sqrt n)$。

那么根据另一种 Cauchy，我们有 $E[X>0]E[X^2]\leq E[X]^2$（ex4）（对于非负变量），从而

$$
Pr[X>0]\geq \epsilon\sqrt t/dW^4
$$

那么只需要 $t$ 足够大，就可以把后面这堆东西压下去。

这样得到 $\epsilon\to C\epsilon,q\to 2,W\to d^{O(dW^4C)}$，然后大小也差不多乘上这么多倍。

这看起来很恐怖，但注意到 $d,W$ 都可以是常数，那么问题也不大。

##### ENCORE: Putting Altogether

回顾一下所有步骤：

1. 把图变成 $d$-regular expander: $\epsilon\to \epsilon/O(d)$。但这与原先度数无关。大小乘上原先度数。
2. Reducing $q$：$q\to 2,W\to W^q,\epsilon\to \epsilon/q$，然后大小变成 $q$ 倍。
3. Reducing $W$：$q\to O(1),W\to 2,\epsilon\to \epsilon/2$。然后大小乘上 $2^{poly(W)}$ 倍。
4. Increasing $\epsilon$：$\epsilon\to C\epsilon,q\to 2,W\to d^{O(dW^4C)}$，然后大小也差不多乘上这么多倍。注意这个只考虑了 $q=2$。

那取 $C=$ 一个常数。一开始 $q=2,W=O(1)$。每次先做第一步，再做第四步，然后第三步，最后第二步，然后就可以升天了。

#### Advanced PCP theorem

上述定理给出的结果形如：

存在某个 $W,\epsilon$，使得区分 CSP(2,W) 的 $1,1-\epsilon$ 是困难的，

但为了做到更好的常数，我们可以考虑更强的 Theorem：增大 $\epsilon$，减小 $W$，或者变成 CSP(q,2)$ 然后减小 $q$。

#### Hastad's 3-bit PCP: Boolean Function Analysis

##### Boolean Function and Fourier Analysis

一个 Boolean Function 是 $\{0,1\}^n\to \R$ 的函数。显然我们在常规模型里面计算的都是 $\{0,1\}^n\to \{0,1\}$ 的东西。这可以看成 $2^n$ 维向量。

但这个东西不那么适合拿来分析：$0$ 无论怎么操作还是 $0$，这在形式上不好看。因此，我们会放到乘法群上，考虑另一组自变量：$\{1,-1\}^n$。其中 $0\to 1,1\to -1$（同时我们也把输出变掉）。这样的话，我们容易写出一组完美的正交基：

$$
\chi_{\alpha}(x)=\prod_{i\in \alpha}x_i
$$

这里补充一些定义。首先函数内积是 $\langle f,g\rangle=E_{x}[f(x)g(x)]$。此时容易发现上面是正交基。那么根据显然的式子：

$$
f=\sum \langle f,\chi_\alpha\rangle \chi_\alpha
$$

因此我们有一个简单的记号：$\hat f_{\alpha}=\langle f,\chi_\alpha\rangle$。我们可以用系数来表示函数。

同样显然的东西：

$$
\langle f,g\rangle=\sum \hat f_{\alpha}\hat g_{\alpha}
$$

##### Proof of Linearity Test

如何分析各种正确率？那就暴力把系数写开，然后用正交基的性质。

考虑 Linearity Test：我们希望说明，如果 $f$ 和一个正经的 WH Code 很接近，那么成功概率很高，同时反之亦然。

首先注意到一个 WH Code 正好是某个 $\chi_{\alpha}$。两个东西的接近程度正好是内积，那前半段相当于说 $\hat f$ 有一个很大的系数。

那我们考虑算正确率。换成乘法之后，相当于算 $\Pr[f(x)f(y)=f(xy)]$，或者 $E[f(x)f(y)f(xy)]$，然后 $+1,/2$（因为取值变成了 $\pm 1$）

然后暴力拆：

$$
E[f(x)f(y)f(xy)]=E[\sum_{a,b,c}\hat f_a\hat f_b\hat f_c\chi_a(x)\chi_b(y)\chi_c(xy)]
$$

然后呢？注意到 $\chi$ 是积性函数：

$$
E[f(x)f(y)f(xy)]=E[\sum_{a,b,c}\hat f_a\hat f_b\hat f_c\chi_a(x)\chi_b(y)\chi_c(xy)]\\
=E[\sum_{a,b,c}\hat f_a\hat f_b\hat f_c\chi_a(x)\chi_b(y)\chi_c(x)\chi_c(y)]
$$

然后就可以右边分别 $E_x,E_y$。此时根据正交容易发现，有值当且仅当 $a=b=c$。那么我们直接得到

$$
=\sum \hat f_a^3
$$

现在大概就是对的了。但还可以继续考虑。注意到 $\langle f,f\rangle=\sum \hat f_a^2=1$。那么这个就不超过 $\sum \hat f_a^2\max\hat f_a=\max\hat f_a$。

这东西有一个卷积解释，但是那样对后面没啥用，所以不讲了。

##### Proving Goldreich-Levin using Fourier Analysis

Ex12。

另一些常见分析计数：考虑前缀。定义

$$
\hat f_{\alpha*}=\sum_{\beta}\hat f_{\alpha\circ\beta}^2
$$

即固定前缀后剩下部分的和。考虑如下式子(ex12a)：

$$
E_{x,x',y}[f(x\circ y)f(x'\circ y)]=E_{x,x',y}\sum_{a,b}\hat f_a\hat f_b\chi_a(x\circ y)\chi_b(x' \circ y)
$$

然后又可以前后拆开，这样就可以看出 $a,b$ 的后半段必须相同。记后半段为 $c$，然后：

$$
E_{x,x',y}[f(x\circ y)f(x'\circ y)]=E_{x,x'}\sum_{a,b,c}\hat f_{a\circ c}\hat f_{b\circ c}\chi_a(x)\chi_b(x')
$$

然后注意到给单个 $\chi_a$ 求期望非零当且仅当 $a=\emptyset$。那么这个式子的结果就是：

$$
\sum_c \hat f_{0\circ c}=\hat f_{00\cdots 0*}
$$

求其它前缀也类似(ex12b)：贴一个 $\chi_\alpha(x)\chi_\alpha(x')$ 即可。

注意到上面的东西都可以采样：如果算一个 $f_a$ 那就用第一问(ex12c)。如果算所有很大的系数，那就分治，每次用第二问算当前区间的总和(ex12d)。

那这有什么用呢？(ex12e)在 Goldreich-Levin 里面，你算内积有 $1/2+\epsilon$ 的正确率，那正确内积的系数就有 $2\epsilon$。然后就用上述技巧把所有系数大的找出来，然后一个个试一下即可。

##### Long Code

考虑如下编码方式：将 $i$ 编码为 $\chi_{\{i\}}$。

如何判定合法性？考虑这样一个 Test：随机 $x,y$，然后以特殊方式随机 $z$：$1-p$ 概率取 $0$，$p$ 概率取 $1$。判定是否 $f(x)f(y)=f(xyz)$。

然后照抄一遍，到最后变成：

$$
=\sum \hat f_a^3\chi_a(z)
$$

此时就可以发现 $\chi_a(z)$ 非常简单：每个不在里面的贡献 $1-p+p=1$，在里面的贡献 $1-p-p=1-2p$。所以得到：

$$
=\sum \hat f_a^3(1-2p)^{|a|}
$$

###### Alphabet Reduction using Long Code

Long Code Testing：首先做 Linearity Test。然后考虑干掉其它的情况。做法如下(ex5d/e)：随机一个位置询问，如果是 $1$ 就跳过。否则，如果是 Long Code，那只有一个位置决定值，而且那个位置当前是 $0$。但如果是更大子集的 Linear Code，那可能有偶数个 $1$。接下来这样操作：随机将 $1$ 变成 $0$，再问一次，看结果会不会变成 $1$。注意到全 $0$ 可以混过去，那再判一下全 $0$。

Long Code Decoding(ex5a/b): Long Code 是 ECC，并且可以快速解码：给一个 $f:[W]\to \{0,1\}$，计算 $f(x)$。在错掉 $1/10$ 的情况下，正确率还是很高。

注意到这个就是 $x\in \{y|f(y)=1\}$。为了做到 ECC，就注意到这是个线性函数，然后随机 $z$ 算 $(s+z)-z$。

然后编码 2CSP 的构造和曾经干的事情一致(ex5f)：每个变量编码取值，每对变量再编码一次取值。然后验证一次二次是否一致，验证二次是否对。

##### Basic Hastad Test

给定 $u,v$ 和一个 $H$，我们想要验证是否 $H(u)=v$，但我们希望这是 PCP 的。

如果没有 $H$ 那大家都知道该怎么做。现在考虑这个 $H$。如果用 Long Code，那么 $c_s=\{u\in S\}$。考虑给一个 $u$ 的 Long Code，我们怎么算一个 $H(u)$ 的 Long Code。可以发现，$H(u)\in S$ 当且仅当 $u\in H^{-1}(S)$，其中 $H^{-1}(S)=\{x|H(x)\in S\}$。那么很简单：$H(u)$ 的 Code 的第 $S$ 位就是 $u$ 的 Code 的第 $H^{-1}(S)$ 位。然后复刻之前判定相等的过程，我们就得到

$$
E_{y} f(H^{-1}(y))g(y)
$$

但我们还需要判定是不是 Lone Code。为了省询问数，考虑和 $f$ 叠起来，那么得到（有一项 $f(H^{-1}(y))^2$ 被消掉了）：

$$
E_{y,x} f(x)f(H^{-1}(y)xz)g(y)
$$

其中 $z$ 还是之前那个分布：每一位 $1-p$ 概率取 $0$，$p$ 概率取 $1$。

那如果有解，我们直接把 $f,g$ 写成对应的 Long Code，然后得到：

$$
E_{y,x} f(x)f(H^{-1}(y)xz)g(y)=E_{y,x}x_uH^{-1}(y)_ux_uz_uy_v
$$

但根据定义，$H^{-1}(y)_u$ 就是 $y_{H(u)}$，所以只剩下 $z_u$。那可以发现正确率是 $1-p$。

现在来看另一个方向。如果正确率很高，至少是 $1/2+\delta$。那么转换 $\pm 1$ 后求和就至少是 $2\delta$。那拆出来：

$$
2\delta\leq E_{x,y,z}\sum_{a,b,c}\hat f_a\hat g_b\hat f_c\chi_a(x)\chi_b(y)\chi_c(x)\chi_c(H^{-1}(y))\chi_c(z)
$$

那首先从 $x$ 可以看到 $a=c$，所以


$$
2\delta\leq E_{y,z}\sum_{b,c}\hat f_c^2\hat g_b\chi_b(y)\chi_c(H^{-1}(y))\chi_c(z)
$$

然后把 $z$ 拆了，和之前的分析一样，$z$ 可以独立性拆开：

$$
2\delta\leq E_{y}\sum_{b,c}\hat f_c^2\hat g_b\chi_b(y)\chi_c(H^{-1}(y))(1-2p)^{|c|}
$$

现在我们来看 $y$。如果 $y$ 的第 $i$ 位变成了 $1$，那在右边，$H^{-1}(i)$ 这些位置也会变成 $1$。然后取值的正负性由 $y,H^{-1}(y)$ 和 $b,c$ 中共同是 $1$ 的位置数量的奇偶性确定。

一位一位考虑，如果对于某个 $i$，它操控的那些位里面 $b,c$ 有奇数个 $1$，那可以发现改这一位就会翻转值，然后总和期望就是 $0$。为了避免这种情况，必须有偶数个 $1$。但因为每个 $i$ 只操控 $b$ 那边的一位，那么为了非 $0$，$b$ 的每一位都由 $c$ 唯一确定：$b$ 的第 $i$ 位等于 $c$ 中 $H^{-1}(i)$ 位总和的奇偶性，因为只有这样能让和不是 $0$。

记这个操作为 $h_2(c)$。那他就等于

$$
2\delta\leq \sum_{c}\hat f_c^2\hat g_{h_2(c)}(1-2p)^{|c|}
$$

##### Hastad Test

考虑一个一般的 2CSP，满足所有限制形如 $H_i(x_j)=x_k$。

我们对于每个 $x_i$ 搞一个 Long Code，然后 Verifier 非常直接：随机一个限制，然后用上面的 Test。

我们考虑这个东西的正确性。我们的目标是说，如果 Verifier 能够很大概率成功，那么实际上的 Code 多少包含了一些满足 $H_i(x_j)=x_k$（虽然他大概率不是个真正的 Code）

考虑上面我们说的事情，如果成功率是 $1/2+\delta$，那我们就有

$$
2\delta\leq \sum_{c}\hat f_c^2\hat g_{h_2(c)}(1-2p)^{|c|}
$$

直观上看，这东西有点像包含了一个关系：如果 $c$ 里面只有一个元素，那右边 $h_2(c)$ 就正好在 $H(c)$ 处有值。如果它们两个系数都不小，那我们就可以提取出来。

那更大的集合怎么考虑？那就均匀随机一个。因此考虑如下构造：对于每一个变量的 Code $f$，我们按照 $\hat f_a^2$ 随机一个 $a$，然后随机取里面的某个元素。

现在考虑更大的一组 $c,h_2(c)$，我们知道每个 $h_2(c)$ 里面的东西在左边都有奇数个原像出现。那么如果我们一起随的话，正确率至少是 $1/|c|$。

但有个问题：如果 $h_2(c)=\emptyset$ 怎么办？注意到规范解里面没有这种情况，那我们可以考虑修改 Code 强行规避：称一个 Code 是奇函数，如果 $f(x)=-f(-x)$（在 $0/1$ 下考虑）。这样的话，我们可以只读一半的 bit 强行保证这是个奇函数。首先正确的 Code 满足这个条件，然后很容易发现：

对于一个奇函数，$\hat f_{\alpha}$ 只有在 $\alpha$ 包含奇数个位置时非零。

证明：考虑内积定义，然后每一对 $f(x)=-f(-x)$ 一起看，如果 $\alpha$ 有偶数个元素那这一对系数相同从而抵消。

那上面的 $(1-2p)^{|c|}$ 差不多是个 $1/|c|$ 级别的东西。如果我们想搞出 $\sum \hat f_c^2\hat g_c^2*1/|c|$，最好用 Cauchy 把一次升到二次：

$$
\sum \hat f_c^2|\hat g_c|1/\sqrt{|c|}\leq (\sum \hat f_c^2)^{1/2}(\sum \hat f_c^2\hat g_c^2*1/|c|)^{1/2}
$$

右边是成功率的根号，这很对。那为了把这东西放成 $1/\sqrt{|c|}$，一种手法是注意到（？）：

$$
(1-2p)^{|c|}\leq 2/\sqrt{p|c|}
$$

然后即可发现 $\delta^2p$ 不超过成功率。那么：如果 $\delta^2p$ 的平均值不超过 $\epsilon$，由另一个 Cauchy 可知 $\delta$ 的平均值不超过 $\sqrt{\epsilon/p}$。由此可以得到如下结果：

我们有一个 $PCP(\log n,1)$，它只询问三个位置。对于一个 2CSP，给一个 $p$，它满足：

1. 如果它可以被全部满足，那当前成功率不小于 $1-p$。
2. 如果只能满足 $\epsilon$ 部分，那当前成功率不大于 $1/2+\sqrt{\epsilon/p}$。

##### Raz's Theorem

我们可以构造 $\epsilon=2^{-t},W=2^{O(t)}$ 的 2CSP 问题，使得这样近似是 NP-Hard 的。更进一步，它满足上面的性质：每个限制形如 $H_i(x_j)=x_k$。

证明跳过，我也不会。

然后就可以说明，存在任意 $(1-\delta,1/2+\delta)$ 正确率的 PCP。

可以发现 UGC 已经很接近这个东西了：如果变成 $H$ 是排列，那就是 UGC。但这个能证，而 UGC 还是 Conjecture。

##### Applications

直接的推论：考虑一堆线性方程，每个方程形如 $x_a+x_b+x_c=0\pmod 2$，问最多能满足多少。

显然这就是上述 PCP，那么任何 $1/2+\epsilon$ 的近似都是 NP-Hard 的。

###### MAX-3SAT

注意到一个线性方程可以写成四个 Clause，如果满足则全部满足，否则必定不满足一个。（把所有静止形状写出来）

那么近似比 $3/4+1/4*1/2+\epsilon=7/8+\epsilon$ 都是困难的。

###### Set Cover

考虑这样一个 Set Gadget：有 $W$ 个子集 $C_i$ 和它们的补集。满足除非选了一对 $(C_i,\bar C_i)$，否则至少需要选 $k$ 个才能覆盖全集。

然后考虑这样构造：每个限制来一个这样的集合，然后对于 $H(u)=v$ 的限制，$v$ 对应 $C_v$，然后 $u$ 对应 $\bar C_{H(u)}$。这样合法当且仅当我们选了一对满足 $H(u)=v$ 的东西。所以如果有解，我们就能 $n$ 个 Set 解决问题。

对于无解的时候，我们一定是每个变量选了很多值。注意到根据 Set Gadget，如果对于一个限制 $H(u)=v$，两边选的变量数加起来不超过 $k$，那么其中一定存在一对满足 $H(u)=v$。然后考虑，每个变量随机选一个选中的值，这样如果总共选了 $nc$ 个 Set，那期望满足数量应当是 $O(n/c^2)$。因为我们知道 2CSP 的 $\epsilon$ 可以任意小（Raz），然后 $k,W$ 可以放大，那这说明对于任意常数 $C$，区分 $n$ 个能覆盖和 $nC$ 个才能覆盖是困难的。

###### Max Cut

ex17: 显然 2CSP 可以表示 Max Cut。

#### Misc Exercises

ex6: 不想做了。

ex7：枚举一个变量扫过去即可。

ex8：直接数。

ex9：懒得做。

ex10：考虑每个 Hypercube 即可。

ex11：回顾 Chapter12 Exercise1。我们重新考虑那个分治，可以发现：Hypercube 上大小为 $k$ 的子集之间最多有 $k\log k$ 条边。证明就是直接分治，每一层的边数不超过 $\min(s_1,s_2)$。

这个 Theorem 好像有个名字，但我忘了。

然后就可以直接证明第一部分。对于第二部分，注意到卡满的情况只能是均匀分治，所以只能是一个低一维的 Hypercube。

ex13/14：我好像有一个想法，但它看起来不可能对，然后懒了。



### XXIII Natural Proof Barrier

有一个结果(可以看我博客的密码学篇):存在 Minicrypt 当且仅当某种程度的近似 $K$ 或者 $K^t$ 是困难的。

我们只看对这里有用的一部分：如果我们能近似 $K$ 或者 $K^t$，我们就能干掉所有 PRG，然后就能干掉其它东西。

为什么呢？因为随机串的 $K$ 大概就是它的长度，但 PRG 输出的串可以被 PRG 的程序和一个小的随机种子刻画，所以它的 $K$ 很小。因此 $K$ 在某种程度上描述了 PRG 的输出和随机串的本质不同。

那么类似的，还有一个更常见的东西也刻画了这样的本质：Circuit Complexity。我们知道，一个随机函数的 Circuit Complexity 是 $2^n/n$，但一个 PRF 的 Circuit Complexity 又一次只是随机 Seed 的长度加上算法描述，所以它们又有本质区别。因此和之前类似的，如果你能很好的算 Circuit Complexity，那你就能干掉所有 PRF。

这看起来都没啥问题：一个 Hardness 对另外一个 Hardness。但这样的话……

> 如果你的 Circuit Lowerbound 证明一不小心能够很好地算一点 Lowerbound，那它就干掉了 PRF。

这大概就是 Natural Proof Barrier 的核心。而后者我们相信是存在的（至少是现在很难干掉的，这也就说明了为什么它使得 Circuit Lowerbound 这么困难）

但和 PRG 的例子有一点区别的是，PRG 部分输入只是一个串，所以 poly 它不是问题。但 Invert PRF 要求还是 poly(n) 而此时写出整个函数就是 $2^n$ 的。因此我们会做一点 padding argument，然后得到一个显然不是 poly 但也不是过于逆天的运行时间。因此我们定义：

Subexponential Strong OWF: Adversary 可以跑 $2^{n^\epsilon}$ 时间。

这个仍然是被相信存在的，然后我们就可以具体来看 Natural Proof Barrier，来考虑什么叫做“一不小心能够很好地算一点”。

#### Natural Proofs

我们回顾一些经典证明：

Parity not in AC0(Chapter14 前半段)：一个 AC0 的东西满足：随机限制 $n-n^{\epsilon}$ 就可以让它变为定值，但显然 Parity 不行。

Communication Complexity(Chapter13)：我们可以说明，如果一个东西的 同色矩形划分/矩阵秩/discrepancy 很大（或者很小），那么它的 Communication Complexity 就很大。

在这些例子中，我们都定义了一个性质 $P$，使得所有很小的 Circuit 都满足这个性质，但我们想要证明的东西不满足，这样就可以得到 Lowerbound。

为了复现刚才的证明：如果我们能够通过这个性质算一点 Lowerbound，我们就能区分 PRF；我们还需要两点：

Constructness：首先我们要能算，注意到输入一个函数本来就是 $2^n$ 的，但上面给出了一个解决方案。因此我们只要求，存在一种方式，输入真值表以 $2^{O(n)}$ 的时间算出 $P$。

Largeness：区分 PRF 需要两步：它对随机串有一种表现，对 PRF 有另外一种表现。上面已经说明，$P$ 对 PRF 会输出 $0$。那么我们需要另一半：一个随机函数有不小(比如 $1/n$) 概率不满足 $P$。

#### Proof of Natural Proof Barrier

首先假装我们可以 poly 地算 $P$。那这样一个东西就干掉了 PRF：对着输入函数跑一下 $P$。

当然，poly 算一个 $P$ 大概率是不靠谱的。因此我们考虑 $2^{O(n)}$ 算 $P$ 的情况。此时我们只取 $n^{\epsilon}$ 位作为输入搞一个新的函数(别的地方填 $0$)。注意到随机搞完还是随机，而 PRF 搞完还是 PRF，而且我们 $P$ 里面定义“小的”是 poly(n) 的话，那 PRF 还是会被区分。这样就是 $2^{n^{\epsilon}}$ 时间。

有一些有趣小结论(ex3)：你不能用 Natural Proof 去证明一个 PRF 的 Hardness，因为证出来就不 Hard 了。

#### Natural Proofs and Unnatural proofs

##### Constructness

为什么会有 Constructness？显然你组合地一些简单的东西，它很大概率满足这件事，因为你的组合描述经常直接是一个算法。而且 $2^O(n)$ 是非常强的，比如说你可以暴力判断这个：限制某 $n-n^{\epsilon}$ 个变量（的一种取值）可以让函数变成定值。

那如何避免 Constructness？有几个例子：

1. $PSPACE\not\in SIZE(n^c)$

实际上可以把 SIZE 换成 SPACE，那一眼 Diagonalization。可以发现 Diagonalization 直接用的最基础的 Predicate，但这个是很难算的。

2. $PH\not\in SIZE(n^c)$(Chapter5)

甚至还是刚刚的 Predicate：我们直接把“不能用简单的 Circuit 写出来”这件事表示成一堆 Quantifier 就行。

但这些简单的例子又直接 relativize，这显然也不好。

3. (Santhanam 07) PromiseMA $\not\in SIZE(n^c),\forall c$。

这里 Promise 指问题有两个 YES/NO 集合，只需要在这些集合上答对。PromiseMA 的意思是存在一个 MA 算法达到这件事。

Proof. 首先用 IP=PSPACE。然后 IP 里面一个 Prover 只需要是 PSPACE 的。然后可以说明，一个 Prover 可以是 P Time 加上一个 PSPACE Oracle。

然后精细搞一下可以说明，只需要问这个 Oracle $n$ 长度的问题。

然后可以套娃：用这个 Oracle 证明自己。

记这个 Oracle 的 Circuit Complexity 是 $S(n)$，此时：

1. 如果 $S(n)\in poly(n)$。那么 $PSPACE=MA\in P/poly$。但又因为 $PSPACE\not\in SIZE(n^c)$，所以就成立了。
2. 否则，考虑加 $S^{1/c-\eps}$ 个 $0$。这样相当于还是给 MA 套了一个任意 Scale，使得它不在任何一个固定的 $n^c$ 里面。那为什么需要 Promise？因为 $S$ 不一定好算。

它不 Relativlize 的直观原因是第一步用了 Arithmetization。不过众所周知，Arithmetization 也有自己的 Barrier：如果你把 Oracle 也线性扩展开来，然后说明上 Oracle 结果不一样，就类似 Relativlization Barrier 一样。

##### Largeness

另一个问题，为什么会有 Largeness？一个直观的想法是，我们定义的 $P$ 希望对小 Circuit Complexity 输出 $0$，也对一些东西输出 $1$。但如果它直接对大 Complexity 输出 $1$，那随机函数显然满足这一点。这样的事情经常出现，比如上面列举的 Communication 那一堆。

还有另一个解释：如果直接拿 Curcuit Complexity 当 Measure，那证明一个函数有 $S$ 的 Lowerbound 就证明了一半的函数有 $S/2$ 的 Lowerbound：考虑随一个 $g$，然后算 $(f\oplus g)\oplus g$。注意到两边分别随机，所以如果有一半的没有这个 Lowerbound，那拼起来就能算 $f$。这再次说明，如果你很准的算了 Circuit Lowerbound，那它就有 Largeness。

我们还可以看一些不那么准的例子。

###### Complexity Measures

一个东西是 Complexity Measure，如果

1. $C(f\land g)\leq C(f)+C(g)$
2. $C(f\lor g)\leq C(f)+C(g)$

比如说，$C$ 等于 Circuit Complexity 加一。

但这个问题就和上面一样，只不过你把异或拆了：注意到

$$
h=f\oplus g,f=(\bar g\land h)\lor (\bar h\land g)
$$

那么至少有 $1/4$ 的东西很大。

多组合一下可以更好，但是懒了。

###### Submodular Functions

一个更强的条件是，$C(f\land g)+C(f\lor g)\leq C(f)+C(g)$。

此时甚至可以说明：

(Razborov 92): 如果 $C$ 还满足 $C(x_i),C(\lnot x_i)\leq 1$，那么 $C=O(n)$。

Proof(**). 我们先证明，$E[C]=O(n)$。然后拿上面那条求个和就知道 $C=O(n)$。

然后怎么搞呢？显然我们想让 $f$ 出现在左边而不是右边，这比较困难。记 $f'$ 是一个只考虑前 $n-1$ 位的函数，那么有

$$
f=(f'_1\land x_n)\lor (f'_2\land x_n)\\
f=(f'_1\lor x_n)\land (f'_2\lor x_n)
$$

然后写出 $C$，求和，可以惊讶地发现上下加起来可以再用一次 Submodular，然后就变成了

$$
2E[C(f)]\leq E[C(f'_1)]+E[C(f'_2)]+2C(x_n)
$$

然后就可以即刻归纳发现 $E[C(f_n)]\leq O(n)$。







--- 2023/9/17 -- 2025/1/22, 494 Days ---

完结撒蔷薇花。别的感想等会再写。

Note. 确实有额外证明没读完可能会补，typo看到肯定补，但是这个时间不会再改。