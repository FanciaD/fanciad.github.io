---
title: '[paper] Reachability Shortcuts'
date: '2025-05-08 11:42:03'
updated: '2025-05-08 11:42:03'
tags: Fancia
permalink: TheButterfly/
description: Reachability Shortcuts
mathjax: true
---

免责声明：写这篇的时候我心情很不好。因为我一个月啥都没搞出来。

我觉得我需要散散心。但是真能吗。

### Fineman's Parallel Reachability

问题是这样的：给一个有向图，我们想算连通性（比如，给一个源点）。

这里希望算法是并行的。但我们都知道，这东西已经在 $NC_2$ 里面了，做法是矩阵乘法然后快速幂。

所以还有一个要求是 efficient。这里指即使并行，总共的 work 还是 $\tilde O(m)$ 的。

这里的做法是:

> 向图中加入 $\tilde O(m)$ 条边，使得图的直径不超过 $n^{2/3}$ 且连通性不变。换言之，$a$ 能到 $b$ 当且仅当新图上也这样，且新图上最短路不超过 $n^{2/3}$ 条边。

然后我们还需要并行做，但那部分我还懒得看。我们先考虑如下问题：

#### (sequential) Reachability Shortcuts

做法非常直接：

1. 随机一个点 $u$，dfs 求出 $u$ 能到/能到 $u$ 的点，然后连所有 $u$ 相关的 shortcut 边。
2. 将所有点按照和 $s$ 的可达性分类，记作四类：互相到达(Bridges)，$s$ 可以到它(Descendants)，它可以到 $s$(Ancestors)，都不能到(Remainings)，然后递归 $D,A,R$ 三部分。
3. 沿着 $D,A$ 递归时深度 $+1$。深度到达 $k$ 时停止。

没了？没了。

这个分治和一般的不那么一样：一般的分治里面，我们需要搞一个合并算法让它正确。但这里正确性是显然的：就算啥也不加也能满足 Reachability 不变，而加的东西显然正确。

但另一方面，这里的 Efficiency 是困难的，这在一般分治里面是简单的。这里不同的是，好像很多分治步骤根本不会有一点进展。唯一有进展的只有 Bridges 的情况。那么，我们为什么会经常到 Bridges 的情况？

这样想好像根本看不出来为啥，因为可能就是没有。那换个想法：注意到 Remainings 没有一点代价，实际上 dfs 的时候根本走不到那里，因此这种情况也是不差的。那换成是说，我们希望不是一直走单纯 Ancestor 或者 Descendant 的情况。

因此我们单独把 $A/D$ 这部分拿出来看一下。为了方便分析，我们只考虑一条路径 $s\to t$，看看它在递归上会怎么变化。

首先考虑路径怎么分治下去。显然，$s$ 能到的点是路径的后缀，能到 $s$ 的点是路径的前缀。那么几种情况：

1. 完全无关，全部走 R 的情况。此时不影响分析。
2. 只有 $s$ 能到的点，那么前缀 R 后者 D。
3. 与上一个对称，前缀 A 后缀 R。
4. 两种都出现。但此时不用做了：我们已经加上了 $s$ 到 $u$ 和 $u$ 到 $t$ 的边。

因此无论如何，还有用的部分都被分成了不超过两段，每一段内部递归。然后段之间可以一步到达。也就是说，Shortcut 后的距离就是两边内部的和再加上 $O(1)$。

但这样的话，还是只有 Bridge 会真的减少距离，别的都是把路径一分再分。和之前的想法一致，我们只有在最后一种情况才算有进展，或者在第一种情况也没有任何代价。那么，我们真的不会一直选中间两种情况吗？

一个关键是，我们每次随机选一个点。那么为了考虑怎么分情况，我们就要考虑每个点是怎么分情况的。可以发现，这正好和每个点与起点终点的可达性有关：我们需要看 $s$ 是否能到 $u$，和 $u$ 是否能到 $t$。都不能到到都能到对应上面的四种情况。第一种可以忽略不计，算概率的时候甚至可以假装出现就重新随机。那么看后面三个。记 $\alpha,\beta,\gamma$ 表示 $s$ 能到/能到 $t$/都能到的点数。那么三种情况的概率正好是正比于 $\alpha,\beta,\gamma$。

然后我们需要看这三个怎么往下递归的。直观上看，我们就是把这么多点分到两个部分里面……那这不是寄了。考虑：$\gamma$ 占比是 $n^{-0.1}$，然后均匀递归，这样的话总共减少的概率只是 $(1-n^{-0.1})^{O(\log n)}$。

那么真的寄了吗？我们再看看，会不会有的点分治之后，就失去了能够分成 $\alpha,\beta$ 类的资格。仔细看一下，如果选出了一个 $\alpha$ 类结点，然后会发生什么。

记路径为 $1-2-\ldots-k$。然后我们选出了一个点 $u$，它能到 $k$。不妨设这个点能走到的链上第一个点是 $a$。

```
-------a------
      / 
     u
```

此时分治就是前面和 $a$ 后面。

先看一个 $\beta$ 类结点。也考虑它在链上的情况。

```
           v
          /
-------a------
      / 
     u
```

在链上有两种情况：如果 $v$ 在后面，那么它自然在分治右边（$u$ 能到的点），然后它在里面还是 $\beta$，因为 $a$ 能到它。

而如果 $v$ 在前面，那它可能在分治左边，此时还是 $\beta$。也有可能，通过外面的路径解决问题。但这种情况我们不知道，不过这是正面的，所以可以不管。

然后看 $\gamma$ 类结点。同样考虑链上第一个能到的/最后一个能到它的。如果这里搞出了 SCC，那可以忽略中间那一段。原因是 dfs 总能把这段一起搞出来。

那么

```
        v
     /    \
-------a------
      / 
     u
```

几种情况：

1. 链上 $u$ 能到 $v$，那就直接去右边做 $\gamma$。
2. 否则去左边，如果是上面这种情况就是左边 $\beta$。否则左边 $\gamma$。
3. 也有可能 $u$ 能通过别的手法到 $v$，那必定是右边 $\alpha$。

这好像都没啥意思。再看最后一种情况，内部之间的比较：

```
---------a-------
        /    /
       u    v
```

考虑 $u,v$ 之间的可达性。

如果互相不能到，那么都把对方扔到 R 侧，或者左侧。但此时只有 $a$ 严格最小的那个还保留可以作为 $\alpha$ 的情况。

如果 $u$ 能到 $v$，那么一定如上图所示，$a$ 在前面。此时分 $u$ 是对的，但分 $v$ 的时候，$u$ 在 A 侧而不是 R 侧，所以直接不在分治中了。

如果互相能到，那都把对面扔到 B 侧，那就更不可能了。

那么可以发现，随机选一个 $\alpha$ 类，期望能让 $\alpha$ 的总数减半。

这就非常nb，然后类似搞一个 $\beta$ 的情况，然后再说 $\gamma$ 直接清空。这样也能处理 $\gamma\to \alpha,\beta$ 的情况。

然后可以发现结论：每轮之后，总的 $\alpha+\beta+\gamma$ 期望减少 $1/4$。直观上讲就是说，如果一直分 $\alpha,\beta$ 的情况，那这些情况很快就没了。

此时可以发现，做 $r$ 层，最终 Shortcut 步数只剩 $2^r+n*(3/4)^r$。这实在是太神奇了。

一个更好的势能分析可以做到每次除以 $\sqrt 2$，但那太抽象了。

#### Parallel Version

为了做到并行，我们需要几步改进：

##### Bound-Hop search and Fringes

首先 dfs 是需要 n 个深度的。无向图 dfs 有一些高论，但有向图不知道。

一个减少深度的方式是，直接只搜 $d$ 个深度。这样自然就解决了深度太大的问题，但这样搞不一定对：之前的关键性质是，每条路径分治完只会分出最多两份，原因是如果能到一个点，就能到后面的所有点。但限制深度后显然不一定有这件事，甚至可以一条路径被完全分开——假设距离是 $a,a+1$ 循环。

为了避免这件事，考虑如果加入了一个点，就把它后面若干步的点复制进来——这些点被称为 Fringes。这样的话，它们可以帮助这个路径不被分开，但同时它们也保留在原图内继续递归。

考虑直接把向后 $+D$ 的东西拿进来。这样之后，每一个 $D$ 步的路径都可以有进展（像之前那样，就是进展到 $n^{2/3}$）。那么，令 $D$ 略大于 $n^{2/3}$ 的话，每次一个很长的路径可以变成相对短的路径（考虑每一段），最多 $\log$ 轮就可以变成 $n^{2/3}$。可以想象的是，这样的并行深度可能也是 $n^{2/3}$。

但每次多拿一些点，显然会导致递归复杂度增加。我们希望每次加进来的足够小——例如只有 $1/\log^3$ 倍，从而递归 $\log$ 层完全不影响。如何做到 $+D$ 步不影响事情呢？首先如果每个深度的点数是均匀的，那这是简单的：如果深度小于 $D\log^3$ 我们就直接不做了，否则复制一段就只有 $1/\log^3$ 的占比。一般情况呢？我们**随机**一个距离做，期望就是对的。

最后有个小问题：递归的话，我们希望每次搜的距离不增，不然可能全乱了。因为这里有个随机，所以给每一层一个距离区间，总共就多 $log$ 倍。

此时还有一些问题：例如，我们的证明依赖距离随机，但一条路径和当前选择点的关系可能与随机有关。为了避免这个，其一是分类的时候按照距离区间的上界分，其二是势能分析的时候可以发现有一定概率划分的东西不影响这事，但我没有发现明白。

##### Parallel Search

现在又有了一个算法，它只需要 $n^{2/3}\log^{sth}$ 深度的 dfs。但这还不是并行的，因为你需要每次选一个点开始 dfs。虽然理论上我们在分开递归，但可能剩下一些没有被访问到的点，这部分深度可能是 $n$。

为了避免这些一直访问不到，考虑一起搜——但这样直接每个点访问太多次。而我们希望的是总 Work 是 m polylog 的（不然直接矩阵乘法）。

那么有一个优秀的方式：倍增地访问。具体来说，我们让每一轮访问的点数是上一轮的 $(1+\epsilon)$ 倍，这样的话，考虑每个点第一个被访问的轮，它在这一轮被访问但不在上一轮被访问的话，期望访问的次数就是 $1+O(\epsilon)*(some \log)$ 级别的。原因就是考虑在这一轮里面随机了很多去到前面的轮。