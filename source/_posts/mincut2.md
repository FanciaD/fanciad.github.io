---
title: '[paper] Undirected Mincut'
date: '2025-04-21 07:13:21'
updated: '2025-04-21 07:13:21'
tags: Fancia
permalink: SkyofTwilight/
description: Undirected Mincut
mathjax: true
---

我承认我写得比较急，但这就是科研的样子。之后会慢慢修的。

现在好像一天不做事就像是严重摆过了啥都没干，而且事情也特别多……记得以前我放置都是以周为单位的。

~~这里url和 Directed 那篇同源。比较幽默的是，我本来预定这段时间会去玩A16往后然后就有新url想法了，但另外几个游戏档期从寒假拖到现在，所以还没玩成~~

### Mincut w/o Maxflow

Setting: 无向图，有边权。问题是全局最小割。

最小割都有经典的基于网络流的做法。暴力是 $n^2$ 次，用最小割树可以做到 $n$ 次。但考虑到网络流很难做，现在还是 $m^{1+o(1)}$，我们想要一些绕过网络流的方法。

事实上，虽然 s-t 最小割等价于最大流，但全局最小割我们确实有更好的做法：

#### Directed Case: Gabow's Duality

第一个有趣的观察来自于有向图的情况：有向图上，$s$-cut 的值等价于我们能从图中拆出多少棵以 $s$ 为根的外向树。

证明可以用拟阵交，可以参考上次写 Mincut 的东西。

这样的话，如果有一个真的最小割，它应该在每棵外向树上正好割一条边，这在外向树上对应的是一个连通块。然后我忘了怎么做了，这里略过。

但这不能直接解决问题：考虑到边权，一个图上拆外向树可能有非常多。

但这里可以**近似**！如果我们搞一个近似（$1+\epsilon$）的外向树分解，那此时真的最小割应该在大多数外向树上只割了一条边，然后我们就还能做。

因此很多时候，我们考虑的问题都是，能不能在把边权减到 $\epsilon^{-1}poly\log$ 的情况下，使得图里面的最小割还几乎不变？如果可以的话，我们先做这一步，然后跑拟阵交拆外向树，然后就搞定了。

对于有向图这并不容易，之前那篇里面提到的做法只做了 Partial Sparsification，然后用一堆技巧解决。

好消息是无向图确实有相关性质。但在那之前，我们还需要解决一个问题。

#### Undirected almost duality

在有向图上，我们可以直接拟阵交说明最小割和外向树分解等价。那如果在无向图上看，一个自然的想法是考虑普通的生成树分解。但这并不对：考虑2*三元环，最小割是4，但是生成树只能分出三个。

但事实上:

> Nash-Williams Theorem: 生成树分解至少是 $t$，当且仅当对于任意 $k$，最小 $k$-cut 的值不小于 $(k-1)t$。

只能说我对拟阵了解不深，只会到拟阵交。

那么找到卡准 $(k-1)t$ 的地方，因为 $k$-cut 的 $2$ 倍等于 $k$ 个 2-cut，所以我们可以给一个最小割的上界：$2(k-1)t/k$。所以这是 $2$-近似。

注意到我们之前说，有一个近似就能做了。这里换成 $2$-近似后，结论变为，最小割对于大多数树都割了最多两条边。

那无向图割两条边怎么做？首先还是可以边分。然后好像还有高明做法。

那么回到之前的问题，我们希望把边权减到很小（比如总数 npolylog）的情况下，使得图里面的最小割还几乎不变（如果它本来是最小割，现在还差不多是最小割）

然后下一步应该求生成树分解。但这又非常难。因此实际上我们应该不管说明那堆东西，然后直接这样做：

1. 先做一个 Sparsifier，把每条边拆成两个方向的有向边，然后随便选一个 $s$ 去做有向图时候的拟阵交做法。这个变换后的任何 s-cut 等于全局最小割，因此如果这里有 $k$ 棵树，最小割就在每棵树上面割了一条外向边。
2. 然后直接对着有向树跑刚才的东西，用**原图**统计权值（用无向边）就行——这东西真可以 polylog，但我忘了怎么做。当然也可以把图放回无向的情况。此时最小割总共割了不超过 $2k$ 条边，因此在很多树上割了至多两条边。这个我还是会 polylog 的：直上直下的情况从上到下搞维护一个线段树；然后在一个点分叉的情况枚举 LCA 然后扫 LCA 经过这里的非树边（别的贡献固定）

因为最开始实际上是近似，所以这里实际上需要 $k(1+\epsilon)$。但显然还是对的。

复杂度取决于 Sparsifier 的大小。第一步拟阵交是 $(最小割大小)^2*m$，第二步更快。因此如果在没有边权的情况下，我们的图边数还是 $\tilde O(m)$ 且最小割很小，那就做完了。为了第二点，我们需要放缩边权。

#### Cut Sparsifier

因此问题最后变成这样一个形式：我们希望找一个 $m^{1+o(1)}$ 大小的无权图，使得最小割是 $n^{o(1)}$，且原来的最小割现在放缩后还是 $1+\epsilon$ 倍近似最小割。

这相当于如下定义：

存在一个 $W$（缩放边权），使得：

1. 对于最小割（权值记作 $\lambda$），它当前的权值不超过 $(1+\epsilon)\lambda/W$。
2. 对于其它割，当前权值不小于 $(1-\epsilon)\lambda/W$。

可以验证如果有这个并且现在最小割很小，带入上面的结果后整个过程是合理的。

#### Karger's Solution

我们首先回顾一个经典减小边权的做法：取一个值 $B$，把边权除以 $B$，然后随机取整：如果除完得到 $k$，那么随机到 $\lceil k\rceil,\lfloor k\rfloor$ 中的一个，使得期望还是 $k$。这样之后最小割期望只剩下 $\lambda/B$。

分析：考虑一个割，它有一堆边，除完之后边权和是 $\lambda/B$。那么现在有一大堆 $01$ 独立变量（$>1$ 的边权贡献的固定部分显然更优），满足和的期望为 $\lambda/B$，然后我们想看它和 $\lambda/B$ 差距很大的概率。根据那种和 $n$ 无关的 Chernoff，超出 $1\pm \epsilon$ 倍概率至多是 $\exp(f(\epsilon)\cdot \Omega(\lambda/B))$。那么只要 $\lambda/B$ 稍微大一点……

但我们有 $2^n$ 个可能的割，无论如何也不能 Union Bound。但在无向图里面，根据上一个 Karger's Algorithm（参考段设）有如下结果：

> $k$ 倍近似最小割的数量不超过 $O(k^kn^{2k})$。（前面 $k$ 那一项具体啥样忘了）

证明就是跑一遍那个随机缩边，然后说明每个 $k$ 倍近似最小割留到最后的概率是这东西的逆。

这样的话，$k$ 倍最小割的数量就是 $\exp(k\log n)$ 级别的。根据一些更强的 Tail Probability，$k$ 倍变到小于 $1-\epsilon$ 的概率可能至少是 $\exp(k(\lambda/B))$ 的。那么只要 $\lambda/B$ 是 $poly\log$ 级别，这就够用了，同时最小割也是 $poly\log$ 的。

但怎么算 $\lambda$ 的？有一些简单的 $(2+\epsilon)-$ 近似，但我还不会

#### Deterministic Solutions: Pessimistic Estimators

关键问题。

一种做 Derandomization 的方法是，我们依次确定每个随机的结果，每一步往之后成功概率更高的方向走。

例如，考虑 Max-3SAT 的问题，直接随机就可以给一个 $7/8$ 的做法。为了确定性，我们考虑记 $C$ 表示期望正确的 Clause 数量。每次给某个随机变量赋值后，我们都可以 $O(n)$ 求出新的 $C$。注意到如果我们给一个变量赋值，那本来的 $C$ 是现在随机赋值后 $C$ 的期望。因此，总存在一种方式让 $C$ 不变小，从而我们每一步都不减少 $C$。最后就得到了确定性的 $7/8$ 近似做法。

在一般情况下，我们不一定能快速求出这个成功概率或者期望 $C$。比如换成上面那个例子，我们就需要考虑指数多个割。

因此，更一般的情况下，我们可以考虑算一个成功概率的**下界** $f$，满足

1. $f$ 是成功概率的一个下界。
2. 每次随机时，存在一种方式让 $f$ 不下降。



#### Expander Case

能不能不 Bound 每个割？如果我们 Bound 每一项，然后每个割只有很少的项，那么误差加起来还是不大。

考虑如果图是一个 $\phi$-Expander：对于任何一个割，它的边权和大于两边 vol 的最小值，其中 vol 是点集内所有点的边权和。

记最小割为 $\lambda$。如果我们拿出一个 $\phi$-Expander，那么根据定义最小割一侧就只有 $vol\leq \lambda/\phi$。我们考虑只解决小的部分。这样的话，考虑的项可能不多，我们就能只 Bound 每一项。

##### Small Cuts

更好的是，我们知道每个点度数至少得是 $\lambda$，所以点数只有 $1/\phi$。但算最小割还是需要求和 $\Omega(n)$ 项，如果我们想限制误差的话……

考虑化简：权值是一侧度数之和（vol）减去内部连边。这就只有 $(1/\phi)^2$ 项。如果我们限制每一项误差比较小——

1. 单个边的误差不超过 $\phi^2\epsilon\lambda$，
2. 度数为 $d$ 的点误差不超过 $\epsilon\phi d$。

这样全部求和，误差就是 $\epsilon \lambda$（$vol\leq \lambda/\phi$），然后就可以接受。

现在只有 $n^2$ 项。每一项放到 $\epsilon\phi^2\lambda$ 级别带来的误差都是可以接受的。然后对第二部分用 Chernoff，那么前面那里再来一个 $\log n$，这样就有 $\exp(-\log n)$ 的概率，然后搞 $n^2$ 项就行了。

然后这样放完，最小割就剩下 $\log n/(\epsilon\phi^2)$，也是可以接受的。

那我们的 Estimator 看起来就是这 $n^2$ 项 Chernoff，但我们还需要一个形式使得每一步不会减少……我们来回顾一下 Chernoff 的代数证明：先上 $\exp$ 然后准备用 Markov。上 $\exp$ 后得到 $\prod e^{E[X]}$，此时用凸性放缩到 $\prod E[e^x]$，然后单算每一项。

因此 Estimator 就是每一个地方的 $\prod E[e^x]$（再除一下 Markov 的东西），这一眼就是对的。

##### Large Cuts

但这样搞还是没法处理（两侧大小都）大的割，因为每一项误差是加起来的。**此时我们将大小定义为两侧点数最小值，因为上面实际上用的是这个**

但此时我们不需要好的近似大的割，只需要让它们不要太小。

那么传统处理方式是放一个 $\phi$-**Conductance** Expander(aka 菊花)，这样大的割上就有很大的权值（希望它是 $\lambda$），然后我们希望小的割影响不大。

但如果只有一个分界线，那比较小的割还是会 $+\lambda$。因此我们希望两条线：比如，点数小于 $\phi^3$ 都去上面（虽然实际上只会用到 $\leq \phi^2$），然后这里加到 $\lambda$，那小的割就只有 $\phi\lambda$，这样就和谐了。

最后算 $\lambda$ 还是和之前差不多。

#### General Case: the Expander Hierarchy

回到一般图的情况。类似的我们可以知道，如果我们跑一个 Expander Decomposition，使得每一块是一个 $\phi$-Expander，那么最小割在每一块内部割的 vol 总和是 $\lambda/\phi$，但这并不会说明点数不多，因为可能划分之后点的度数就比 $\lambda$ 小了。

因此我们定义 **Boundary-Linked Expander**：简单来说就是连到外面去的边也计算。要求割至少是内部边vol的 $\phi$ 倍，再加上外部边 $\alpha$ 倍。

Note on 参数取值：常见 Expander Decomposition 需要 $1/\phi=n^{o(1)}$（而不是最好的 $poly\log$），但 $1/\alpha$ 可以是 $poly\log$。等会会看到这非常有用。



现在就可以保证点数至多是 $1/\phi$ 了。那么和这部分的相关项会比较小。但实际上的最小割还会在这些 Expander 之间割，这可能还有非常多的项。

此时就需要考虑多重 Expander：考虑来一个上面那种 Expander Decomposition。如果把得到的每一个 Expander 缩点（自环扔掉）后，图又是一个 $\phi$-Expander。那我们就知道，一个最小割首先在第一层只割掉了 $1/\phi$ 个点，然后在第二层最多只有 $1/\phi$ 个 Expander。

当然第一层的情况既可能是一个 Expander 里面只选了几个点，也可能是只删了几个点。总之，小的那一侧计入割掉的数量。

因此一个最小割是 $1/\phi$ 个 Expander，再加上或减去 $1/\phi$ 个点。根据之前的想法，一个割的权值可以写成度数和减去内部连边的边权。现在还有减法项，做点容斥后也可以这样写。现在一项可能是一个 Expander 整体的度数，也可能是一个 Expander 向另一个 Expander（或者一个点）的所有边的边权和。

毛估估很容易相信第二层只割了 $1/\phi$ 个。但实际证明没那么简单：实际的割并不是以 Expander 为整体。

不过我们可以考虑那个近似到以 Expander 为整体的割。根据 Boundary Linked 的定义，割的权值不超过 Boundary 权值的 $\alpha$ 倍。那么如果我们转到那个割上，权值最多增大 $1+1/\alpha$ 倍。因此第二层实际上是 $1/\alpha\phi$ 个，但这也差不多。



然后我们可以扩展到更多层的情况：每次做 Boundary-Linked Expander Decomposition，然后缩点做下一层。层数是 $L=O(\log n)$。这样，一个最小割在每一层上最多割了 $1/\alpha^L\phi$ 个“点”。

这里就可以看出，为什么需要 $1/\alpha$ 比 $1/\phi$ 小了：$\alpha$ 会叠 $L$ 次。

两层的时候我们就要考虑每个 Expander 是只拿了几个点还是整体拿了删掉几个。为了方便，我们定义 **Decomposition Sequence**：在每一层上，我们选择这一层的若干个 Expander。这样，每一层上“割掉”的东西就是这一层和上一层的差。

这样多层套一下，每个最小割最多被来回分成 $O(L/\alpha^L\phi)$ 个这样的东西。所以只要我们每一项的误差乘上这个数量的平方还是很小，那就可以接受。因此我们希望找到一个取整方式，使得这 $L^2m$ 项（每个 Expander 的度数和，任意两个 Expander 之间的边权和。）

那么和之前类似，只要我们取整到 $\log n\epsilon\phi^2\alpha^{2L}\lambda/L^2$（我们相信整个系数是 $n^{-o(1)}$），那根据 Chernoff，总的成功率就很高。然后我们抄写一遍上面的 Pessimistic Estimator。

##### Balanced Cut Case

上面这样可以说明，每一个最小割都只有很小的误差。但是和之前一样，我们需要说明别的割不会太小。

这里做法非常直接：考虑先找一个 $n^{o(1)}$ 近似的 Cut Sparsifier，然后加到上面去。这样 $n^{o(1)}$ 倍近似以上的最小割现在都很大了，然后在上面把每层考虑的点数放大 $n^{o(1)}$ 倍解决剩下的。

对于一个一般的割，考虑像之前一样构造 Decomposition Sequence。每次往上的时候，我们选择 vol 的中位数，这样每次割的误差正比于这一层差距的 vol。

如果每一层割的误差都很小，那就和之前一样，搞出来总的项数不多，从而误差不多。否则，我们希望这次加的东西给它很大的权值。那就是误差越大权值越大……所以我们自己搞个 Vertex Expander。然后把不同层的构造叠加起来。根据结论，有常数度数的 Expander 构造，从下往上叠起来的时候均摊一下度数。然后因为这里误差向上传递，所以参数和 Expander Hierarchy 一样。



然后把两个构造叠起来。