---
title: '[draft] [paper] Undirected Mincut V2'
date: '2025-05-04 21:54:36'
updated: '2025-05-04 21:54:36'
tags: Fancia
permalink: EveryTimetheSunRises/
description: Undirected Mincut V2
mathjax: true
---

Disclaimer：还没写完。

考虑到这篇比一晚上速通那篇长了15倍而且难了15倍，写这么慢也是合理的。

真没 url 用了，换一个吧。

### Deterministic m*polylog Undirected MinCut

#### Reviews

##### Exact Mincut by Mincut Sparsifier

话接上一篇。在上一篇，我们学到了如下求最小割的方法：

记最小割为 $\lambda$。首先，如果我们通过某种手段，把有边权的图变成没有边权的，且满足：

1. 按照某种比例放缩后，图里面的最小割不小于 $(1-\epsilon)\lambda$，且原来的最小割现在边权不大于 $(1+\epsilon)\lambda$。换言之，它能够很好地近似所有最小割，且对于别的割也不会放得太离谱。
2. 现在图的最小割很小，比如说 $n^{o(1)}$ 或者 $poly\log n$。

在做到这件事后，我们把每条边拆成两条有向边，此时最小割等于有向图上任意一个 $s$-cut。根据有向图上拟阵交的结论，$s$-cut 的数量正等价于最多能拆出多少个以 $s$ 为根的外向树（参考mincut一代）。并且，我们有一个最小割大小平方乘上 $m$ 的求分解算法，甚至一个最小割大小乘 $m$ 好像再乘点 $\log$ 的算法（但是我没看懂）。

此时，一个本来的最小割在此时还是近似最小割，因此在当前图上它平均在每棵树上割了 $1+O(\epsilon)$ 条有向边。每条边有唯一对应的反向边，因此如果我们把反向割的也算进来，那平均也是 $2+O(\epsilon)$。此时就相当于把每棵树变成无向图。因此，它一定在很多树上只割了不超过 $2$ 条边。

然后就是这样一个问题：给一张图和一棵树，问所有树上割两条边的割在原图上的最小割。这东西总能数据结构 polylog 维护。

##### Constructing Sparsifier --- Randomized

因此拿出“某种手段”是最主要的问题。

首先，我们来一个 $\lambda$ 的 $\tilde O(m)$ 时间 $2$-近似。这东西我还不会，但是可以相信有。

然后，最初的做法是，我们直接把每条边权值随机取整到 $\lambda/poly\log n$ 的倍数，保证期望正确。然后根据 Chernoff，我们可以得到一个指数上有 $C/\lambda\cdot poly\log n$ 的东西。但这还不直接对，因为有 $2^n$ 个割。但根据那个随机缩边的算法，$\alpha$ 倍近似的最小割数量只有 $n^{2\alpha}$ 个。因此这东西会是对的。

##### Constructing Sparsifier --- Deterministic

如果图是个 $\phi$-Expander，那么所有真的最小割都会在一侧非常小——差不多就是 $1/\phi$。然后根据如下公式：

> 割的大小等于一侧度数和减去内部连边

我们只需要近似好每个度数和每条边的权值，就可以保证所有小的割都是对的。然后为了处理大的割，我们额外往图里面加一点 Expander。

然后显然可以随机取整，使得所有度数和每条边的误差都不大。但这样就可以确定性了——我们有一大堆 Chernoff，只需要考虑它们的错误概率之和，然后每一步往减少这个的方向选。

对于一般图，考虑 Expander Hierarchy。我们把一个最小割一层一层沿着 Hierarchy 放缩上去，即可得到它在上面每一层都割得不多——这个值由以下两部分组成：

1. 一层内我们是 $\phi$-expander，因此乘一个 $1/\phi$。这会是 $n^{o(1)}$ 或者小一点。
2. 更严重的问题是，我们每次向上放缩，最小割的权值都会变大——这个值是 $1/\alpha$，但它会乘层数次。通过合理配合 $\alpha$ 和 $\phi$，我们可以做到 $n^{o(1)}$。

但是这个还是可以接受，因此我们随机取整，保证每个 Expander 的度数和任意两个 Expander 之间的边权和误差都不大，然后套之前的东西。

~~好像写得比上次好~~

但这样很难做到 $poly\log$：每层就乘一个不小的数，乘很多次。如果这个数是 $1+o(1)$ 那可以，但 Expander Decomposition 至少是 $\log n$。

#### Overviews

我们每次提到 $\lambda$ 的时候，都认为那是一个 $1.00001$ 倍的近似最小割——实在不行我们可以先跑 $2$-近似，然后枚举。

因此我们介绍一些最新最热的方法。根据上面的分析，我们需要找到一个划分，使得：

1. 每个最小割在分出来的每一块上割的比较少。
2. 我们可以把最小割放缩到块之间（即补上或者去掉割的部分），此时割的大小只变成 $1+1/poly\log n$ 倍。

那么我们先来看第二点。

#### s-strong components

与那篇无权最小割类似的，我们先做这样一件事：

将图分成若干块，使得所有近似（$1.01$）最小割和每一块的交（较小一侧）满足 $vol\leq s_0$。

之前干这件事都是直接 Expander Decomposition，但那东西不够快。我们想要更好。

##### Push-Relabel

Expander 的另一种技术。

一种推流方式是，每个点有一个高度 $h$，然后我们只从高往低推流。每次，我们选择高度最低且还有流量的点，然后把它升一层，尝试把流推下去。

这里流量是贪心接收，即先 fill 这个点的 sink，然后继续向后推。那么可以发现：

1. 只有最高的层可能还有流量需要推。
2. 只有最低的层可能还能接收流量。

注意到我们每次是推不动了才升，那么还有如下结论：


3. 一条有流量的边只能从高度 $i$ 连向 $i-1,i,i+1,\cdots$。因为你是在 $i-1$ 层没法推了再继续。

那么如果暴力做到 $h>n$，那么就有空层，从而残量网络被流完了。如果考虑复杂度，那么

1. 升层只有 $O(nh)$ 次，总共会反转 $O(mh)$ 次边。
2. 如果我们写了当前弧优化，那么每次推流我们只用 $O(h)$ 的时间，或者我们用掉了一条边。从而复杂度就是 $O(mh^2)$ 的。
3. 更近一步，使用 LCT 维护所有当前弧，支持沿着一条链推流（链 $\min$ 和链减），那么就可以做到 $O(mh\log m)$。

但这有什么好处呢？好处是，我们不一定要让 $h=n$。考虑取一个比较小的 $h$，跑一会看看发生了啥。如果已经流好了，那皆大欢喜。不然，可能 $h$ 层的点上还有一堆剩余流量，或者叫做 excess。我们希望说明，这样就有一个 Sparse Cut。Sparse Cut 的好处是，如果我们沿着 Sparse Cut 分割，那此时删掉的边数就.

为了规范，我们考虑如下条件的流问题：

1. 边的容量正好是边权的 $U$ 倍。
2. 点上的初始流量不超过度数的 $\beta$ 倍。
3. 点的目标流量就是度数。

考虑这样一件事：我们在得到的分层图上选一层割。此时图上有两种边：

1. 从 $i$ 连向 $i,i+1$ 的边。
2. 从 $i$ 连向更后面层的边。根据上述性质，它们必定满流。

如果没有第二类边，那会发生什么？假设整张图没有 $\phi$-conductance Cut，那么第一层到第二层之间，割的大小至少是 $\phi$ 倍前面的 vol。但因为它们都是到第二层的边，那么前两层的 vol 就会至少是 $1+\phi$ 倍。那么最后就会得到 $(1+\phi)^{h/2}$（因为取较小一侧）。如果这个数大于了 $w(G)$，那就显然不对。因此可以发现，如果 $\phi= O(\log W(G)/h)$ 且 $h\geq \log W(G)$，那么根据 $(1+1/n)^n$ 啥的就能得到那个界。

因此没有第二类边的时候，就存在 $O(\log W(G)/h)$ 级别的 Sparse Cut，或者满流了。

然后看第二类边。因为它们必定满流，那么根据 $\beta,U$，可以得到，它们最多贡献差不多 $\beta/U$ 的 Conductance：边权是 $U$ 倍，而流量是 $\beta$ 倍 vol。当然这不直接对，因为可能沿着反向边流回来——但我们已经知道 $i\to i+1$ 的边很少，就是上面那些，那么再算一次也可以。最后得到，一定存在 $O(\log W(G)/h)+\beta/U$ 级别的 Cut。

但很多时候，我们不仅需要 Sparse Cut，还需要 Balanced Sparse Cut——两边的 vol 都不太小。不然，往下分的复杂度就爆了。在这里我们可以说明，如果最后没流成功的流量比较多，那上面的 Cut 就比较 Balance: 现在留在左边的流量是 excess + vol，而这里初始流量是 $\beta vol$。还可能有外面来的流量，那些是 $U\cdot O(\log W(G)/h)$。那么可以得到：

$$vol(left side)\geq excess / (\beta-1+O(\log W(G)/h))$$

不过这样好像只说了左边不会小。那怎么保证右边也不小呢？因为右边（第 $0$ 层）一定包含所有还可以接收流量的点，因此如果初始放的流量不多——比如不超过一半，那右边最后一层就至少有一半，然后就没事。

这样我们差不多就说，我们要么可以跑一个很好的流，要么可以找到很好的割。接下来，我们尝试使用这样的网络流解决问题。

##### The Flows

首先上面 Conductance 有一项 $\beta/U$，所以我们让 $U$ 大一点：取 $U=O(\tau)$，其中 $\tau$ 是一个妙妙小参数，现在我们只说它是 $\omega(1)$ 的。

我们先考虑，随便怎么样选一个流量流，然后我们想要说，如果有一个不是 s-strong 的割，那么它一定不能被流满——此时我们像刚才那样找到一组割，根据性质，左侧一定被流满了，因此左侧内部不存在一个不满足 s-strong 的割，所以它就是 s-strong 的。可以发现此时甚至不需要限制右边比较大，因为左边直接满足条件了。

那么考虑什么样的流能满足这件事：如果一个不超过 $\lambda$ 的割与当前区域相交，我们希望说，如果一侧大小不超过 $s$，那么它就不会流满。

我们看看这里面的流量是多少：

1. 从外面流进来的，这差不多是 $U\cdot \lambda$ 级别。所以只要 $s\geq O(\tau\lambda)$，那这部分就差不多没问题。
2. 本来就在里面的，因此我们希望有：对于任意一个权值小于 $\lambda$，一侧大小小于 $s$ 的割，它一侧里面的初始流量只有 $s/3$。

那不流了怎么样？可以发现合法是把 sink 流满或者流不动，但不能是 source 满流。因此有第三个隐性限制：

3. 初始流量总和至少是度数总和，从而一定能流满。
4. 同时，我们希望 $\beta/U$ 很小，是 $1/\tau$ 级别的。那么最好的想法是 $\beta=O(1)$，但稍微大一点好像也没太大关系。

如果有这个那就是好的，取 $U=O(\beta\tau),h=O(\tau\log W(G))$，那就得到了 $1/\tau$ 的 Cut 或者直接说明全部满足 $s$-strong。同时第一种情况左边也满足了 $s$-strong。

那问题来了，我们如何满足这个看起来一点都不均衡的限制：总的流量至少是总的 vol，但对于权值很小，一侧 vol 也很小的割，它的流量至多是 $vol/3$？

##### Flow Selection

我们希望把在一个小的割里面的东西给扔掉。怎么判断是否在一个小的割里面？那当然还是得流。

考虑从一个点开始放很多流，然后看它们能不能流到每个点自身度数的 sink 里面去。

我们想说一个小的割就不行——直观上看，能流出去的部分只有 $\lambda$，因此只需要一开始放的能够超过这部分和内部流量——但很遗憾的是，内部流量可以非常大，比如总的东西的一半。

这怎么办？我们介绍 Iterative Improvements：我们一开始得到 $s=W(G)$-strong，然后每一步我们尝试在 $2s$-strong 上得到 $s$-strong。这样的话，上面第二步就只有 $2s$ 的流量。那么，我们只需要每次在一个点上 $4s$ 流量，然后开始跑流，甚至可以让 $U=s/2\lambda$。此时一个流能跑满当且仅当它不在这里面——甚至能跑到 $3s$ 都当且仅当它不在割里面。这是为了保证只要不行，那么 excess 一定足够大。

那么问题又来了——怎么跑这么多流？每次我们可以放 $4s$ 的流量，这样需要跑一大堆上述网络流。好消息是，push-relabel 是一个 Incremental 的算法，说人话就是可以在上面加流量，然后总复杂度还是 $O(mh\log n)$。那我们考虑这样干：

> 在一个图上跑 $W_G/100s$ 组上面的东西，但是分别记录每组的流量怎么样了。然后拿出那些流了至少 $3s$ 的东西，如果至少有 $W_G/200s$ 组，那么这些再缩放一下就是一个合理的流量。否则的话，我们留下了 $W_G/100$ 的 excess。我们希望这就能说明一个很大的割。

然后看一下这堆参数：$\beta=200s/\lambda,U=s/2\lambda$——好像不大好。但我们可以更加放缩一下：取 $U=s/2\lambda\cdot O(\tau)$，然后跑 $\tau$ 倍的那么多组东西（限制放到，比如说，$3.9s$）。然后把这 $\tau$ 倍平均掉。此时会有一些割里面的东西跑出来，但是对于每个割，跑出来的都会很少（受到 $3.9$ 影响，所以没事）这样 $\beta$ 不怎么变，但是 $U$ 那边多了一个 $\tau$ 倍，所以 $\beta/U$ 这一项解决了。

但还有第二步——Balanced。回顾上面那个式子，可以看成 excess 除以 $\beta,U$。此时如果 $\beta$ 很大就不行。因此我们继续介绍：

##### Flow Scaling

##### Altogether

#### From s-strong to Uncrossing

回到之前的问题，我们希望把图划分成一堆小块，满足：

1. 剩余的边权不是太多，比如不超过原来边权和的 $0.998244353$ 倍。
2. 对于每一个近似最小割（$1.01\lambda$），我们可以把它近似到这些块上的一个割，满足权值增大的很少（$1+1/poly\log$ 倍），且改变的大小也很少（$poly\log$ 级别）

直观地看，我们先做上面那几步，然后删了很少的边。此时可以做到 $s_0=\lambda*poly\log$。除了希望 $s_0$-strong，我们还希望如下性质来满足第二条：

> 定义一个连通块 $S$ 上的一个割 $C$ 是 $(1+\epsilon)$-boundary sparse 的，如果这个割两侧在 $S$ 之中的点向 $S$ 之外的边权和都至少是 $(1+\epsilon)$ 倍这个割在 $S$ 上的权值。同时，我们只考虑 $\leq 1.01\lambda$ 的割。
>
> 一个连通块是好的，如果不存在这样的割。

如果不存在这样的割，那在一个连通块里面，每一个割都不是 boundary sparse 的，从而我们可以找到小的一侧，把割换过去。此时割的权值减少了原来 $S$ 内部割的权值，然后最多加上了某一侧向外的所有边权，所以最多增加 $(1+\epsilon)$ 倍。

注意这只是充分条件，因为加的边权是个上界，可能少加。

因此我们想在 $s_0$-strong 上继续划分。为了保证删的边不太多，我们希望这样操作完，所有块的 Boundary 大小之和只是之前的 polylog 倍（这里我们默认 $\epsilon^{-1}=poly\log$）。

从现在开始，我们考虑一个 $s_0$-strong 的东西，看如何在里面继续划分。

直观地想，我们希望不断找出这样的割，然后把它割掉。好处是，每次我们增加了 $2*\partial$ 的边权作为代价，但大块的 Boundary 减少了 $\epsilon\partial$，因为这是 Boundary Sparse。那么，随便我们怎么割，最后增加的 Boundary 总和都是可以接受的。

##### (Again) Flows, Sources, and Well-Connected Sets

我们可以从流的角度考虑这个问题，什么样的流可以区分出这样 boundary sparse 的割？

按照定义，这个割的大小差不多比两侧 Boundary 大小的 $1-\epsilon$ 倍要小。那我们就应该考虑这样的流：每个点的流量是外部 Boundary 边权，然后内部边流量就是边权。如果出现一个 Boundary Sparse 的割，那它流不出去，因此这个割就会被处理掉……

但一个流的问题不仅要有源，还要有接受流量的汇。不过我们有一个 $\epsilon$ 的差距，同时我们保证了**这个割是 s0-strong**的，所以它内部 vol 只有 $s_0$。因此考虑每个点放 $c*deg$，其中 $c$ 差不多是 $\epsilon\lambda/s_0$ 级别。然后割大概只能流出去 $\lambda$——

但此时我们并没有保证这里面的割就很大。因为即使整体上是 $\lambda$ 的割，分到这个小块（$s_0$-strong）里面可能就很小了。

那我们先不管这件事，先做简单情况：

> 定义一个块是 Well-Connected 的，如果它的最小割很大。这里我们让它至少是 $0.1\lambda$.

那此时就可以说这是合理的了。后面我们会看到，这个假设非常非常非常有用。

但还有个问题，这样可以说明，如果流到一半流不动了，那已经流满的部分确实是一个 Boundary Sparse 的割。但如果流太多（多于一半）甚至流满了呢？那就保证不了这件事了。这相当于说，我们不能往里面放太多流量。简单来说，每个点放 $c*deg$，其中 $c$ 差不多是 $\epsilon\lambda/s_0$ 级别。那么假设我们就在 $vol\leq s_0$（就是一个 $s_0$-strong 的割的一侧）上面放了流量，那总流量是 $s_0$。此时如果总的 $vol\geq s_0^2/\epsilon\lambda$，它就不能流满，我们就能找到一组割。

但问题还远没有结束。我们不知道哪个集合是割，因此我们不能确定往哪里放流量。而如果都放的话，显然就流不掉了。因此，我们希望流量数量是 $O(s_0)$ 的。也就是说，我们想找一些流量起点的集合，使得每个我们想考虑的割都被某个集合包含。然后，从每个集合开始做流，应该就能达到我们想要的效果。

##### From Flows to MinCuts, Good Cuts

但还有个问题——如果有多个割相交，那我们的流可能只会返回它们的交集。那这就寄了。

我们尝试说明一个割和这个交之间有一些性质，但从流的角度，它会在流不动时就停止，但前面可能有更小的割。

这启发我们切换到最小割的视角——它不必只看第一个流不出去的割，而是真的最小割。

这样的好处是，对于任意一个我们关注的割，我们可以取它和（最小）最小割的交，这不会增大最小割，否则最小割就会取外面。

回顾一下建图。每个点向汇点连 $vol*(\epsilon \lambda/s_0)$ 的边，然后每个问题有一个源点，源点向这个问题每个需要流量的点连 $(1-\epsilon)*\partial$ 的边。

然后我们取这个的最小割。我们希望的是，如果有一块东西，大小不超过 $s_0$，在当前大块内部割不超过 $\lambda$。然后如果它是 Boundary Sparse 的，它就会被叉出去。如果它不是 Boundary Sparse 的，那我们可以直接把它 Uncross 了。

1. 最小割的大小(vol)最多增加了 $s_0/\epsilon\lambda$ 倍，因为不然的话，割汇点边的代价就不如把所有源点边割掉了。
2. 我们割的确实是 Boundary Sparse 的，不然还是不如把源点边割掉。这样的话，不管我们怎么
3. 根据最小割性质，如果我们找到最小的最小割 $C$，那么对于任意一个割 $A$，$A\cap C$ 都是一个不会变差的割。那考虑对于一个在我们给流量的集合 $S$ 中的 $A$，我们可以把它变到 $A\cap C$ 里面。

仔细查看第三条。此时割减少了 

1. $A$ 在小块里面的割，以及
2. $A\setminus C$ 连向汇点的边

增加了

1. （$1-\epsilon$ 倍）$A\setminus C$ 的边界，和
2. $A\cap C$ 连向 $A\setminus C$ 的部分，还有
3. 源点连向 $A\setminus C$ 的。
 
如果没有第二项，那这就是完美的 Uncrossing：第一项减小的可以盖住后面三项，而后面三项中的前两项就是 Uncrossing 的代价。

而那一项是 $\epsilon\lambda$。那么——

如果割得比较大（常数倍 $\lambda$），那就还是 $1+\epsilon$ 倍的 Uncrossing。

那如果割特别小，怎么处理这个 $+\epsilon\lambda$ 的东西？这时有一个非常关键的观察：注意到最小割是 $\lambda$。那如果我们做了改动，这个改动的 Boundary 就是两边变化部分拼起来，那就是两倍原先的割，加上 $\epsilon\lambda$。所以，如果这东西 Boundary 小于 $0.49\lambda$，那更好——我们甚至把整块都叉出去了。

那么我们可以做之前的东西。需要构造：

> 找到数量不多的大小为 $O(s_0)$ 的集合，使得任意一个
>
> 1. $\lambda/10$-Well-Connected
> 2. $s_0$-strong
>
> 的割都被某个集合包含。

##### Covering Sources for Good Cuts

###### From Small Cuts (and Well-Connectness)

考虑如何枚举这样的集合。首先我们要找的是不大的割。那根据 Gabow 经典的做法，我们可以对图做生成树分解，然后最小割在生成树上割的比较少，然后就可以在生成树上枚举。

但众所周知这东西不能做到有权图。在上一篇里面，我们用了一整套 Expander 技术来让这东西近似正确。但如果我们只考虑（一大堆修饰词的）好的情况，那能不能更好呢？

上一篇说过，如果点数很少，那么逐项近似即可保证正确。而一般情况则是在 Expander Hierarchy 上点数很少。但此时我们有 $s_0$-strong, $\lambda/10$-Well-Connected，那每个点度数至少是 $\lambda/10$，所以点数至多是 $20s_0/\lambda$。那如果按照 $O(\lambda^3/s_0^2)$ 为单位放缩，对于这些连通块的误差就是小的，搞完（原来）还是 $O(\lambda)$ 级别。然后现在边权大概是 $O((s_0/\lambda)^2)$。

那我们照样去跑生成树分解……但有个问题，可能图里面真正的最小割有很多边，所以现在权值太小了。那么就跑不出生成树分解。

现在的情况是，全局之间的 mincut 可能很小，但是每个我们关心的集合都在一个 mincut 很大的区域里面——至少它自己就是。我们不能造出整个生成树，但我们还是希望对于每个这样的区域有一个生成树——尽管我们并不知道区域是啥。

总结一下，我们希望造一堆森林，使得对于一个 mincut 很大的区域，它在这里都连通。在这里，我们记“mincut很大”的分界点为 $k$，然后我们也希望有 $k$ 个森林。

但森林的话不太好拿之前那套转成有向生成树，这里考虑一套 MWU 做法：

每次取最小生成树，然后把用的边边权乘 $1.14$。

这是在干啥？？直观上看，我们希望搞很多生成树，同时尽量避免多重复使用边，因此搞了这个贪心。

那它为什么是对的？

结论：对于一个最小割至少是 $k$ 的连通块，在 $O(k\log m)$ 步内用到的最大边权是 $poly(m)$ 的。

首先这听起来很对，因为把那 $k$ 棵拆出来轮流选就是对的。但我们根本不知道这个块是啥，更不知道树是啥。但实际上我们真的可以证明：

1. 每次操作后，总边权最多增加到 $1+2/k$ 倍。

证明：初始所有边可以被拆到 $k$ 棵生成树上，使得每条边只使用两次。那么这些生成树的边权加起来是 $2$ 倍总边权，所以总存在一个是 $2/k$ 倍边权。

然后我们选最小生成树，所以 $k\log m$ 轮后，总边权是 $poly(m)$，这就搞定了。

那么考虑，只保留 $\leq poly(m)$ 的边，我们就能满足：

> 构造 $O(k\log m)$ 个生成森林，满足每条边最多出现 $O(\log m)$ 次，同时每个最小割至少是 $k$ 的集合在每一个森林上都连通。

回到之前的部分，在这个连通块里面，最小割差不多是 $0.1\lambda$，然后我们要考虑的割是 $\lambda$，所以这是 $O(1)$ 倍近似。那么放到上面去，这个割平均在每个森林里面割了 $O(1)$ 个位置。

那么我们可以找到 $n^{O(1)}$ 个集合……但这不好。一个好的数字是 $n\times poly\log n$，或者 $n\times poly(s_0/\lambda)$。

###### From Well-Connectness

唯一让事情变得不一样的条件，是我们还要求 Well-Connected。这实际上是一个非常强的条件——一个这样的集合，vol 很小($O(s_0)$)，最小割很大（$O(\lambda)$，认为这两差 polylog 倍）。更进一步，我们还知道点数也很少(polylog)。那一个点为了满足这件事，它的度数必须集中到一部分点上。此时随便捏一个就不能满足条件。

我们考虑的集合大小是 $O(s_0/\lambda)$ 的，因此如果想把两个集合捏在一起，它们中间至少需要一条 $O(\lambda^3/s_0^2)$ 的边来使得割是 $O(\lambda)$。但我们又可以只考虑 $vol\leq s_0$ 的点，这样每个点只需要考虑 $O((s_0/\lambda)^3)$ 个相邻点。这可以看成每个点这么多度数的图，然后我们选的需要是一个连通块。

但直接这样枚举，我们得到的连通块数量是 $O((s_0/\lambda)^{O(s_0/\lambda)})$，这是不好的。可以发现这里没有用整个块还是一个小割的性质。

###### Altogether

因此我们需要把两个性质放一起。

第一个性质实际上说明我们可以只用考虑 $O(1)$ 个块：注意到我们还有 $vol$ 很小的条件，那么树上做一个欧拉序，按照 $vol=s_0$ 分块，然后一个割了 $k$ 次的东西在树上是 $O(k)$ 个区间，放到块上即可。这样的话，暴力枚举 $O(1)$ 个块捏起来是正确的。但那还是太慢了。

此时每个点只被 $poly(s_0/\lambda)$ 个块覆盖，然后把这些造出来的块看做点，做第二步的东西。具体来说，两个 Set 连边当且仅当有点相交或者有大边权的边相连。因为每个点在 $poly(s_0/\lambda)$ 个集合里面，所以边数还是不多。这样就是 $O(n\cdot (s_0/\lambda)^{O(1)})$。这里产生了创纪录的 log 数量。

那这样我们就找到了这堆集合的构造。

##### Putting Cuts Together

然后按照之前的分析，我们只需要对于每个集合，以它为源跑一个最小割，就能找到我们想割掉的东西。

但这是 $\tilde O(n)$ 个最小割，naive！

什么，多个最小割？那我们应该使用

###### Approximate Isolating Cut

考虑放很多组源，然后跑 Isolating Cut。那我们是不是所有源放一起跑就秒了？这听起来好像有点不对。

仔细回顾一下现在的证明。我们需要考虑把割从 $A$ 换到 $A\cap C$ 的时候，割减少和增大了多少。之前的分析是，减少的有割的一项和连向汇点的一项，而第二项很小；它们能覆盖增大的三项，其中两项包含了 Uncrossing 的代价，所以是对的。但这里仔细看一下，$A$ 还连接了一些点——源点。之前，因为唯一的源点一直在 $C$ 里面，所以不会出现减少的项。但现在如果别的源点也连到 $A$ 里面，那你把这个点移走的时候就又减少了一些东西，这就寄了。

但这就说明，我们只要一次少放点，让放的集合不相交，就赢了。注意到上面的操作是，集合相交必定连边，然后我们在那个图上选 $O(1)$ 个点的连通块。那么我们每次需要选出尽量多个连通块，使得它们之间是一个独立集。因为度数是 polylog，我们每次选出一个之后，贪心把周围 $poly\log^{O(1)}$ 个位置都抠掉，然后选一个位置开始 dfs。这样就保证每次找到 $n/poly\log^{O(1)}$ 个位置，从而只需要跑 $poly\log$ 轮 Isolating Cut。

但 Exact Isolating Cut 的做法太慢了，需要 $O(\log n)$ 次最小割。不过，有一个 near-linear（假设图的 Conductance 是 $1/polylog$）的近似算法（保证找到的还是 Isolating）。那为什么这里图有这么好的 Conductance 呢？注意到我们每个点都向汇点连边 $\epsilon\lambda/s_0*vol$，那 conductance 差不多就是这个。

然后我们把之前证明的东西再再证一遍。现在还可能增加一项近似项，这个差不多是 $\epsilon s_0$ 的，因为最小割是 $s_0$。那只要 $\epsilon$ 足够小，比 $\lambda/s_0$ 小不少，就没什么问题。

那么之前的结论还是成立：对于一组里面的每一个 $S$，我们可以找到一个割 $C$，满足：

1. 它的 vol 不增加很多。
2. 它是 Boundary Sparse。
3. 对于本来 $S$ 中一个割 $U$，我们可以把它 Uncross 到 $C\cap U$ 里面，使得权值只增加 $1+\epsilon$ 倍。同时改变当且仅当原来在这里面割了 $\Omega(\lambda)$。

那根据之前对最小割的分析，所有的 Good Cut 都会被某一个最小割包含，然后移掉就解决了这个 Good Cut。根据我们造的最小割性质，每个割都是 Boundary Sparse 的，所以割一块出去 vol 会减少，大概是 vol 减少 $\epsilon\cdot k$，然后割了 $k$ 的一块。这样就可以说明总的 Boundary 只增加 $\epsilon^{-1}$ 倍。Uncrossing 的 $1+\epsilon$ 倍直接从最小割拿性质。调整大小就考虑，Good Cut 根本不能调整（在两个章节前）

##### From Good Cuts to All Cuts

> 1. $\lambda/10$-Well-Connected
> 2. $s_0$-strong
> 3. 割小于 $0.49\lambda$。

对于一个一般情况，我们考虑把它拆成很多小块，然后每一个小块之间使用上述构造找一个到删掉部分的 Uncrossing，最后直接拼起来。

那拼起来的代价是啥？当然是块之间边的量。

这就有一个问题——如果按照 $\lambda/10$ 分，那这个代价就是 $\lambda*(s_0/\lambda)^2$，这太大了。如果按照更小的分，那它就不是 Well-Connected，然后就不能用之前的结论。

但如果你还记得的话，之前不能用的主要原因是点数可能非常大，然后我们是一个 Additive 的近似。后面还有第二步把集合合并起来，但那个是可以做更小的割的——把大的边权的分界线放小 $poly\log$ 倍，从而复杂度增加一个 $poly\log$。

###### Shrinking to Smaller Sets

什么集合是小的？Well Connected（因为我们有 $s_0$-strong 的假设）是小的。

我们可以把不 Well Connected 的东西搞成一堆 Well Connected 的东西，那做法就是看到小的割就切掉。问题是，可能得到了特别多个小块。如果只有 $O(1)$ 个小块，那总的大小就很小，然后我们就赢了。怎么做呢？

之前我们的结论实际上更强：对于 Good Cut，我们不只是找一个 Uncrossing，更是直接把它叉出大块了。所以跑一轮之后，所有 Good Cut 的部分都直接被移除了。

再看 Boundary。因为每次割的都是 $0.1\lambda$，那平均每个块会有 $0.2\lambda$，加上初始边权。

因此可以证明。有一半减去 $O(1)$ 个块同时也是 Good Cut。更好的是，如果你把这些块删掉，那么剩下的块在剩下的图里面也有这么多是新的 Good Cut。（否则的话，把块拼起来，最后 Boundary 太大）

考虑跑一轮之前的东西。根据那堆分析，每一个是 Good Cut 的都会被某个割包含，然后被删掉。那么一轮之后就有一半左右的块没了。

那么可以神奇地发现，只要跑 $\log n$ 轮，那么最后就只剩下 $O(1)$ 个块。从而点数只剩下 $O(s_0/\lambda)$。然后，拿出之前的东西。

###### Splitting to Better Cuts

此时我们把割的权值调到 $O(\lambda\cdot (\lambda/\epsilon s_0))$，这保证最后无论怎么调，分出来中间的部分都不会太影响最小割。

这样搞的话，之前把 Set 合并起来（From Well-Connectness）那里参数需要改。但这只增加 polylog 倍。

然后每一块内部套一遍之前的证明，唯一区别是取整的时候我们手动说明它的点数合理，所以影响不大。

这样每一块内部我们有一个好的 Uncrossing，然后直接拼起来。注意到按照这个边界分，同时度数很小的和，那加起来中间部分只有 $0.01\epsilon\lambda$，所以这就是真的很好的 Uncrossing。

结束了……吗？不，我们只是把小块叉出去了，这还有点问题。

##### Recap

回想一下在这一个大的部分里面，我们干了啥。

我们最开始想说，一个 $(1+\epsilon)$-Boundary-Sparse 的东西是坏的，所以我们通过常规建图，跑一个最小割把这种东西拿掉。为了设计流量，我们搞了一大堆东西。

但最小割拿掉之后不一定就完全解决了 Boundary Sparse 的问题——我们知道，剩下的那一大块肯定没有这个问题了。但拿掉的部分不一定没有那些问题——可能那里面还有别的 Boundary Sparse 的割，但是被最小割盖住了。

因此我们想做 Uncrossing 的话，我们还得解决小块的部分……这和原来的问题有什么区别？

好消息是，我们分出来的块大小是很小的，实际上比 $s_0$ 大了 $s_0/\epsilon\lambda$ 倍（回顾一开始的网络流构造，我们需要这么多来保证它不流满，所以最坏是切了这么多。）

更好的是，类似之前的分析，无论里面怎么分，我们都能满足“变化得很少”的性质：注意到如果 $1+\epsilon$ 的 Uncrossing 改变了东西，那里面割的部分至少得是 $0.49\lambda$，否则两边拼起来就是更小的割。所以最多只会改 $O(1)$ 个。因为每一块很小，所以随便怎么改都是合法的。

这是 $\lambda\cdot poly\log n$，点数从而是 $poly\log n$。因此我们可以考虑多项式算法。

#### Polynomial Uncrossing

现在需要干的事情是，给一个块，我们还是希望分块做 Uncrossing。满足：

1. 能做 $1+\epsilon$ 的 Uncrossing。
2. 删边的数量可以是原先 Boundary 的 polylog 倍。

和之前最大的区别是，因为块大小只有 polylog，我们可以任意 poly 算法。

此时啥东西都可以拿出来用了，比如直接开切。（之前只能证明的时候用）

那直观地想，我们想干这件事：

> 如果存在一个 $(1+\epsilon)$-boundary sparse 的割，我们就把它切掉。

那么需要回答两个问题：怎么判是否存在这样的割？这样切复杂度对不对？

对于第一个问题，显然这相当于一个 Sparse Cut。但这东西最好的做法还是 Cut-Matching Game 那套，它不仅有个大近似比，还是随机的。

不过有个限制：我们只考虑大小最多 $1.01\lambda$ 的割。这有什么用？

直接搞好像没啥用，因为可能这部分里面最小割超级小，但如果这样呢？

##### Progress by Sparse Cuts

Rule 1: 如果图里面的最小割小于 $0.49\lambda$，我们就把它割掉。

为什么这有用？根据 Karger's Algorithm（随机那个），我们可以说明 $2.33$-近似最小割只有 $n^{4.66}$ 个。更高级的证明可以说明这东西只有 $n^4$ 个（指数上取整），但我不会，这里也不需要。根据 Karger's Algorithm（确定性那个，参考上一篇），我们可以枚举所有的近似最小割。做法就是先分出一堆树，然后 $\alpha$-近似最小割平均切了 $2\alpha$ 个位置。因此我们可以枚举一棵树，枚举 $\lfloor 2\alpha\rfloor$ 个位置割掉，然后计算最小割。这样复杂度就是 $m^2$ 乘上近似最小割的数量。

因此如果我们先按照上面那样切完，那么所有我们考虑的割都是 $2.33$-近似最小割，因此可以多项式时间枚举。

而且，事实上割掉这些是有理的：它们一定是 Boundary Sparse，两侧边界至少得是 $0.51\lambda$，不然你就有一个更小的全局割。

那为什么我们可以这样做？

记初始 Boundary 大小为 $\partial$。我们的操作是，每次选一个大小不超过 $0.49\lambda$ 的割，然后分开。我们希望证明，最后所有块的 Boundary 大小是 $\partial poly\log$。

为什么是 $0.49\lambda$？因为有一个隐藏的条件：图的最小割至少是 $\lambda$，所以每个块的 Boundary 大小至少是 $\lambda$。

直观地看，即使每次分很小一块出来，那一边也是 $\lambda$ Boundary，所以原来至少是 $0.51\lambda$ Boundary。那么大的块就至少减少了 $0.02\lambda$，总 Boundary 只是增加了 $0.98\lambda$。

一般地，我们定义势能为 $\sum\max(0,|\partial|-\lambda)$。可以证明每次势能减少 $0.02\lambda$，而总 Boundary 只是增加了 $0.98\lambda$。因此，最后的 Boundary 大小为 $O(\partial)$。

##### Progress of Not-too-small Components

现在，我们可以枚举可能的 $(1+\epsilon)$-boundary sparse 的割，然后考虑把它割掉。这样对吗？

此时每次相当于选一个 $[0.49\lambda,1.01\lambda]$ 的割割掉，然后因为两边都是 $1+\epsilon$ 倍，所以两块大小都会降低 $\epsilon$ 乘上割的权值。

如果每次割的都正好是 $1\lambda$，那可以设势能为 $\sum\max(S-2\lambda,0)$，用这个摊掉边界的增加。然后每步用 $\lambda/\epsilon$ 的势能减少换最多 $2\lambda$ 的增加……但这真的对吗？

这个分析在 $S$ 很小的时候就失效了，因为势能减少量为 $0$。确实有一个反例：现在有一块 $2\lambda$ 的，对半分可以得到 $2(1-\epsilon)\lambda$ 的两部分，然后继续对半分即可得到 $2(1-\epsilon)^2\lambda$。这样可以搞出非常大的满二叉树递归。

但可以发现，如果只操作大小至少是 $2.33\lambda$ 的块，那么每一步势能减少量还是足够少的。（考虑分成大/大，大/小和小/小的情况）。这是好的。我们可以先贪心这样做一步，然后变成如下问题：

##### Solving Small Compoments

现在每个块的边界大小只有 $2.33\lambda$，然后我们还是需要做之前的东西。

如果我们一直割，如何避免之前那个指数级大小的情况？有两点观察：

1. 那样搞出来，我们考虑了指数多个割（每个割总共只有 $1.01\lambda$，所以只会出现在很少的块中），但如果我们从最小割至少是 $0.49\lambda$ 的东西开始，就只有 $n^4$ 个割。
2. 我们更可以从整体的角度考虑这个割：如果第一次分开后两边大小都很大，然后第二次又在左边找了个 $(1-\epsilon)\lambda$ 的割……它也在右边出现！所以右边就最多 $\epsilon\lambda$。根据之前的分析，小的割直接割掉就是赚的。

据此，我们可以设计如下方(ma)法(yi)：

1. 先搞出所有值得考虑的那 $n^4$ 个割，只考虑它们在当前块上的投影。
2. 如果有一个割割得比较小，那就直接操作。
3. 否则拿一个 $(1+\epsilon)$ Boundary Sparse 的，沿着它割。如果都没有就愉快收工。

我们的核心思路是，在一步操作后，如果有另外一个割和它相交，那么这个割接下来要么在左边很小，要么在右边很小。无论如何，我们都可以在一边跑第一种情况，这是有进展的。

#### Altogether

全部拼起来，我们就得到了一个划分，满足：

1. Boundary 只是全图的一小部分。
2. 对于任何一个比较小的割，它都可以调整到这些块上，满足权值只增加 $1+1/poly\log n$ 倍，然后调整的量也只是 $poly\log n$。

然后和之前一样，我们造一个 Hierarchy，每次往上合并块。那么和之前一样，可以得到：

1. 每层往上只增加 $1+1/polylog$ 倍，所以到最后也还是只增加了 $O(1)$ 倍。因此，一个最小割在往上的过程中总共会改变 $O(\log n s_0/\epsilon\lambda)$。
2. 上一步的原因是这是个常数倍近似，因此上面层的推导仍然成立。只是在分成 Good Cut 的时候，需要调整常数。

因此在这里，只要我们把取整单位设成 $(s_0/\epsilon\lambda)^2\log$，那对于所有改变不超过 $s_0/\epsilon\lambda$ 的割，Chernoff 就可以对，然后我们就可以使用之前那一堆 Chernoff Estimator。

然后还需要处理改变很大的割。我们希望设计另外一个图，使得最小割在这个图上不会增加太多割的权值，但改变很大的割会增加至少 $\lambda$。

比起之前那堆重量级，一个最正确的观察是：最小割就是那些改变很少的割。那我们直接刻画改变，加点！来一个 Hierarchy 对应的树。这样的话，这上面最小割的贡献正好是最小改变量。

然后分个界：如果割了少于 $(\log n s_0/\epsilon\lambda)^2$ 就用上面那种方法做，然后来个大一点的取整单位。割得更多就考虑下面，此时让它们加 $\lambda$ 的话，小的部分只需要加 $\lambda*(\epsilon\lambda/s_0)\leq \epsilon\lambda$，这就对了。